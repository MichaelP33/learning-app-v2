import type { Quiz } from "@/types";

// AUTO-GENERATED by scripts/generate-quizzes-registry.mjs
export const externalQuizzes: Record<string, Quiz> = {
  "agile-scrum": {
  "title": "Agile/Scrum Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 24,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary Scrum artifact tying scope to delivery?",
      "options": [
        "Product Backlog",
        "Burnup Chart",
        "Definition of Done",
        "Sprint Velocity"
      ],
      "correctAnswer": 0,
      "additionalContext": "The Product Backlog is the ordered list of everything needed in the product; prioritization ties scope to delivery sequence.",
      "keyConcepts": [
        "Product Backlog",
        "Prioritization",
        "Scope"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Timebox for a standard Scrum sprint?",
      "options": [
        "1-2 days",
        "1-4 weeks",
        "6-8 weeks",
        "Quarterly"
      ],
      "correctAnswer": 1,
      "additionalContext": "Scrum sprints are short, consistent timeboxes (often 2 weeks) to enable frequent inspection and adaptation.",
      "keyConcepts": [
        "Timebox",
        "Sprint"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Who prioritizes the Product Backlog?",
      "options": [
        "Scrum Master",
        "Product Owner",
        "Developers",
        "Project Manager"
      ],
      "correctAnswer": 1,
      "additionalContext": "The Product Owner maximizes product value by ordering the backlog according to outcomes and risk.",
      "keyConcepts": [
        "Product Owner",
        "Backlog Ordering"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Daily Scrum goal?",
      "options": [
        "Approve budget",
        "Plan next increment",
        "Inspect progress and adapt plan",
        "Demo to stakeholders"
      ],
      "correctAnswer": 2,
      "additionalContext": "The team inspects progress toward the Sprint Goal and adapts the plan for the next 24 hours.",
      "keyConcepts": [
        "Sprint Goal",
        "Inspect & Adapt"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Definition of Done ensures:",
      "options": [
        "Scope flexibility",
        "Release cadence",
        "Quality and completeness",
        "Executive approval"
      ],
      "correctAnswer": 2,
      "additionalContext": "DoD is the quality bar for increments; work meeting DoD is potentially releasable.",
      "keyConcepts": [
        "Definition of Done",
        "Quality Gates"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Sprint Review focuses on:",
      "options": [
        "Team grievances",
        "Hiring decisions",
        "Increment inspection with stakeholders",
        "Quarterly roadmap"
      ],
      "correctAnswer": 2,
      "additionalContext": "The team and stakeholders inspect the increment and adapt the Product Backlog.",
      "keyConcepts": [
        "Increment",
        "Stakeholders"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Sprint Retrospective outcome:",
      "options": [
        "Shippable increment",
        "Updated Definition of Ready",
        "Improvement actions",
        "Budget approval"
      ],
      "correctAnswer": 2,
      "additionalContext": "Retro produces concrete improvement actions to enhance process, tools, or collaboration.",
      "keyConcepts": [
        "Retrospective",
        "Continuous Improvement"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Velocity best practice:",
      "options": [
        "Compare teams",
        "Treat as target",
        "Use for team forecasting",
        "Publish to executives"
      ],
      "correctAnswer": 2,
      "additionalContext": "Velocity is for team forecasting; it should not be used to compare teams or set quotas.",
      "keyConcepts": [
        "Velocity",
        "Forecasting"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Describe one concrete change you would propose after a retrospective and how you would measure its impact.",
      "sampleStrongResponse": "Introduce WIP limit of 2 per developer; measure lead time and carryover reduction across next 3 sprints."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 4,
      "question": "Explain how you ensure Definition of Done is applied consistently across stories.",
      "sampleStrongResponse": "Shared DoD checklist in PR template + automated checks (tests, coverage, lint) in CI; audit sample of completed stories each sprint."
    }
  ]
},
  "api-versioning": {
  "title": "API Versioning Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR introduces breaking changes without any policy. What do you require before merge?",
      "options": [
        "Ship now and update docs later if customers complain",
        "Adopt a versioning policy (URI or header) with frozen behavior per major and additive changes within a major",
        "Hide changes behind feature flags permanently without docs",
        "Support unlimited concurrent majors indefinitely"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: version lanes isolate breakers; majors freeze contracts.; Why correct: a clear mechanism and compatibility rules prevent silent breaks.; Why others are wrong: ship‑now erodes trust; flags without policy drift; infinite majors explode cost.; Cursor leverage: generate policy PR text; diff OpenAPI between majors; scaffold routers.; Acceptance checks: mechanism chosen; rules documented; routers/tests in place.",
      "keyConcepts": [
        "Versioning mechanism",
        "Compatibility contract",
        "Additive changes"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team wants both header and URI versioning for flexibility. What stance keeps behavior predictable?",
      "options": [
        "Use both; clients can pick any and behavior may differ",
        "Pick one primary mechanism and apply it consistently across endpoints and gateways",
        "Avoid versioning entirely; rely on minor changes only",
        "Randomize version selection per request to balance traffic"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: one primary mechanism reduces ambiguity.; Why correct: consistent routing and caching avoid drift and bugs.; Why others are wrong: mixed mechanisms create cache/tooling issues; no versioning blocks evolution; randomization is chaos.; Cursor leverage: update gateways; adjust caches/CDN; regenerate docs/SDK.; Acceptance checks: single mechanism enforced; headers/paths validated; caches configured.",
      "keyConcepts": [
        "URI vs header",
        "Consistency",
        "Caching"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Silent breaking change in v1 response fields. What remediation do you require?",
      "options": [
        "Leave it; customers will adapt",
        "Add Deprecation/Sunset headers, restore v1 schema, and ship additive v1.1 while planning v2",
        "Delete v1 immediately and force upgrade",
        "Change the SDK only without changing the API"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: fix regressions in‑lane and signal change.; Why correct: restore v1 behavior, add headers, and plan a clean v2.; Why others are wrong: ignoring breaks trust; forced migrations cause outages; SDK‑only diverges.; Cursor leverage: diff OpenAPI; generate comms; add middleware for headers.; Acceptance checks: v1 restored; headers present; v2 plan published.",
      "keyConcepts": [
        "Deprecation",
        "Sunset",
        "Compatibility"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "A new major (v2) is planned. What rollout plan do you require?",
      "options": [
        "Cut over all traffic at once and delete v1 immediately",
        "Staged rollout with per‑version routers, per‑version docs/SDKs, and adoption dashboards",
        "Hide v2 behind a query parameter to avoid router changes",
        "Keep both versions forever to avoid customer comms"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: stage majors with clear lanes and visibility.; Why correct: routers/docs/SDKs per version and dashboards enable orderly adoption.; Why others are wrong: big‑bang cuts break clients; hidden params drift; infinite support explodes cost.; Cursor leverage: scaffold routers; split OpenAPI; build dashboards.; Acceptance checks: per‑version docs/SDKs live; dashboards show adoption; rollback path defined.",
      "keyConcepts": [
        "Per‑version routers",
        "Docs/SDKs",
        "Staged rollout"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Comms for v1 sunset are missing. What do you require?",
      "options": [
        "Tweet once and hope customers see it",
        "Add Deprecation/Sunset headers with dates, publish guides, and email key accounts",
        "Rely on support tickets to notify customers",
        "Change only the SDK release notes"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: warn in responses and out‑of‑band.; Why correct: headers surface warnings where calls happen; guides and direct comms de‑risk adoption.; Why others are wrong: tweets and tickets miss traffic; SDK‑only misses curl and custom clients.; Cursor leverage: add headers; draft email templates; generate upgrade guides.; Acceptance checks: headers on every v1 call; comms sent; guide published.",
      "keyConcepts": [
        "Deprecation headers",
        "Sunset",
        "Migration guides"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Within a major, a field removal is proposed. What policy do you require?",
      "options": [
        "Allow removals if tests pass",
        "Freeze schemas within a major; allow only additive changes (new optional fields)",
        "Remove fields silently and update docs later",
        "Gate removals by a feature flag only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: additive‑only policy per major.; Why correct: freezing prevents silent breaks; additive changes preserve compatibility.; Why others are wrong: tests don’t cover all clients; silent changes break consumers; flags without policy drift.; Cursor leverage: add compatibility checks in CI; diff OpenAPI; update style guide.; Acceptance checks: CI blocks breaking diffs; policy documented; examples updated.",
      "keyConcepts": [
        "Compatibility",
        "Additive changes",
        "CI checks"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Gateways/CDN misroute versions occasionally. What do you require to isolate behavior?",
      "options": [
        "Allow mixed behavior; it averages out",
        "Per‑version routes and cache keys; include version in analytics and alerts",
        "Disable caching entirely to avoid issues",
        "Forward everything to a single backend and inspect bodies for version"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: route and observe by version.; Why correct: per‑version keys prevent drift and enable visibility.; Why others are wrong: mixed lanes erode trust; no cache kills perf; body sniffing is fragile.; Cursor leverage: configure cache keys; add version analytics; build alerts.; Acceptance checks: version‑tagged metrics; stable routing; no cross‑lane drift.",
      "keyConcepts": [
        "Version routing",
        "Caching",
        "Analytics"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "SDKs and docs drift from behavior. What guardrail do you require?",
      "options": [
        "Hand‑edit docs monthly as time allows",
        "Generate per‑version SDKs/docs from OpenAPI in CI and publish together with releases",
        "Let each team maintain docs independently of code",
        "Rely on community PRs to correct mismatches"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: generate artifacts from the source of truth.; Why correct: CI‑generated SDKs/docs keep parity across versions.; Why others are wrong: hand edits drift; siloed docs diverge; ad‑hoc fixes lag.; Cursor leverage: set up pipelines; split specs per version; publish on release.; Acceptance checks: generated artifacts; parity tests green; release notes linked.",
      "keyConcepts": [
        "OpenAPI",
        "SDK generation",
        "Docs parity"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a versioning policy PR note: mechanism (URI or header), compatibility rules (additive within major), deprecation headers, and adoption dashboards. Include acceptance checks.",
      "sampleStrongResponse": "Policy: choose URI (/v2/...) as the primary lane; freeze behavior per major; allow additive only within a major. Signal deprecations with Deprecation/Sunset headers and dates. Generate per‑version OpenAPI/SDKs. Dashboard: traffic by version and top lagging accounts. Acceptance: routing tests pass; headers present; v1/v2 docs live; alerts wired."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a v1 → v2 migration plan: staging, adapters, comms, rollout, and success metrics (e.g., &ge; 90% v2 traffic in 60 days, zero Sev‑1s).",
      "sampleStrongResponse": "Stage v2 behind per‑version routers; keep v1 stable. Provide adapters/shims where possible. Publish guides and SDKs. Roll out by account cohorts with dashboards and alerts. Success: &ge; 90% v2 traffic by day 60; deprecation notices acknowledged; no Sev‑1 incidents; rollback plan to route back to v1 if error rate or p95 breach thresholds."
    }
  ]
},
  "artifact-management": {
  "title": "Artifact Management Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Immutability in artifact management is best ensured by:",
      "options": [
        "Promoting by digest across environments; treat tags as pointers",
        "Editing artifacts in-place after publish",
        "Rebuilding artifacts at each promotion step",
        "Using only human-readable tags in production"
      ],
      "correctAnswer": 0,
      "additionalContext": "Digest-based promotion preserves exact bits and provenance; tags can move and are not reliable identity.",
      "keyConcepts": [
        "Immutability",
        "Digest",
        "Promotion"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Provenance and SBOMs together primarily enable:",
      "options": [
        "Faster CSS builds",
        "Traceability, vulnerability response, and audits",
        "UI theming consistency",
        "Shorter commit messages"
      ],
      "correctAnswer": 1,
      "additionalContext": "Provenance ties builds to inputs and process; SBOM lists components and licenses.",
      "keyConcepts": [
        "Provenance",
        "SBOM",
        "Audits"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why separate package registries from deploy-time artifact registries?",
      "options": [
        "They are identical and interchangeable",
        "To remove access control",
        "They have different SLAs and access patterns (build vs deploy)",
        "To avoid replication and caching"
      ],
      "correctAnswer": 2,
      "additionalContext": "Build-time package registries differ from deploy-time artifact registries; manage them with appropriate policies and SLAs.",
      "keyConcepts": [
        "Registries",
        "SLAs",
        "Access patterns"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "A correct promotion practice across environments is to:",
      "options": [
        "Rebuild binaries for each environment",
        "Change content under the same tag",
        "Delete old digests to save space only",
        "Copy or reference the same digest after checks pass"
      ],
      "correctAnswer": 3,
      "additionalContext": "Promotion should move the exact digest that passed tests and scans; never rebuild during promotion.",
      "keyConcepts": [
        "Promotion",
        "Checks",
        "Determinism"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Strong signature verification should occur:",
      "options": [
        "At deploy time with fail-closed gates",
        "Only in local development",
        "Never, to speed up deploys",
        "Only if a human approves manually"
      ],
      "correctAnswer": 0,
      "additionalContext": "Verify signatures and provenance at deploy; block rollouts when evidence is missing or invalid.",
      "keyConcepts": [
        "Signatures",
        "Verification",
        "Fail-closed"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why are tags alone insufficient as deploy identifiers?",
      "options": [
        "Tags are always unique across time",
        "Tags cannot be read by tools",
        "Tags can be mutable; digests guarantee exact content",
        "Tags require no access control"
      ],
      "correctAnswer": 2,
      "additionalContext": "Tags may move; deploy by digest to ensure the exact bits run everywhere.",
      "keyConcepts": [
        "Tags",
        "Digest",
        "Identity"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Regional mirrors and caching primarily help by:",
      "options": [
        "Increasing egress costs",
        "Reducing latency, egress, and improving resilience",
        "Avoiding access control",
        "Disabling audits"
      ],
      "correctAnswer": 1,
      "additionalContext": "Mirrors keep deploys fast and resilient during central outages and reduce network costs.",
      "keyConcepts": [
        "Mirrors",
        "Latency",
        "Resilience"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "An audit-friendly promotion record should include:",
      "options": [
        "Only the artifact name",
        "No timestamps to reduce noise",
        "A random hash unrelated to content",
        "Who promoted, when, source/target namespaces, and digest"
      ],
      "correctAnswer": 3,
      "additionalContext": "Record promotion lineage: actor, time, from/to, checks passed, and exact digest.",
      "keyConcepts": [
        "Audit trail",
        "Lineage",
        "Compliance"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design an artifact promotion pipeline from dev → staging → prod that preserves immutability and provenance. Include rollback and audit requirements.",
      "sampleStrongResponse": "Publish artifacts with SBOM and provenance; sign outputs. Promote by digest through environment namespaces after tests/scans pass. Record who/when/checks in an immutable log. Rollback by re-promoting a prior known-good digest. Enforce deploy-time signature and provenance verification (fail-closed)."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Your org experienced a &ldquo;prod tag drifted from staging&rdquo; incident. Propose controls in registries and CD to prevent this class of issue permanently.",
      "sampleStrongResponse": "Require deploy by digest in CD; block mutable tags at prod. Verify signatures and provenance at deploy. Record promotion events with actor/time/digest. Use regional mirrors for resilience. Add policy that forbids rebuilds during promotion and alerts on tag moves in prod namespaces."
    }
  ]
},
  "authentication-authorization": {
  "title": "Authentication & Authorization Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR uses ID Tokens to authorize API calls. What correction do you require?",
      "options": [
        "Allow ID Tokens for APIs to simplify flows",
        "Require Access Tokens for APIs with audience checks; keep ID Token for the client app",
        "Use refresh tokens directly on APIs for stronger security",
        "Accept any JWT as long as the signature verifies"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: Access Tokens are for APIs; ID Tokens are for identity.; Why correct: Access Tokens include audience/scope for APIs; ID Tokens identify the user to the client.; Why others are wrong: refresh tokens are not presented to APIs; any‑JWT acceptance risks confused deputy attacks.; Cursor leverage: add middleware for aud/scope; update docs; generate examples.; Acceptance checks: ID vs Access split documented; audience verified; routes enforce scopes.",
      "keyConcepts": [
        "Access Token",
        "ID Token",
        "Audience",
        "Scopes"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Tokens are long‑lived and sessions don’t rotate. What change do you require?",
      "options": [
        "Keep tokens long to reduce logins",
        "Adopt short‑lived access tokens with refresh rotation and jti checks",
        "Use a single everlasting access token per user",
        "Rotate only ID Tokens and leave access tokens as is"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: reduce blast radius with short‑lived access and RTR.; Why correct: rotation with jti prevents replay chains; shorter access lifetimes reduce risk.; Why others are wrong: long‑lived tokens increase breach impact; rotating wrong token doesn’t help.; Cursor leverage: scaffold RTR; add caches by kid; write PR acceptance checks.; Acceptance checks: access TTL short; RTR enforced; revoke path tested.",
      "keyConcepts": [
        "Refresh rotation",
        "jti",
        "TTL",
        "Blast radius"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Frontend stores tokens in localStorage. What requirement do you set?",
      "options": [
        "Keep localStorage; it’s convenient",
        "Store tokens in HTTP‑only, Secure, SameSite cookies and protect against CSRF",
        "Embed tokens in URLs for easy sharing",
        "Send tokens to the client only as base64 to hide them"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: protect tokens from XSS and CSRF.; Why correct: HTTP‑only cookies prevent JS access; SameSite and CSRF patterns mitigate forgery.; Why others are wrong: localStorage is XSS‑exposed; URLs leak; base64 is not security.; Cursor leverage: scaffold cookie config; add CSRF protection; update docs.; Acceptance checks: cookies configured; CSRF checks in place; tests green.",
      "keyConcepts": [
        "HTTP‑only cookies",
        "SameSite",
        "CSRF",
        "XSS"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Scopes are role names (e.g., admin, user) and partners have over‑broad access. What do you require?",
      "options": [
        "Keep role scopes; least privilege is too complex",
        "Move to resource‑action scopes (e.g., orders:read, refunds:create) and centralize checks",
        "Let each microservice invent its own scope names independently",
        "Grant all scopes by default and deny on incident"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: encode least privilege via resource‑action scopes.; Why correct: fine‑grained scopes reduce privilege and align to endpoints.; Why others are wrong: role names are coarse; siloed scopes drift; allow‑all is unsafe.; Cursor leverage: generate a scope matrix; add policy middleware; write PR wording for checks.; Acceptance checks: matrix approved; checks centralized; audit logs capture decisions.",
      "keyConcepts": [
        "Least privilege",
        "Scopes",
        "Policy middleware",
        "Audit"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "JWKS rotation leads to intermittent token validation failures. What guardrail do you require?",
      "options": [
        "Fetch JWKS on every request to ensure freshness",
        "Cache by kid with backoff and expiry; retry gracefully when keys rotate",
        "Disable rotation to keep keys stable",
        "Accept unsigned tokens temporarily during rotation"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: resilient key validation via kid‑aware caches.; Why correct: kid cache + backoff handles rotation safely; prevents outages.; Why others are wrong: per‑request fetch hurts reliability; no rotation is unsafe; unsigned tokens are unacceptable.; Cursor leverage: scaffold JWKS cache; add metrics and alerts; update docs.; Acceptance checks: cache hit rate stable; rotation tested; errors within budget.",
      "keyConcepts": [
        "JWKS",
        "kid",
        "Caching",
        "Backoff"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Sensitive endpoints (refunds) lack step‑up auth. What do you require?",
      "options": [
        "Trust existing sessions; refunds are rare",
        "Require step‑up auth and re‑authentication window; audit decisions and actor",
        "Add an extra confirmation dialog only",
        "Rely on support to catch fraud post‑hoc"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: step‑up for high‑risk actions.; Why correct: step‑up reduces abuse and creates audit evidence.; Why others are wrong: dialogs are not auth; post‑hoc detection is late.; Cursor leverage: scaffold step‑up flow; add audit logs; update scopes.; Acceptance checks: step‑up enforced; audits recorded; abuse rate down.",
      "keyConcepts": [
        "Step‑up authentication",
        "Audit",
        "Risk"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "APIs accept any token regardless of audience claims. What must be added?",
      "options": [
        "Accept all tokens to maximize compatibility",
        "Validate audience (aud) against the API and enforce scope checks per route",
        "Only check token expiry and ignore audience",
        "Reject tokens with refresh tokens present"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: validate audience and scopes per API.; Why correct: aud prevents token replay to the wrong API; scopes encode permissions.; Why others are wrong: ignoring aud enables confused deputy; expiry‑only is insufficient.; Cursor leverage: add audience config; route‑level scope checks; tests.; Acceptance checks: aud enforced; scope checks per route; tests pass.",
      "keyConcepts": [
        "Audience",
        "Scopes",
        "Confused deputy"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Partner integration needs machine‑to‑machine auth. What pattern do you require?",
      "options": [
        "Share a user’s refresh token with the partner",
        "Use client credentials or mTLS with scoped Access Tokens and short TTLs",
        "Let partners call with unsigned JSON payloads",
        "Reuse session cookies between services"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: use proper service credentials with scopes.; Why correct: client credentials/mTLS issue tokens for services with least privilege.; Why others are wrong: user tokens and cookies are wrong for services; unsigned payloads are insecure.; Cursor leverage: scaffold client‑credentials flow; generate policy; example requests.; Acceptance checks: tokens scoped; TTL short; logs include sub/aud.",
      "keyConcepts": [
        "Client credentials",
        "mTLS",
        "Scopes",
        "TTL"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment for securing a new payments API: token types, scopes, TTLs, JWKS caching, and audit requirements. Include measurable acceptance checks.",
      "sampleStrongResponse": "Require Access Tokens (aud=payments) with resource‑action scopes; TTL &le; 15 min; refresh rotation for browser flows. Cache JWKS by kid with backoff. Log auth decisions with sub/aud/scope/decision. Acceptance: 100% aud validated; scopes enforced per route; rotation tests green; audit logs searchable within 5 min."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a least‑privilege rollout: scope matrix, central checks, step‑up for sensitive actions, and comms. Include success metrics (e.g., over‑broad scope usage ↓ 80%).",
      "sampleStrongResponse": "Define a resource‑action scope matrix and generate policy middleware for all services. Add step‑up for refunds and admin routes. Centralize checks and audit logs. Communicate partner impact and SDK updates. Success: over‑broad scope usage ↓ 80%, auth errors &le; baseline, and incident rate for access escalation → near zero."
    }
  ]
},
  "branching-strategies": {
  "title": "Branching Strategies Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Main risk of long&ndash;lived branches as teams and codebases grow is:",
      "options": [
        "Drift and higher integration risk as divergence increases",
        "Simpler audits due to fewer commits",
        "Guaranteed faster lead time",
        "Elimination of merge conflicts over time"
      ],
      "correctAnswer": 0,
      "additionalContext": "Long&ndash;lived branches diverge from main, increasing conflict and integration risk, especially in tightly coupled code.",
      "keyConcepts": [
        "Long&ndash;lived branches",
        "Integration risk",
        "Conflict frequency"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Feature flags help reduce branching risk because they:",
      "options": [
        "Replace the need for testing altogether",
        "Allow incomplete work to merge to main safely while disabled",
        "Remove the need for code reviews",
        "Make rebase operations unnecessary"
      ],
      "correctAnswer": 1,
      "additionalContext": "Flags let teams ship code paths disabled by default, shortening branch lifetime and reducing integration pain.",
      "keyConcepts": [
        "Feature flags",
        "Risk reduction",
        "Integration cadence"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "A practical integration cadence to limit conflicts on active features is:",
      "options": [
        "Integrate at end of quarter during a freeze",
        "Integrate only when conflicts arise",
        "Integrate at least daily to keep branches current with main",
        "Avoid integrating until the feature is complete"
      ],
      "correctAnswer": 2,
      "additionalContext": "Frequent integration shortens the divergence window and reduces conflict size when they occur.",
      "keyConcepts": [
        "Integration cadence",
        "Conflict reduction",
        "Branch freshness"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Prefer creating a short&ndash;lived branch instead of only using flags when:",
      "options": [
        "The change is trivial UI copy",
        "The work is easily hidden behind a single toggle",
        "The change only affects test data",
        "The work spans risky schema or contract changes requiring isolation"
      ],
      "correctAnswer": 3,
      "additionalContext": "Risky cross&ndash;cutting changes often need isolation, incremental PRs, and explicit hardening before enabling flags.",
      "keyConcepts": [
        "Risky changes",
        "Isolation",
        "Flags vs branching"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Best practice for day&ndash;to&ndash;day feature branches is:",
      "options": [
        "Prefer small, single&ndash;purpose branches and PRs",
        "Accumulate many unrelated changes to reduce PR count",
        "Force&ndash;push shared release branches frequently",
        "Skip PRs for speed when tests pass locally"
      ],
      "correctAnswer": 0,
      "additionalContext": "Small, focused PRs improve clarity, review quality, and merge safety.",
      "keyConcepts": [
        "Small PRs",
        "Focus",
        "Review quality"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why is developing features directly on a release branch discouraged?",
      "options": [
        "It always breaks CI by design",
        "It causes divergence, cherry&ndash;pick debt, and confusion about sources of truth",
        "It prevents tagging",
        "It disables hotfix workflows automatically"
      ],
      "correctAnswer": 1,
      "additionalContext": "Release branches should stabilize a specific cut. New feature work belongs on short&ndash;lived branches against main.",
      "keyConcepts": [
        "Release branches",
        "Stabilization",
        "Cherry&ndash;pick debt"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "To reduce conflict size on a feature branch you should:",
      "options": [
        "Avoid syncing with main until ready",
        "Lock main during development",
        "Regularly rebase or merge main into the branch to stay up to date",
        "Rewrite main to match the branch"
      ],
      "correctAnswer": 2,
      "additionalContext": "Keeping branches current with main reduces the scope of conflicts and makes resolution simpler.",
      "keyConcepts": [
        "Branch freshness",
        "Rebase vs merge",
        "Conflict scope"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which naming approach improves traceability for branches?",
      "options": [
        "Random names for privacy",
        "All branches named after developers",
        "Names that omit any link to tracking systems",
        "Prefix with ticket ID and a concise description (e.g., feat/PROJ-123-short-title)"
      ],
      "correctAnswer": 3,
      "additionalContext": "Ticket&ndash;prefixed, descriptive names support searchability, auditability, and automation hooks.",
      "keyConcepts": [
        "Traceability",
        "Naming",
        "Automation"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a team policy that keeps branches short&ndash;lived. Include maximum age, integration cadence, use of flags, and merge strategy to main.",
      "sampleStrongResponse": "Set a default maximum branch age (e.g., 5 business days). Require at least daily sync with main and small PRs. Use feature flags for incomplete paths so changes can merge early. Merge to main via squash&ndash;merge after green CI and required reviews; prohibit rebasing shared branches."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a migration plan from GitFlow with long&ndash;lived branches to trunk&ndash;based development. Include risk controls, rollout phases, and success metrics.",
      "sampleStrongResponse": "Pilot trunk&ndash;based on one service with feature flags and strict CI gates. Phase 1: shrink branch lifetime, enforce small PRs, add status checks. Phase 2: add release trains if needed, create short stabilization windows, adopt tags and automated changelogs. Measure merge frequency, time&ndash;to&ndash;prod, and conflict rate; adjust guardrails as teams adapt."
    }
  ]
},
  "build-automation": {
  "title": "Build Automation Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Incremental builds primarily rely on:",
      "options": [
        "Timestamps on files to decide what to rebuild",
        "A build graph with content hashing of declared inputs and tools",
        "Manual selection of targets each run",
        "Ignoring tool versions to keep keys stable"
      ],
      "correctAnswer": 1,
      "additionalContext": "Tracking inputs → outputs across a DAG and hashing inputs (including tool versions) lets the system skip unchanged work.",
      "keyConcepts": [
        "Incremental builds",
        "Build graph",
        "Content hashing"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Stable cache keys for build steps should include:",
      "options": [
        "Only filenames without content",
        "Source digests, toolchain identifiers, env/flags that affect outputs",
        "Timestamps and CI job number",
        "Random seed to avoid collisions"
      ],
      "correctAnswer": 1,
      "additionalContext": "Cache keys must reflect all inputs to avoid collisions and enable deterministic reuse across machines.",
      "keyConcepts": [
        "Cache keys",
        "Determinism",
        "Toolchain identifiers"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "A primary benefit of a remote build cache is:",
      "options": [
        "Forcing full rebuilds for safety",
        "Storing logs only, not artifacts",
        "Tying builds to a single runner",
        "Sharing compiled results across CI agents and laptops"
      ],
      "correctAnswer": 3,
      "additionalContext": "Remote caches let teams reuse prior results across machines, cutting CI minutes and local feedback time.",
      "keyConcepts": [
        "Remote cache",
        "Reuse",
        "CI speed"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which practice unlocks maximum parallelism in builds?",
      "options": [
        "Single-threaded minifiers",
        "Global locks around package installation",
        "Graph-aware scheduling of independent nodes",
        "Serial test execution without sharding"
      ],
      "correctAnswer": 2,
      "additionalContext": "Model dependencies as a DAG and schedule independent nodes concurrently; shard long-running tests by runtime.",
      "keyConcepts": [
        "Parallelization",
        "DAG",
        "Test sharding"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Treating CI as a DAG of cacheable stages instead of shell scripts enables:",
      "options": [
        "Selective execution of only affected targets",
        "Longer queues and idle cores",
        "Hidden, ambient dependencies",
        "Unbounded network access in compile steps"
      ],
      "correctAnswer": 0,
      "additionalContext": "Pipelines modeled as graphs make dependencies explicit and allow partial, affected-only runs.",
      "keyConcepts": [
        "CI orchestration",
        "Affected-only runs",
        "Pipeline DAG"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Matrix builds are primarily used to:",
      "options": [
        "Speed up a single OS by duplicating work",
        "Hide flaky tests",
        "Validate across OS/architectures in parallel",
        "Reduce test coverage for faster runs"
      ],
      "correctAnswer": 2,
      "additionalContext": "Matrix builds fan out jobs across OS/arch combinations to catch portability issues efficiently.",
      "keyConcepts": [
        "Matrix builds",
        "Cross-platform",
        "Parallelism"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why should artifacts be promoted by digest across environments?",
      "options": [
        "It preserves exact bits and provenance; no rebuilds during promotion",
        "Digests are easier to remember than tags",
        "It guarantees rebuilds at each stage",
        "Tags are immutable everywhere"
      ],
      "correctAnswer": 0,
      "additionalContext": "Promoting by digest ensures the same artifact is used in staging and production, maintaining provenance and repeatability.",
      "keyConcepts": [
        "Promotion",
        "Digest",
        "Provenance"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "To prevent &ldquo;works on my machine&rdquo; failures, build systems should:",
      "options": [
        "Rely on developer PATH and host tools",
        "Use hermetic, containerized toolchains and block undeclared network access",
        "Skip hashing tool versions to keep caches warm",
        "Allow ambient environment variables to influence outputs"
      ],
      "correctAnswer": 1,
      "additionalContext": "Hermetic builds pin tools and remove ambient state so outputs depend only on declared inputs.",
      "keyConcepts": [
        "Hermetic builds",
        "Containers",
        "Determinism"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design a caching strategy for a large monorepo. What belongs in action keys, what should be stored remotely, and how will you pre-warm caches in CI?",
      "sampleStrongResponse": "Compute content-addressed keys from source digests, toolchain image, env flags, and fetch inputs. Store action results and final artifacts in a remote cache. Pre-warm by reusing successful pipeline caches, seeding common targets on main, and sharing cache across branches. Track hit rates and fix missing inputs that cause cache misses."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a hermetic CI pipeline as a DAG: compile, shard tests, package, SBOM/provenance/signing, and promotion. How will you measure success and enable fast rollback?",
      "sampleStrongResponse": "Model stages as cacheable nodes. Compile with network blocked; shard tests by historical runtime; package artifacts and attach SBOM and provenance; sign outputs; promote by digest only after gates pass. Success metrics: p95 PR validation time, cache hit rate, change failure rate. Rollback by promoting a prior known-good digest with recorded evidence and alerts."
    }
  ]
},
  "capacity-planning": {
  "title": "Capacity Planning Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Velocity is best used as:",
      "options": [
        "A target teams must hit",
        "A comparison metric across teams",
        "A performance rating for individuals",
        "An input for team forecasting and planning"
      ],
      "correctAnswer": 3,
      "additionalContext": "Velocity is a team-internal trend to inform forecasts; it is not a target or comparison metric.",
      "keyConcepts": [
        "Velocity",
        "Forecasting",
        "Anti patterns"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Utilization near 100% typically leads to:",
      "options": [
        "Lower cycle time and faster flow",
        "Higher wait times and queueing delays",
        "Fewer incidents",
        "More flexibility and buffer"
      ],
      "correctAnswer": 1,
      "additionalContext": "High utilization creates queues and delays; leaving buffer improves predictability.",
      "keyConcepts": [
        "Utilization",
        "Queues",
        "Predictability"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "A practical buffer for unplanned work in sprint forecasting:",
      "options": [
        "0% so we maximize commitment",
        "10&ndash;20% based on historical interrupts",
        "50% by default",
        "Only if leadership asks for it"
      ],
      "correctAnswer": 1,
      "additionalContext": "Reserve a modest buffer based on history to absorb support and discovery without frequent rollover.",
      "keyConcepts": [
        "Buffer",
        "Unplanned work",
        "Forecasting"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Forecast ranges communicate:",
      "options": [
        "Certainty of a single date",
        "A desire to avoid accountability",
        "Confidence intervals that reflect variability",
        "Only worst case scenarios"
      ],
      "correctAnswer": 2,
      "additionalContext": "Use ranges and probabilities to reflect uncertainty and set better expectations.",
      "keyConcepts": [
        "Ranges",
        "Confidence",
        "Uncertainty"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Variance in throughput or cycle time should prompt:",
      "options": [
        "Root cause exploration and scenario updates",
        "Team comparison for competition",
        "Immediate scope increase",
        "Ignoring the data to avoid churn"
      ],
      "correctAnswer": 0,
      "additionalContext": "Investigate sources of variance and update scenarios and buffers accordingly.",
      "keyConcepts": [
        "Variance",
        "Root cause",
        "Scenario updates"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Scenario planning in capacity planning means:",
      "options": [
        "Choosing one plan and sticking to it",
        "Deferring decisions until the deadline",
        "Building multiple plausible plans with triggers to switch",
        "Always picking the most optimistic plan"
      ],
      "correctAnswer": 2,
      "additionalContext": "Define best/base/worst cases with signals that indicate when to pivot between them.",
      "keyConcepts": [
        "Scenario planning",
        "Triggers",
        "Pivoting"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "How should historical velocity be combined with upcoming constraints?",
      "options": [
        "Ignore constraints if velocity is high",
        "Keep the highest observed velocity as the commitment",
        "Use the manager&rsquo;s preference",
        "Adjust forecasts for holidays, support load, and dependencies"
      ],
      "correctAnswer": 3,
      "additionalContext": "Apply known constraints and expected interrupts to adjust from historical trends.",
      "keyConcepts": [
        "Historical data",
        "Constraints",
        "Adjustments"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "A signal that a team is overcommitting in planning:",
      "options": [
        "Frequent rollover and growing WIP",
        "Stable cycle time and minimal carryover",
        "Predictable forecasts within range",
        "Consistent buffer usage without spillover"
      ],
      "correctAnswer": 0,
      "additionalContext": "Rollover and growing WIP indicate overcommitment; reduce scope and increase slice thinness.",
      "keyConcepts": [
        "Overcommitment",
        "WIP",
        "Rollover"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "You have 6 sprints of data with velocities: 22, 18, 24, 20, 21, 19. Propose a forecast range and buffer for the next sprint, and explain how you would communicate confidence.",
      "sampleStrongResponse": "Use recent range 18&ndash;24 with median near 20&ndash;21. Plan near the lower bound minus expected interrupts, e.g., 18&ndash;20 of planned work with a small buffer. Communicate as a range with confidence and assumptions, and revisit mid sprint with signals."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "A leadership date is proposed that assumes zero interrupts. Outline a scenario plan that includes triggers to tighten scope or switch tracks while maintaining quality.",
      "sampleStrongResponse": "Create base/best/worst scenarios with explicit buffers and quality guardrails. Define triggers like support ticket volume or dependency slippage to tighten scope, defer lower value items, or switch to a fallback plan. Keep quality bars enforced by CI and DoD."
    }
  ]
},
  "change-management": {
  "title": "Change Management Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Approvals vs guardrails &mdash; which is the mature stance?",
      "options": [
        "Shift routine, low&ndash;risk changes to automated guardrails; reserve approvals for high risk",
        "Require approvals for all changes regardless of risk",
        "Eliminate guardrails and rely on manager sign&ndash;off",
        "Use approvals only after incidents"
      ],
      "correctAnswer": 0,
      "additionalContext": "Mature orgs automate safety checks (&ldquo;policy&ndash;as&ndash;code&rdquo;) and retain approvals for novel or high&ndash;risk work.",
      "keyConcepts": [
        "Approvals",
        "Guardrails",
        "Policy&ndash;as&ndash;code"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Risk assessment inputs emphasized in the article?",
      "options": [
        "Impact, likelihood, detectability; consider seasonality and customer segments",
        "Aesthetics, novelty, brand color",
        "Developer preference only",
        "Cost of hardware upgrades"
      ],
      "correctAnswer": 0,
      "additionalContext": "Assess impact, likelihood, and detectability; include context like holiday traffic spikes and affected segments.",
      "keyConcepts": [
        "Risk assessment",
        "Detectability",
        "Seasonality"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Purpose of change windows?",
      "options": [
        "Concentrate staffing/comms when risk appetite is higher; keep emergency windows for true urgent work",
        "Spread staffing thinly across time",
        "Guarantee zero incidents",
        "Replace guardrails with manual reviews"
      ],
      "correctAnswer": 0,
      "additionalContext": "Change windows coordinate people and communication for planned risk, while emergency criteria avoid blanket freezes.",
      "keyConcepts": [
        "Change windows",
        "Risk appetite",
        "Emergency windows"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Communication and audit essentials for significant changes include:",
      "options": [
        "Pre&ndash;announce timelines/mitigations; keep who/what/when/why in audit trails",
        "Verbal updates only",
        "Hide impact until after rollout",
        "Delete records after success"
      ],
      "correctAnswer": 0,
      "additionalContext": "Communicate early and maintain auditability: record approvers, rationale, timing, and link to artifacts/incidents.",
      "keyConcepts": [
        "Communication plan",
        "Audit trail",
        "Stakeholders"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Change Advisory Board (CAB) usage per the article?",
      "options": [
        "Use for complex, multi&ndash;system changes; avoid for routine reversible work with strong guardrails",
        "Use for all production changes",
        "Avoid entirely",
        "Only convene after outages"
      ],
      "correctAnswer": 0,
      "additionalContext": "CABs help coordinate cross&ndash;system change; they are overkill for routine changes where guardrails suffice.",
      "keyConcepts": [
        "CAB",
        "Cross&ndash;team coordination",
        "Guardrails"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "What increases safe throughput according to the article?",
      "options": [
        "Guardrails enabling smaller, more frequent changes",
        "Bigger batches and rarer releases",
        "Eliminating monitoring during windows",
        "Unlimited parallel high&ndash;risk changes"
      ],
      "correctAnswer": 0,
      "additionalContext": "Smaller, frequent changes with automated checks reduce batch risk and increase safe throughput.",
      "keyConcepts": [
        "Throughput",
        "Batch size",
        "Guardrails"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Auditability by default means:",
      "options": [
        "Collect approvals, evidence, and outcomes in one system; link to monitoring and tickets",
        "Keep approvals separate from outcomes",
        "Store records in personal notes",
        "Only log issues, not changes"
      ],
      "correctAnswer": 0,
      "additionalContext": "Centralize change records with links to PRs, deploys, incidents, RCAs, and monitoring annotations.",
      "keyConcepts": [
        "Auditability",
        "Single source of truth",
        "Integrations"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "When replacing approvals with guardrails, teams should:",
      "options": [
        "Map risk tiers to guardrails and keep human review for high&ndash;impact or irreversible changes",
        "Remove all human review for novel changes",
        "Use guardrails only for staging",
        "Decide informally per engineer"
      ],
      "correctAnswer": 0,
      "additionalContext": "Codify risk tiers and align guardrails/approval paths; preserve human review for high&ndash;impact or irreversible changes.",
      "keyConcepts": [
        "Risk tiers",
        "Guardrails mapping",
        "Approvals"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Classify a database index addition during peak season. Propose risk tier, guardrails vs approvals, change window, and communication artifacts.",
      "sampleStrongResponse": "Risk: medium&ndash;high due to peak traffic and potential latency impact. Guardrails: tests, migration dry&ndash;run on prod&ndash;like data, capacity checks, monitoring annotations, rollback plan. Approvals: domain owner + DBA. Change window: staffed period with on&ndash;call ack. Comms: pre&ndash;announce internal impact, link to runbook and rollback triggers; update audit record with outcomes."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Design an end&ndash;to&ndash;end change record template that satisfies audit trail essentials and streamlines comms. Include how low&ndash;risk changes self&ndash;approve when guardrails pass.",
      "sampleStrongResponse": "Template fields: what/why, risk tier, guardrails evidence (tests, SLO checks, rollout/rollback plan), approvers (auto&ndash;assigned by domain), change window, monitoring annotations, links to PRs/flags/deploys, and outcomes/RCAs. Policy: if risk tier is low and all guardrails pass, auto self&ndash;approve with owner ack; otherwise require listed approvers. System auto&ndash;publishes comms to stakeholders and stores immutable logs."
    }
  ]
},
  "cloud-ides": {
  "title": "Cloud IDEs Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Latency consideration for Cloud IDEs:",
      "options": [
        "Place workspaces near users and prebuild heavy tasks",
        "Add more local plugins to reduce RTT",
        "Throttle keystrokes to match server speed",
        "Ignore latency; developer location doesn&rsquo;t matter"
      ],
      "correctAnswer": 0,
      "additionalContext": "Latency impacts typing responsiveness and debugging. Run workspaces in nearby regions and shift heavy work (builds, indexing) to prebuilds to minimize perceived lag.",
      "keyConcepts": [
        "Latency",
        "Regions",
        "Prebuilds"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Workspace isolation best aligns with:",
      "options": [
        "Shared containers for all users",
        "Per‑user isolated VMs/containers with network guardrails",
        "Mount production databases directly",
        "One workspace per organization only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Isolate user workspaces using per‑user VMs/containers, apply egress controls, and restrict privileges. This limits blast radius and meets compliance needs.",
      "keyConcepts": [
        "Isolation",
        "Egress control",
        "Least privilege"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Ephemeral environments help by:",
      "options": [
        "Accumulating unpatched tools",
        "Persisting root access across sessions",
        "Ensuring clean state on start and easy disposal",
        "Requiring manual cleanup"
      ],
      "correctAnswer": 2,
      "additionalContext": "Ephemeral workspaces start from a clean, approved image each time, reducing config drift. Persistent storage can be separate (e.g., home volume) with policies.",
      "keyConcepts": [
        "Ephemeral",
        "Golden images",
        "Drift reduction"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Policy controls in Cloud IDEs typically:",
      "options": [
        "Disable all outbound networking",
        "Ignore audit logging to reduce cost",
        "Replace code review entirely",
        "Enforce org policies (egress, secrets, extensions) as code"
      ],
      "correctAnswer": 3,
      "additionalContext": "Policy‑as‑code can enforce extensions, block risky egress, require signed images, and log actions. This complements reviews rather than replacing them.",
      "keyConcepts": [
        "Policy‑as‑code",
        "Audit logs",
        "Governance"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Secrets handling principle:",
      "options": [
        "Inject short‑lived credentials from a secrets manager",
        "Check secrets into the repo but encrypt later",
        "Store tokens in dotfiles permanently",
        "Ask users to paste secrets each session"
      ],
      "correctAnswer": 0,
      "additionalContext": "Use a secrets manager with short‑lived tokens (e.g., OIDC‑issued). Avoid committing secrets. Provide least privilege and rotate frequently.",
      "keyConcepts": [
        "Secrets manager",
        "Short‑lived tokens",
        "Least privilege"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Trade‑off vs local IDEs:",
      "options": [
        "Cloud IDEs always work offline",
        "They centralize policy and improve security but add network dependency",
        "They remove all latency",
        "They require admin rights on developer laptops"
      ],
      "correctAnswer": 1,
      "additionalContext": "Cloud IDEs improve control and consistency, but rely on network performance and availability. Offline work is limited.",
      "keyConcepts": [
        "Trade‑offs",
        "Network dependency",
        "Control"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Prebuild pipelines primarily:",
      "options": [
        "Run production workloads",
        "Throttle user CPU",
        "Prepare dependencies and index code to speed start times",
        "Disable language servers"
      ],
      "correctAnswer": 2,
      "additionalContext": "Prebuilds download dependencies, run CI‑like setup, and index code so interactive sessions are snappy.",
      "keyConcepts": [
        "Prebuilds",
        "Indexing",
        "Cold start"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Data exfiltration risk mitigation includes:",
      "options": [
        "Unlimited clipboard and port‑forwarding",
        "No monitoring of workspace actions",
        "Sharing a single SSH key across all users",
        "Egress restrictions, watermarking, and audit trails"
      ],
      "correctAnswer": 3,
      "additionalContext": "Apply DLP policies: control clipboard/port‑forwarding, restrict egress, and log activity. Use per‑user credentials with rotation.",
      "keyConcepts": [
        "DLP",
        "Egress control",
        "Audit"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design a secure Cloud IDE rollout: region selection, workspace isolation, secrets handling, and monitoring.",
      "sampleStrongResponse": "Choose regions close to users and enforce per‑user isolated workspaces with egress policies. Inject short‑lived credentials from a secrets manager via OIDC. Require signed base images and extensions allowlists. Enable comprehensive audit logs, anomaly detection, and alerting. Measure latency, time‑to‑ready, and policy violations."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Your team is migrating to Cloud IDEs. Outline a plan to keep developer experience fast while meeting compliance requirements.",
      "sampleStrongResponse": "Implement prebuilds to warm caches and index code. Place workspaces near users and autoscale. Enforce policy‑as‑code for extensions, networking, and base images; inject short‑lived secrets. Provide fallbacks for local dev when needed, and track metrics (latency, launch time, error rates, and security findings)."
    }
  ]
},
  "code-editors-vs-ides": {
  "title": "Code Editors vs IDEs Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is the core difference between a lightweight code editor and a full IDE?",
      "options": [
        "IDEs integrate debugging, refactoring, and project tooling; editors focus on editing with optional plugins",
        "Editors always include full build systems and test runners",
        "IDEs cannot be extended with plugins",
        "Editors are only for plain‑text files, not code"
      ],
      "correctAnswer": 0,
      "additionalContext": "Editors prioritize startup speed and small footprint. IDEs ship integrated debugging, refactors, test runners, and project models out of the box for deeper workflows.",
      "keyConcepts": [
        "Capability vs footprint",
        "Integration depth",
        "Extensibility"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which statement best describes typical startup performance?",
      "options": [
        "IDEs always start faster due to indexing",
        "Editors tend to start faster; IDEs may take longer due to indexing and project scanning",
        "Editors are always slower because they lack features",
        "Both are identical in startup time"
      ],
      "correctAnswer": 1,
      "additionalContext": "Indexing and heavy project models can add startup overhead in IDEs, while editors often defer work until a feature is invoked.",
      "keyConcepts": [
        "Startup time",
        "Indexing",
        "Deferred work"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "How can plugin ecosystems affect capability parity between editors and IDEs?",
      "options": [
        "Plugins rarely add significant features",
        "Plugins only change themes",
        "Rich plugin ecosystems can close capability gaps, though configuration effort may rise",
        "Plugins eliminate the need for version control"
      ],
      "correctAnswer": 2,
      "additionalContext": "With the right extensions (LSP, debugger adapters, test runners), editors can approximate IDE features but require careful setup.",
      "keyConcepts": [
        "Plugin ecosystems",
        "Configuration",
        "LSP"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a primary benefit of remote development (for example, dev containers or remote SSH) in this context?",
      "options": [
        "It guarantees zero latency",
        "It prevents any dependency drift automatically",
        "It makes local CPUs irrelevant in all cases",
        "It offloads heavy toolchains to a remote host while using a local UI"
      ],
      "correctAnswer": 3,
      "additionalContext": "Remote development centralizes toolchains and compute in a consistent environment while the editor/IDE provides the interface locally.",
      "keyConcepts": [
        "Remote dev",
        "Dev containers",
        "Consistency"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "When might a lightweight editor be preferable over an IDE for a large monorepo?",
      "options": [
        "When deep refactors across many projects are required immediately",
        "When you need built‑in database migration tools",
        "When quick edits are needed and heavy indexing would slow you down",
        "When you must compile native toolchains locally"
      ],
      "correctAnswer": 2,
      "additionalContext": "For quick, localized changes, avoiding full indexing can reduce waiting time. For large cross‑cutting changes, IDE capabilities may win.",
      "keyConcepts": [
        "Monorepos",
        "Indexing cost",
        "Edit latency"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "In which scenario does an IDE typically provide outsized benefits?",
      "options": [
        "Editing a single config file",
        "Performing large, type‑aware refactors and deep navigation in complex codebases",
        "Previewing Markdown",
        "Viewing logs only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Type‑aware navigation and refactoring tools shine in big, strongly typed codebases where correctness and consistency matter.",
      "keyConcepts": [
        "Refactors",
        "Type awareness",
        "Deep navigation"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a common risk of installing too many extensions?",
      "options": [
        "Increased CPU, memory usage, and slower startup times",
        "Lower memory usage",
        "Guaranteed stability improvements",
        "Automatic security hardening"
      ],
      "correctAnswer": 0,
      "additionalContext": "Each extension can load background processes, watchers, or parsers that add overhead. A curated set helps maintain performance.",
      "keyConcepts": [
        "Extension bloat",
        "Performance budgets",
        "Startup"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a typical trade‑off of remote development compared to fully local development?",
      "options": [
        "No need for security reviews",
        "Unlimited offline capability",
        "Zero cost for compute",
        "Potential latency and dependency on network connectivity"
      ],
      "correctAnswer": 3,
      "additionalContext": "While remote environments can be consistent and powerful, interactive tasks can feel slower on poor connections.",
      "keyConcepts": [
        "Latency",
        "Connectivity",
        "Remote trade‑offs"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Your team is deciding between an IDE‑first or editor‑plus‑plugins approach. Explain the trade‑offs and when you would recommend each.",
      "sampleStrongResponse": "Recommend an IDE for large, typed codebases where refactor safety, deep navigation, and integrated debugging reduce risk. Recommend an editor‑plus‑plugins for fast startup, lightweight machines, or polyglot teams where only a subset of features is needed. Note the setup tax for plugins and the need for extension governance. Consider remote development when local machines struggle with indexing.",
      "keyConcepts": [
        "Trade‑offs",
        "Team context",
        "Risk vs speed"
      ]
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Propose a plugin governance policy that balances capability with performance and security for your organization.",
      "sampleStrongResponse": "Define an allowlist with review criteria (maintenance cadence, permissions requested, reputation). Set performance budgets (startup time, memory) and monitor with profiling tools. Require &ldquo;least privilege&rdquo; by disabling unused capabilities. Stage updates in a pilot group before broad rollout, and document alternatives for any blocked extensions.",
      "keyConcepts": [
        "Governance",
        "Allowlist",
        "Performance budgets",
        "Security"
      ]
    }
  ]
},
  "code-reviews": {
  "title": "Code Reviews Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary goal of code reviews:",
      "options": [
        "Detect defects early and reduce risk",
        "Enforce individual style preferences",
        "Slow down delivery to catch all nits",
        "Replace testing entirely"
      ],
      "correctAnswer": 0,
      "additionalContext": "Early reviews surface issues before production when remediation costs can rise 10x–100x; they also spread knowledge.",
      "keyConcepts": [
        "Defect detection",
        "Risk reduction",
        "Knowledge sharing"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Recommended review batch size:",
      "options": [
        "Thousands of lines per PR",
        "Small, focused changes with clear intent",
        "Only one PR per quarter",
        "Massive refactors mixed with unrelated changes"
      ],
      "correctAnswer": 1,
      "additionalContext": "Smaller, focused PRs reduce cognitive load and increase feedback quality and speed.",
      "keyConcepts": [
        "Batch size",
        "Focused PRs",
        "Cognitive load"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Best review style for high‑risk, complex changes:",
      "options": [
        "Async PR review only",
        "No review if tests pass",
        "Pair review (synchronous walkthrough)",
        "Wait until after release"
      ],
      "correctAnswer": 2,
      "additionalContext": "Pairing on complex changes improves shared understanding and catches design issues earlier.",
      "keyConcepts": [
        "Pair review",
        "Complex changes",
        "Risk"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Feedback norm aligned with psychological safety:",
      "options": [
        "Gatekeep with blanket rejections",
        "Block on preference‑only comments",
        "Nitpick unrelated formatting",
        "Ask questions with rationale and offer alternatives"
      ],
      "correctAnswer": 3,
      "additionalContext": "Prefer questions and rationale (&ldquo;Could we extract this because...&rdquo;) and separate must‑fix issues from suggestions.",
      "keyConcepts": [
        "Psychological safety",
        "Feedback norms",
        "Must‑fix vs suggestions"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Useful reviewer checklist focus:",
      "options": [
        "Personal naming preferences",
        "Keyboard layout consistency",
        "Security, accessibility, performance budgets",
        "Whimsical style changes"
      ],
      "correctAnswer": 2,
      "additionalContext": "Checklists tailored to code areas (security, accessibility, performance, error handling) improve consistency.",
      "keyConcepts": [
        "Checklists",
        "Quality gates",
        "Consistency"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Expected outcomes of effective reviews:",
      "options": [
        "Longer cycle times",
        "Higher change success rate and predictable cycle time",
        "More rollbacks",
        "Less onboarding clarity"
      ],
      "correctAnswer": 1,
      "additionalContext": "Outcomes include fewer production defects, faster onboarding, and steadier delivery.",
      "keyConcepts": [
        "Outcomes",
        "Change success",
        "Cycle time"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which is an anti‑pattern in reviews?",
      "options": [
        "Rubber‑stamping large diffs without context",
        "Providing context and standards links",
        "Clarifying must‑fix vs suggestions",
        "Keeping PRs focused"
      ],
      "correctAnswer": 0,
      "additionalContext": "Avoid rubber‑stamping and preference‑only blocking; focus on risk hot spots and clarity.",
      "keyConcepts": [
        "Anti‑patterns",
        "Rubber‑stamping"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Policy‑as‑code guardrails primarily:",
      "options": [
        "Replace human reviews",
        "Measure keyboard speed",
        "Enforce security/performance policies via linters and CI",
        "Delay releases by adding manual steps"
      ],
      "correctAnswer": 3,
      "additionalContext": "Automated checks enforce standards and surface breaking changes to APIs and contracts early.",
      "keyConcepts": [
        "Policy‑as‑code",
        "Linters",
        "CI"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Describe how you would structure a reviewer checklist for a critical area (e.g., auth or data access) and how you would validate its effectiveness over time.",
      "sampleStrongResponse": "Create a short, risk‑based checklist (input validation, authz, logging, error handling, perf budgets). Track escaped defects and change failure rate; spot‑audit PRs monthly and evolve items when incidents occur."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "A teammate flags that reviews feel like gates rather than collaboration. How would you reset norms and measure improvement?",
      "sampleStrongResponse": "Run a brief workshop to align on goals and examples of constructive feedback; update PR template to separate must‑fix vs suggestions and rationale. Measure review turnaround, change success rate, and developer sentiment over 2–3 sprints."
    }
  ]
},
  "dependency-management": {
  "title": "Dependency Management Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Most dependency risk in large systems comes from:",
      "options": [
        "Only direct dependencies that we import",
        "Transitive dependencies pulled in by direct deps (blast radius)",
        "Operating system packages only",
        "Tooling unrelated to builds"
      ],
      "correctAnswer": 1,
      "additionalContext": "Transitives often hide vulnerabilities and create wide blast radius across many services.",
      "keyConcepts": [
        "Transitive risk",
        "Blast radius",
        "Graphs"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Effective triage of a CVE should prioritize:",
      "options": [
        "Package popularity",
        "Reachability and exploitability in your binaries",
        "Commit message length",
        "Team size"
      ],
      "correctAnswer": 1,
      "additionalContext": "Use reachability to see if vulnerable code paths are invoked; combine with severity and compensating controls.",
      "keyConcepts": [
        "Reachability",
        "Exploitability",
        "Triage"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "License policy enforcement should be:",
      "options": [
        "Manual and ad-hoc",
        "Performed only during annual audits",
        "Automated as policy-as-code in CI and registries",
        "Skipped for transitive dependencies"
      ],
      "correctAnswer": 2,
      "additionalContext": "Automate license allow/deny checks at PR time and publish; generate attribution for distributions.",
      "keyConcepts": [
        "Licenses",
        "Policy-as-code",
        "Attribution"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why adopt regular update cadences?",
      "options": [
        "To defer risk until the end of the year",
        "To accumulate larger, riskier upgrades",
        "To avoid all PRs for months",
        "To reduce big-bang upgrades and keep remediation fast"
      ],
      "correctAnswer": 3,
      "additionalContext": "Small, routine bumps keep systems fresh and make security fixes easier to ship.",
      "keyConcepts": [
        "Update cadence",
        "Risk reduction",
        "Remediation speed"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "When remediation must be deferred, a good practice is to:",
      "options": [
        "Accept permanent risk without record",
        "Hide the issue to avoid attention",
        "Remove attribution requirements",
        "Record a time-bound exception with owner and expiry"
      ],
      "correctAnswer": 3,
      "additionalContext": "Time-bound exceptions with approvals prevent silent, permanent risk acceptance.",
      "keyConcepts": [
        "Exceptions",
        "Governance",
        "Expiry"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "A common safe remediation path is:",
      "options": [
        "Rewrite the app immediately",
        "Ignore advisories if tests are green",
        "Backport a patch or pin to a safe minor and plan a major upgrade",
        "Remove the dependency from SBOMs only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Backports and safe pins buy time; majors get scheduled with migration guides and tests.",
      "keyConcepts": [
        "Backport",
        "Pinning",
        "Major upgrade"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Reasonable remediation SLAs often include:",
      "options": [
        "Only best-effort timelines",
        "Critical in 48–72h; high in a sprint; others via cadence",
        "No timelines for transitive issues",
        "Annual remediation only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Set clear SLAs to keep risk low while balancing team capacity.",
      "keyConcepts": [
        "SLA",
        "Risk",
        "Prioritization"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "A key metric to track dependency program effectiveness is:",
      "options": [
        "Number of stars on GitHub",
        "Lines of code changed",
        "Number of packages installed per day",
        "Remediation lead time from advisory to rollout"
      ],
      "correctAnswer": 3,
      "additionalContext": "Track how quickly advisories are triaged, fixed, tested, and rolled out across services.",
      "keyConcepts": [
        "Lead time",
        "Advisories",
        "Program metrics"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design a company-wide dependency remediation workflow: ingestion of advisories, reachability analysis, triage, PR automation, canary rollout, and exception handling.",
      "sampleStrongResponse": "Ingest advisories into a central system and map to SBOMs. Run reachability to prioritize. Auto-open PRs for safe bumps; create migration tracks for breakers. Canary critical services first behind flags. Track remediation lead time and require time-bound exceptions with owner/expiry for deferrals."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "A high-centrality library in your monorepo needs a major upgrade. Outline a plan that limits blast radius and preserves delivery: staging strategy, test strategy, and rollout.",
      "sampleStrongResponse": "Add characterization and integration tests around critical paths. Create a branch with workspace isolation; bump the library and codemods. Roll out via flags/canary to low-risk services first, then expand. Monitor error rate and p95 latency; rollback by digest if thresholds breach. Complete attribution and license checks before production."
    }
  ]
},
  "developer-productivity-tools": {
  "title": "Developer Productivity Tools Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is the primary distinction between linters and code formatters?",
      "options": [
        "Formatters detect security vulnerabilities; linters only change whitespace",
        "Linters only add colors; formatters enforce naming conventions",
        "Linters enforce rules and surface potential defects; formatters standardize code style",
        "They are interchangeable tools"
      ],
      "correctAnswer": 2,
      "additionalContext": "Linters flag probable bugs and policy violations (for example, unused variables), while formatters normalize layout so developers focus on logic, not style.",
      "keyConcepts": [
        "Linters",
        "Formatters",
        "Quality vs style"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "How do pre‑commit hooks improve consistency?",
      "options": [
        "They randomly block commits",
        "They auto‑merge branches",
        "They enforce checks (for example, lint/format) before code lands",
        "They remove tests to speed up CI"
      ],
      "correctAnswer": 0,
      "additionalContext": "Pre‑commit hooks run tooling locally (format, lint, type checks) to catch issues early and reduce churn in CI.",
      "keyConcepts": [
        "Pre‑commit",
        "Consistency",
        "Shift‑left"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "What advantage does structural code search provide over plain text search?",
      "options": [
        "It searches only comments",
        "It matches code patterns at the syntax/AST level (for example, function calls with certain arguments)",
        "It renames files automatically",
        "It replaces the need for tests"
      ],
      "correctAnswer": 1,
      "additionalContext": "Structural search understands code shapes, enabling precise queries like finding unsafe API usages versus broad text matches.",
      "keyConcepts": [
        "Structural search",
        "AST",
        "Precision"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "How do snippets and macros boost developer throughput?",
      "options": [
        "By disabling type checking",
        "By hiding errors",
        "By increasing network bandwidth",
        "By automating repetitive patterns and reducing keystrokes"
      ],
      "correctAnswer": 3,
      "additionalContext": "Reusable templates for boilerplate (for example, test skeletons) reduce friction and promote consistency.",
      "keyConcepts": [
        "Snippets",
        "Automation",
        "Consistency"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "What role do task runners (for example, npm scripts, Make, or Invoke) play?",
      "options": [
        "They replace version control",
        "They handle production incident response",
        "They provide a single entry point to common commands and workflows",
        "They automatically refactor code"
      ],
      "correctAnswer": 2,
      "additionalContext": "Task runners standardize commands like test, lint, build, and release, reducing the &ldquo;how do I run this&rdquo; learning curve.",
      "keyConcepts": [
        "Task runners",
        "Standardization",
        "DX"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why is terminal/CLI integration inside the editor/IDE useful?",
      "options": [
        "It disables environment variables",
        "It forces GUI usage only",
        "It removes the need for build tools",
        "It keeps commands, environment, and output close to the code for fast iteration"
      ],
      "correctAnswer": 3,
      "additionalContext": "An embedded terminal preserves project context and makes iterative loops (edit‑run‑test) quicker.",
      "keyConcepts": [
        "CLI",
        "Feedback loop",
        "Context switching"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "How should Prettier and ESLint typically be used together?",
      "options": [
        "Run Prettier for styling and use ESLint for rules; resolve conflicts with appropriate configs",
        "Only run ESLint and ignore formatting",
        "Run both but disable all rules",
        "Run Prettier as a linter plugin so no configuration is needed"
      ],
      "correctAnswer": 0,
      "additionalContext": "Prettier handles formatting concerns, while ESLint enforces quality and policy rules. Use configs to avoid rule overlap.",
      "keyConcepts": [
        "Prettier",
        "ESLint",
        "Tooling harmony"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a balanced policy for linter severity in CI?",
      "options": [
        "Fail CI on any warning",
        "Fail on errors while tracking warnings; escalate categories over time",
        "Ignore errors and warnings",
        "Fail only on style issues"
      ],
      "correctAnswer": 1,
      "additionalContext": "Start with errors as blockers and warnings as tracked metrics, then ratchet up standards as the codebase improves.",
      "keyConcepts": [
        "CI policy",
        "Severity",
        "Continuous improvement"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Outline a plan to roll out linters and formatters to an existing repository with minimal disruption.",
      "sampleStrongResponse": "Introduce shared configs and run tools in fix mode to create a baseline commit. Add pre‑commit hooks to prevent regressions. In CI, fail on errors and report warnings. Communicate style decisions and provide editor integration steps. Apply changes in focused batches to avoid noisy diffs and coordinate with active feature branches.",
      "keyConcepts": [
        "Migration plan",
        "Hooks",
        "Baseline commit"
      ]
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Design a productivity toolkit for a new service: specify search tools, snippets, tasks, and CI integrations that will reduce onboarding time.",
      "sampleStrongResponse": "Provide structural code search patterns for common APIs, a curated snippet set for test and handler templates, and npm scripts for dev, test, lint, and type‑check. Add a &ldquo;first‑run&rdquo; script to install dependencies and pre‑commit hooks. Document how to run everything inside the editor&rsquo;s terminal so newcomers can ship a passing change in under an hour.",
      "keyConcepts": [
        "Onboarding",
        "Toolkit",
        "Standard scripts"
      ]
    }
  ]
},
  "development-containers": {
  "title": "Development Containers Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Purpose of devcontainer.json:",
      "options": [
        "Define a reproducible containerized dev environment",
        "Store editor theme preferences only",
        "Replace CI/CD pipelines",
        "Manage production deployments"
      ],
      "correctAnswer": 0,
      "additionalContext": "The devcontainer.json describes the tools, extensions, ports, and container image/Dockerfile so every developer gets the same environment.",
      "keyConcepts": [
        "devcontainer.json",
        "Reproducibility",
        "Tooling"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Typical location of devcontainer config:",
      "options": [
        ".vscode/devcontainers.json",
        ".devcontainer/devcontainer.json",
        "devcontainers/devcontainer.yaml",
        "~/.config/devcontainer.json"
      ],
      "correctAnswer": 1,
      "additionalContext": "Editors like VS Code look for a .devcontainer directory with devcontainer.json (and optionally Dockerfile/docker‑compose) to define the environment.",
      "keyConcepts": [
        "Project layout",
        "VS Code",
        "Remote Containers"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Key benefit for onboarding speed:",
      "options": [
        "Manual per‑machine setup",
        "Rewriting code editors",
        "One‑click &ldquo;Reopen in Container&rdquo; with prebuilt tools",
        "Skipping dependency installation"
      ],
      "correctAnswer": 2,
      "additionalContext": "Preconfigured images/Dockerfiles minimize time to first PR. Prebuilds can front‑load dependency installation for even faster starts.",
      "keyConcepts": [
        "Onboarding",
        "Prebuilds",
        "Consistency"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Remote container workflow characteristic:",
      "options": [
        "All dev tools run on the host OS",
        "Local files are copied into the container once",
        "Container shares the host kernel and full host PATH",
        "Workspace is mounted; tools run inside the container"
      ],
      "correctAnswer": 3,
      "additionalContext": "Editors mount the workspace into the container so changes reflect instantly. Language servers, compilers, and CLIs run inside the container.",
      "keyConcepts": [
        "Workspace mount",
        "Tooling in container",
        "Live edits"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Volume strategy for dependency caches:",
      "options": [
        "Use a named volume to persist npm/pip caches across rebuilds",
        "Always install dependencies into the image&rsquo;s final layer",
        "Delete caches on every start to be &ldquo;clean&rdquo;",
        "Mount caches from /tmp inside the container"
      ],
      "correctAnswer": 0,
      "additionalContext": "Persistent named volumes (e.g., node_modules cache) speed up iterative development without polluting the image layers.",
      "keyConcepts": [
        "Volumes",
        "Caching",
        "Iterative dev"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Reproducibility practice in devcontainers:",
      "options": [
        "Rely on latest tags everywhere",
        "Pin base image versions and use lockfiles for dependencies",
        "Install tools manually after container starts",
        "Use environment variables only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Pin images (e.g., sha256 digests) and use package lockfiles so every developer and CI get the same toolchain.",
      "keyConcepts": [
        "Pinning",
        "Lockfiles",
        "Determinism"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "When to use remote containers vs local host tools:",
      "options": [
        "Prefer remote containers only for static websites",
        "Always use host tools regardless of requirements",
        "Use remote containers when projects demand specific OS/toolchains",
        "Remote containers are required for production only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Remote containers shine when native dependencies, compilers, or services are hard to reproduce locally. Local tools can be fine for simple stacks.",
      "keyConcepts": [
        "Native deps",
        "Toolchains",
        "Trade‑offs"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Common devcontainer.json fields:",
      "options": [
        "GPU firmware blobs, BIOS settings, kernel patches",
        "Executable installer paths for each OS",
        "IAM user creation scripts for production",
        "image/Dockerfile, features, customizations, forwardPorts"
      ],
      "correctAnswer": 3,
      "additionalContext": "Fields typically include image/Dockerfile, features, extensions, settings, mounts, postCreate/postStart commands, and forwarded ports.",
      "keyConcepts": [
        "Features",
        "Extensions",
        "Ports"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design a devcontainer for a polyglot repo (Node + Python + Postgres). Include base image strategy, features, volumes, and postCreate steps.",
      "sampleStrongResponse": "Start from a minimal base (e.g., debian-slim) or official devcontainers image. Add features for Node and Python with pinned versions; install Poetry and use a lockfile. Define a service for Postgres in compose with a named volume for data. Mount caches (npm/pip) via named volumes. Expose/forward ports, set environment variables, and run postCreate to install dependencies and prewarm caches."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Propose a plan to speed onboarding using prebuilt devcontainers and CI prebuilds while keeping environments deterministic.",
      "sampleStrongResponse": "Create prebuilt images with pinned versions and publish to an internal registry. Use CI prebuilds to install dependencies and run language server indexing. Developers use &ldquo;Reopen in Container&rdquo; to start quickly. Enforce lockfiles, digest‑pinned base images, and postCreate validation scripts. Track time‑to‑first‑PR, failure rates due to env issues, and cache hit rates."
    }
  ]
},
  "devops-philosophy": {
  "title": "DevOps Philosophy Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 24,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Core DevOps objective?",
      "options": [
        "Faster, safer delivery",
        "More meetings",
        "Quarterly releases",
        "Manual deployments"
      ],
      "correctAnswer": 0,
      "additionalContext": "DevOps optimizes delivery speed and reliability by aligning dev and ops through automation and collaboration.",
      "keyConcepts": [
        "Delivery",
        "Collaboration",
        "Automation"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Key DevOps practice for environment parity:",
      "options": [
        "Pet servers",
        "Manual config",
        "Immutable infrastructure",
        "Snowflake hosts"
      ],
      "correctAnswer": 2,
      "additionalContext": "Immutable infra ensures deployments replace rather than mutate servers, preventing drift.",
      "keyConcepts": [
        "Immutable Infra",
        "Drift"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "CI best describes:",
      "options": [
        "Compiling once a year",
        "Merging infrequently",
        "Automated build/test per change",
        "Manual QA only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Each change triggers build and tests, catching issues early and often.",
      "keyConcepts": [
        "CI",
        "Automation"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "CD focuses on:",
      "options": [
        "Long release trains",
        "Automated, reliable releases",
        "Manual approvals only",
        "Freeze windows"
      ],
      "correctAnswer": 1,
      "additionalContext": "CD automates release pipelines for consistent, low‑risk deployments.",
      "keyConcepts": [
        "CD",
        "Pipelines"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Observability provides:",
      "options": [
        "Feature flags",
        "Build caching",
        "System insights via metrics/logs/traces",
        "Static analysis"
      ],
      "correctAnswer": 2,
      "additionalContext": "Observability instruments systems to understand internal state via signals and traces.",
      "keyConcepts": [
        "Observability",
        "Telemetry"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Infrastructure as Code benefit:",
      "options": [
        "Undocumented state",
        "Drift tolerance",
        "Reproducibility and reviewability",
        "Manual hotfixes only"
      ],
      "correctAnswer": 2,
      "additionalContext": "IaC makes infra changes declarative, versioned, and reviewable like code.",
      "keyConcepts": [
        "IaC",
        "Reproducibility"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Change failure rate goal:",
      "options": [
        "As high as possible",
        "Unknown",
        "As low as possible",
        "Exactly 10%"
      ],
      "correctAnswer": 2,
      "additionalContext": "Elite DevOps performance targets low change failure rate alongside high frequency and fast recovery.",
      "keyConcepts": [
        "DORA",
        "CFR"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Deployment strategy reducing blast radius:",
      "options": [
        "Big bang",
        "All-at-once",
        "Blue/Green or Canary",
        "Manual midnight release"
      ],
      "correctAnswer": 2,
      "additionalContext": "Blue/Green and canary isolate impact and allow quick rollback.",
      "keyConcepts": [
        "Blue/Green",
        "Canary",
        "Rollback"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Name two metrics you would track to measure DevOps success and why they matter.",
      "sampleStrongResponse": "Lead time for changes and change failure rate; together reflect delivery speed and stability with direct business impact."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 4,
      "question": "Describe a rollback plan for a critical service and how you would test it.",
      "sampleStrongResponse": "Use Blue/Green with traffic switch and database safety checks; practice regular game days validating scripts and monitoring thresholds."
    }
  ]
},
  "docker-containerization": {
  "title": "Docker Containerization Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Core benefit of Docker image layers:",
      "options": [
        "Layered filesystem enables cache reuse across builds",
        "Images are single monolithic archives without diffs",
        "Layers compile into the host kernel for performance",
        "Layers are only used for UI assets"
      ],
      "correctAnswer": 0,
      "additionalContext": "Images are composed of immutable layers. Unchanged layers are reused between builds, which accelerates CI and reduces registry storage. Pinning layers improves reproducibility.",
      "keyConcepts": [
        "Image layers",
        "Caching",
        "Reproducibility"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Container isolation model:",
      "options": [
        "Hardware virtualization per container",
        "Process isolation with namespaces/cgroups on a shared kernel",
        "Only a chroot without resource controls",
        "Browser sandboxing"
      ],
      "correctAnswer": 1,
      "additionalContext": "Containers isolate processes using Linux namespaces and cgroups on a shared host kernel. This differs from VMs, which virtualize hardware via a hypervisor.",
      "keyConcepts": [
        "Namespaces",
        "cgroups",
        "Shared kernel"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Docker registries are used to:",
      "options": [
        "Force rebuilding images on every host",
        "Store only image metadata without layers",
        "Push/pull images and reference them by tags or digests",
        "Replace application package managers entirely"
      ],
      "correctAnswer": 2,
      "additionalContext": "Registries store image layers and manifests. Use tags for human‑friendly versions and digests for immutable references. Prefer digests for deploys that must be exact.",
      "keyConcepts": [
        "Registry",
        "Tags",
        "Digests"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Bridge networking and port publishing:",
      "options": [
        "Containers are directly routable on the LAN by default",
        "Mapping 8080:80 exposes container port 80 on host port 8080",
        "Publishing ports changes the container&rsquo;s internal port",
        "Bridge networking disallows container‑to‑container traffic"
      ],
      "correctAnswer": 1,
      "additionalContext": "On the default bridge network, you can map host ports to container ports (e.g., 8080:80). Service discovery within a user‑defined network uses container or service names.",
      "keyConcepts": [
        "Bridge network",
        "Port mapping",
        "Service discovery"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Multi‑arch builds with Buildx:",
      "options": [
        "Use docker buildx build --platform linux/amd64,linux/arm64 to publish a multi‑arch manifest",
        "Multi‑arch requires separate Dockerfiles per architecture",
        "Only arm64 can be targeted by Buildx",
        "Multi‑arch removes the need for testing"
      ],
      "correctAnswer": 0,
      "additionalContext": "BuildKit/Buildx can build for multiple architectures and publish a manifest list so clients pull the right image for their CPU.",
      "keyConcepts": [
        "Buildx",
        "Multi‑arch",
        "Manifest list"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Best practice for leveraging layer cache:",
      "options": [
        "Copy the entire repo before installing dependencies",
        "Disable cache to avoid stale layers",
        "Install dependencies before copying full source and pin versions",
        "Combine all steps into a single RUN to simplify"
      ],
      "correctAnswer": 2,
      "additionalContext": "Order Dockerfile steps to maximize cache hits. Install dependencies (using lockfiles) before copying the full source so frequent code changes don&rsquo;t bust earlier layers.",
      "keyConcepts": [
        "Layer cache",
        "Dockerfile ordering",
        "Pinning"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Container data persistence:",
      "options": [
        "Rely on the container writable layer for databases",
        "Always bake data into the image",
        "Restart containers to ensure data durability",
        "Use named volumes or managed storage for persistent state"
      ],
      "correctAnswer": 3,
      "additionalContext": "The writable layer is ephemeral. Use volumes or external storage for stateful data. Backups and lifecycle policies should apply to volumes, not container layers.",
      "keyConcepts": [
        "Volumes",
        "Ephemeral layers",
        "Persistence"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Docker Compose service communication:",
      "options": [
        "Requires hostnames set in /etc/hosts",
        "Requires publishing all ports to the host",
        "Uses host network by default",
        "Uses an isolated network with DNS by service name"
      ],
      "correctAnswer": 3,
      "additionalContext": "Compose creates an isolated network; services can reach each other via service names (DNS). Host port publishing isn&rsquo;t needed for internal calls.",
      "keyConcepts": [
        "Compose",
        "Isolated network",
        "DNS"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Outline a production‑ready Dockerfile for a web API: base image choice, build stages, caching strategy, non‑root user, and runtime configuration.",
      "sampleStrongResponse": "Use a small, CVE‑scanned base (e.g., distroless) and multi‑stage builds: builder stage for deps/compile, final stage with only runtime artifacts. Order steps to maximize cache with lockfiles. Run as non‑root, drop capabilities, and configure via env vars/secrets. Add healthcheck and set read‑only filesystem where possible."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Describe how you would design image distribution and provenance: tags vs digests, SBOM/signing, and rollback strategy across regions.",
      "sampleStrongResponse": "Publish images with semantic tags and deploy by immutable digests for repeatability. Generate SBOMs and sign images (e.g., Sigstore). Enforce policy that only signed images run. Roll out region by region with canaries; keep previous digests for fast rollback. Monitor pull success rates and error budgets."
    }
  ]
},
  "document-databases": {
  "title": "Document Databases Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team proposes embedding order items, shipping address, and payment summary into one document for speed. What alignment do you require before approving?",
      "options": [
        "Add global schema validation to reject any unknown fields",
        "Shard randomly to avoid hotspots regardless of access patterns",
        "Confirm single‑document atomicity and size budget; shape embeds to hot reads",
        "Create a join table to normalize everything for analytics"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: align on single‑document atomicity and document size budget tied to dominant reads.; Why correct: embedding works when the hot path is satisfied in one atomic write and the document stays within size limits.; Why others are wrong: blanket validation does not prove atomicity or fit; random sharding ignores access patterns and risks scatter‑gather; full normalization defeats the purpose of a document store for object‑centric reads.; Cursor leverage: generate a PR comment that states the atomicity boundary; add a doc‑size budget and hot‑path examples; request a one‑pager on shard‑key rationale.; Acceptance checks: atomic write scope documented; max document size stated; shard‑key aligned to dominant filters.",
      "keyConcepts": [
        "Single‑document atomicity",
        "Document size limits",
        "Access‑pattern modeling"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Customers say &ldquo;I saved but still see old totals.&rdquo; What expectation should you set and require in the PR?",
      "options": [
        "Rebuild every index to refresh query results",
        "Disable secondaries entirely to guarantee freshness",
        "Raise write concern to the fastest setting across services",
        "Set a staleness window and route must‑be‑fresh reads to the primary"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: document an agreed freshness window and route must‑be‑fresh reads to primary/causal sessions.; Why correct: secondaries can lag; expectation language prevents overpromising and clarifies when primary reads are required.; Why others are wrong: index rebuilds do not address replica lag; disabling secondaries wastes safe capacity; changing write concern does not guarantee read‑after‑write across replicas.; Cursor leverage: draft the freshness SLA text; identify primary‑only paths; add a simple lag monitor with alert thresholds.; Acceptance checks: SLA documented in code/docs; router rules updated; replica‑lag alerts configured.",
      "keyConcepts": [
        "Replica lag",
        "Freshness window",
        "Primary‑only reads"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR adds a new aggregation pipeline for a dashboard. What de‑risking request should you make before merge?",
      "options": [
        "Add indexes for every intermediate stage output to be safe",
        "Attach an EXPLAIN‑like summary and index coverage; stream stages and project only needed fields",
        "Increase cluster size temporarily to reduce risk without further checks",
        "Run the pipeline on the primary during peak to simulate worst case"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: verify plan shape and index coverage; keep the pipeline streaming and lean.; Why correct: an EXPLAIN‑like output surfaces scans/fan‑out; projecting only needed fields and ensuring index coverage keeps latency predictable.; Why others are wrong: indexing every stage inflates write cost; extra hardware hides design issues; running on primary at peak risks customer impact.; Cursor leverage: summarize the plan; flag unindexed predicates; propose a minimal index and a rollback script.; Acceptance checks: plan attached; minimal index justified; rollback path defined.",
      "keyConcepts": [
        "Aggregation pipeline",
        "Index coverage",
        "EXPLAIN/PROFILE"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team wants to duplicate product names into order documents to speed reads. What do you require to keep trust?",
      "options": [
        "Document source of truth, freshness SLA, repair job, and write‑amplification budget",
        "Guarantee all services are now strongly consistent everywhere",
        "Disable updates to product names to avoid drift",
        "Commit to removing all denormalization in the next sprint"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: denormalization needs explicit guardrails to remain trustworthy.; Why correct: defining source of truth, staleness window, repair/rebuild path, and write‑amp budget prevents silent drift and runaway costs.; Why others are wrong: global strong consistency is unrealistic; freezing updates blocks real needs; promising removal ignores the valid performance goal.; Cursor leverage: generate a short design note template; include a reconciliation job stub; estimate write‑amp and size growth.; Acceptance checks: guardrails documented; repair job owned with SLO; staleness communicated to stakeholders.",
      "keyConcepts": [
        "Denormalization",
        "Trust guardrails",
        "Repair jobs"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "After sharding, a profile page is randomly slow. What is the most likely diagnosis and first ask?",
      "options": [
        "Document size limits were exceeded; move attachments to object storage",
        "Cross‑zone network is flaky; add client retries globally",
        "Shard key misaligned with dominant filters; ask for scatter‑gather evidence and key rationale",
        "Secondaries are overloaded; route all reads to primary"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: poor shard‑key choice causes scatter‑gather and random p95 spikes.; Why correct: when the key does not match filters, queries fan out; asking for evidence and rationale drives a fix.; Why others are wrong: oversize docs hurt throughput but not random fan‑out; generic network retries mask the issue; routing to primary dodges the root cause and can overload it.; Cursor leverage: analyze query filters vs shard‑key; simulate scatter‑gather; propose alternative keys.; Acceptance checks: key rationale documented; fan‑out eliminated in EXPLAIN; p95 stabilized within budget.",
      "keyConcepts": [
        "Shard key",
        "Scatter‑gather",
        "p95 latency"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Average document size doubled due to optional fields. What is the best move to keep latency predictable?",
      "options": [
        "Accept growth; storage is cheap and performance won&rsquo;t change",
        "Create per‑field indexes to accelerate sparse lookups across the board",
        "Turn off schema validation so compression can work better",
        "Split hot sub‑objects into targeted projections and keep documents under size limits"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: keep documents lean and precompute targeted projections for hot reads.; Why correct: smaller docs improve I/O and cache hit rates; projections stabilize latency for frequent reads.; Why others are wrong: size growth hurts cache/throughput; blanket indexing increases write amp; validation does not materially change payload size.; Cursor leverage: estimate size impact; propose projection shapes; add a size budget check in CI.; Acceptance checks: doc size tracked; projections deployed; latency SLO met.",
      "keyConcepts": [
        "Document size limits",
        "Projections/materialized views",
        "Latency SLO"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR adds three new secondary indexes and writes slowed down. What review stance keeps balance?",
      "options": [
        "Keep all indexes; read speed is the only priority for dashboards",
        "Prune overlapping indexes and keep a minimal set tied to real predicates; note write cost",
        "Add shards so write slowdown will disappear without trade‑offs",
        "Move all writes to nightly windows and accept slower merges"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: curate a minimal index set that matches predicates and budgets write amp.; Why correct: each index adds write work; the smallest set that serves real queries preserves throughput.; Why others are wrong: reads‑only focus ignores OLTP needs; more shards don&rsquo;t fix per‑document write amp; batching shifts pain and risks staleness.; Cursor leverage: inspect query predicates; suggest a composite index; provide a rollback for dropped indexes.; Acceptance checks: unused indexes pruned; hot path covered by minimal index; write metrics stable.",
      "keyConcepts": [
        "Index planning",
        "Write amplification",
        "Predicate coverage"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team will refresh a materialized projection via change streams. What guardrails do you require?",
      "options": [
        "Idempotent consumers with backpressure and replay; enforce size limits",
        "Emit every change to all downstream services to be extra safe",
        "Use long TTLs so projections rarely update even after writes",
        "Disable primary reads to force all queries through projections"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: make consumers idempotent, resilient, and bounded.; Why correct: idempotency + backpressure + replay keep projections correct under retries and bursts; size checks avoid runaway growth.; Why others are wrong: broadcasting to all services creates noise and cost; long TTLs risk staleness; disabling primary reads removes a safety valve.; Cursor leverage: generate consumer skeletons with idempotency; add replay tests; create a projection size budget check.; Acceptance checks: idempotency proven in tests; replay path documented; size budget enforced.",
      "keyConcepts": [
        "Change streams",
        "Materialized projection",
        "Idempotency"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to de‑risk a new hot‑path aggregation. Include: EXPLAIN‑like summary, slow‑query budget (e.g., p95 ≤ 150 ms), minimal index coverage rationale, and a rollback plan if p95 regresses.",
      "sampleStrongResponse": "Request an EXPLAIN/PROFILE snippet for the exact match/project/sort stages and confirm there are no collection scans or cross‑shard fan‑outs. State the slow‑query budget (for example, p95 ≤ 150 ms at current QPS) and propose the smallest composite index that matches equality then range predicates. Call out write‑amplification cost and ask for a rollback toggle or script to drop the index if p95 regresses after deploy. Ask Cursor to summarize the plan, generate the index DDL and rollback, and produce a PR‑ready comment that captures the budget and acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a phased migration talk track for moving a denormalized field into a validated shape. Include add → backfill → flip → enforce → cleanup with safety checks and stakeholder comms.",
      "sampleStrongResponse": "Plan: add the new validated field and start dual‑writing; backfill existing documents in batches with pacing and error budgets; flip reads via a feature flag and verify parity on a sampled slice; enforce validators and remove writes to the legacy field; clean up the old field and monitoring. Safety: idempotent backfill, shard‑aware batching, p95 targets, and a rollback toggle to route reads back. Comms: share the freshness window, expected p95, and a blast‑radius note with support/product; confirm success by zero drift and stable p95 after flip. Ask Cursor to draft the batch plan, flags, and a stakeholder note."
    }
  ]
},
  "documentation-standards": {
  "title": "Documentation Standards Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Docs‑as‑Code emphasizes:",
      "options": [
        "Ad‑hoc wikis without reviews",
        "Versioned docs reviewed via PRs and validated by CI",
        "Docs separate from source control",
        "Handwritten notes only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Treat docs like code: versioning, reviews, and CI validation improve quality and freshness.",
      "keyConcepts": [
        "Docs‑as‑Code",
        "PR reviews",
        "CI validation"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Templates help by:",
      "options": [
        "Enforcing required sections and style",
        "Replacing all documentation",
        "Hiding ownership information",
        "Preventing updates"
      ],
      "correctAnswer": 0,
      "additionalContext": "ADRs, runbooks, and README templates ensure consistent structure and content.",
      "keyConcepts": [
        "Templates",
        "Consistency",
        "Quality"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Information architecture practice:",
      "options": [
        "Unclear ownership and nested folders without logic",
        "Random links between services",
        "Clear ownership and discoverability per system or domain",
        "One giant README for everything"
      ],
      "correctAnswer": 2,
      "additionalContext": "Link code to docs (services → READMEs, APIs → OpenAPI, ops → runbooks) with clear owners.",
      "keyConcepts": [
        "Ownership",
        "Discoverability",
        "Linking code to docs"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Governance that prevents drift:",
      "options": [
        "No review cadence",
        "Annual audits only",
        "Ongoing review cadence and freshness SLAs",
        "Delete stale docs without replacement"
      ],
      "correctAnswer": 2,
      "additionalContext": "Set owners and review cadence to keep documentation current and trustworthy.",
      "keyConcepts": [
        "Governance",
        "Freshness",
        "SLA"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Metric that indicates documentation health:",
      "options": [
        "Number of emojis used",
        "Doc freshness (time since last verified)",
        "Team size",
        "Lines of code in the repo"
      ],
      "correctAnswer": 1,
      "additionalContext": "Track freshness, coverage, and search success/time‑to‑find to improve outcomes.",
      "keyConcepts": [
        "Freshness",
        "Coverage",
        "Search success"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Linking code to docs example:",
      "options": [
        "APIs → OpenAPI specs; operations → runbooks",
        "APIs → random chat screenshots",
        "Services → unrelated blog posts",
        "Incidents → no records"
      ],
      "correctAnswer": 0,
      "additionalContext": "Make APIs discoverable through OpenAPI; operational knowledge through runbooks; services through READMEs.",
      "keyConcepts": [
        "OpenAPI",
        "Runbooks",
        "READMEs"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Policy/style linting in CI helps by:",
      "options": [
        "Blocking all documentation",
        "Automating checks for required sections and style",
        "Randomly reformatting content",
        "Replacing human review fully"
      ],
      "correctAnswer": 1,
      "additionalContext": "Linting detects missing sections and style drift early, improving quality.",
      "keyConcepts": [
        "Linting",
        "CI",
        "Quality"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Outcome of robust documentation standards:",
      "options": [
        "Increased coordination cost",
        "More blocked incidents",
        "Reduced handoff errors and faster onboarding",
        "No change to audit readiness"
      ],
      "correctAnswer": 2,
      "additionalContext": "Standards reduce handoff errors, unblock incidents, and improve compliance readiness.",
      "keyConcepts": [
        "Handoffs",
        "Onboarding",
        "Compliance"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Propose a &ldquo;docs‑as‑code&rdquo; rollout for a monorepo: templates, ownership, CI checks, and review cadence. How will you measure improvement?",
      "sampleStrongResponse": "Introduce README, runbook, and ADR templates with owners per service. Add CI linting for required sections and stale checks. Establish quarterly freshness reviews. Measure doc freshness, coverage across systems, search success rate, and mean time‑to‑find critical docs."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "An audit is upcoming. Outline a lightweight plan to achieve compliance readiness by default through documentation standards and automation.",
      "sampleStrongResponse": "Define ownership and SLAs, enforce templates, and add CI checks for required content. Link code to OpenAPI and runbooks, auto‑summarize incidents/PRs into docs, and monitor coverage/freshness dashboards. Success is smoother audits and reduced time‑to‑find during incidents."
    }
  ]
},
  "extension-ecosystems": {
  "title": "Extension Ecosystems Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a primary security risk introduced by editor/IDE extensions?",
      "options": [
        "Supply‑chain exposure if extensions have broad filesystem or network permissions",
        "Guaranteed elimination of all vulnerabilities",
        "Automatic code review of all commits",
        "Hardware isolation of the development machine"
      ],
      "correctAnswer": 0,
      "additionalContext": "Extensions may have access to files, environment variables, and network calls. Poorly vetted plugins can exfiltrate data or inject malicious code.",
      "keyConcepts": [
        "Supply chain",
        "Permissions",
        "Data exfiltration"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a good first‑pass evaluation signal when assessing an extension?",
      "options": [
        "Number of colors in its theme",
        "Presence of animated icons",
        "Maintenance cadence, clear permissions, and reputable publisher",
        "Total size of screenshots"
      ],
      "correctAnswer": 2,
      "additionalContext": "Look for an active changelog, transparent scopes/permissions, signed publishers, and community reputation before trial.",
      "keyConcepts": [
        "Evaluation",
        "Reputation",
        "Permissions"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "How can teams isolate performance issues potentially caused by extensions?",
      "options": [
        "Use built‑in profiling and extension bisect/safe‑mode to identify the culprit",
        "Install more extensions to mask the problem",
        "Ignore any slowdowns",
        "Disable the IDE entirely"
      ],
      "correctAnswer": 0,
      "additionalContext": "Many tools provide an &ldquo;extension bisect&rdquo; or safe‑mode that disables subsets of extensions to quickly find regressions.",
      "keyConcepts": [
        "Performance diagnostics",
        "Profiling",
        "Bisect"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which policy best addresses telemetry and privacy concerns with extensions?",
      "options": [
        "Allow any telemetry by default",
        "Review extension telemetry, disable unnecessary tracking, and document data flows",
        "Block all extensions regardless of function",
        "Trust publishers without review"
      ],
      "correctAnswer": 1,
      "additionalContext": "A balanced approach audits what data leaves developer machines and ensures collection aligns with company policy.",
      "keyConcepts": [
        "Telemetry",
        "Privacy",
        "Policy"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a best practice for update hygiene in an extension‑heavy environment?",
      "options": [
        "Auto‑update all extensions immediately in production",
        "Never update extensions",
        "Let each developer choose any version",
        "Stage updates with a canary group and pin versions for critical tools"
      ],
      "correctAnswer": 3,
      "additionalContext": "Staged rollouts catch regressions early. Pinning versions for critical tools prevents surprise breakages.",
      "keyConcepts": [
        "Update hygiene",
        "Staged rollout",
        "Version pinning"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is the purpose of an organization extension allowlist?",
      "options": [
        "To improve keyboard backlighting",
        "To block all development",
        "To require administrative passwords for every keystroke",
        "To approve a curated set of extensions that meet security and performance standards"
      ],
      "correctAnswer": 3,
      "additionalContext": "An allowlist defines which extensions are approved. Criteria include maintenance, permissions, and performance impact.",
      "keyConcepts": [
        "Allowlist",
        "Governance",
        "Standards"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "What principle should guide requested permissions for extensions?",
      "options": [
        "Request every permission to avoid friction",
        "Request the minimum necessary (least privilege)",
        "Avoid declaring permissions",
        "Share credentials for convenience"
      ],
      "correctAnswer": 1,
      "additionalContext": "Least privilege reduces blast radius if an extension is compromised and limits accidental data exposure.",
      "keyConcepts": [
        "Least privilege",
        "Permissions",
        "Risk reduction"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "How should teams handle extensions in remote/containerized development environments?",
      "options": [
        "Allow any extension from the public marketplace",
        "Disable all extensions always",
        "Audit container capabilities and restrict extension hosts to the project scope",
        "Run extensions as root for convenience"
      ],
      "correctAnswer": 2,
      "additionalContext": "Scope extensions to the workspace folder, avoid privileged containers, and review shared images for preinstalled plugins.",
      "keyConcepts": [
        "Remote dev",
        "Containers",
        "Scope restrictions"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a lightweight process for evaluating and approving new extensions for team use.",
      "sampleStrongResponse": "Define review criteria (publisher reputation, maintenance cadence, permissions requested, telemetry behavior). Test the extension in a sandbox project, measure startup impact, and run a brief security review. If approved, add it to the allowlist with version pinning and document configuration steps.",
      "keyConcepts": [
        "Evaluation",
        "Sandboxing",
        "Approval"
      ]
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Describe how you would detect and remediate a performance regression introduced by an extension across a large team.",
      "sampleStrongResponse": "Use profiling and the platform&rsquo;s extension bisect to confirm the culprit. Roll back or pin the previous version, notify a pilot channel, and open an upstream issue with traces. Update the allowlist with a mitigation note and monitor startup and idle CPU metrics before re‑enabling the extension broadly.",
      "keyConcepts": [
        "Regression response",
        "Pin/rollback",
        "Monitoring"
      ]
    }
  ]
},
  "feature-flags": {
  "title": "Feature Flags Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which statement correctly maps common flag types?",
      "options": [
        "Release flags gate incomplete work; ops flags toggle runtime behavior; experiment flags run A/B or multivariate tests",
        "Release flags for experiments; ops flags for A/B tests; experiment flags for incident response",
        "Ops flags hide WIP; experiment flags manage cache TTLs; release flags target cohorts",
        "All flag types are interchangeable if you log evaluations"
      ],
      "correctAnswer": 0,
      "additionalContext": "Release flags hide work&ndash;in&ndash;progress, ops flags change operational behavior, and experiment flags power A/B or multivariate tests.",
      "keyConcepts": [
        "Flag taxonomy",
        "Release",
        "Ops",
        "Experiment"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Best practice at flag creation time?",
      "options": [
        "Skip ownership to reduce process",
        "Set intent (&ldquo;release&rdquo;/&ldquo;ops&rdquo;/&ldquo;experiment&rdquo;), owner, and a remove&ndash;by date",
        "Default flags to permanent",
        "Use ad&ndash;hoc names and rely on memory"
      ],
      "correctAnswer": 1,
      "additionalContext": "Defining intent, ownership, and expiry up front prevents orphaned toggles and reduces future risk.",
      "keyConcepts": [
        "Lifecycle",
        "Ownership",
        "Expiry"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Safe default rollout pattern for a new high&ndash;risk flag?",
      "options": [
        "Flip globally immediately",
        "Target only new users worldwide",
        "Ramp from internal/staff to small percentages, then cohorts or regions",
        "Roll out by random servers without monitoring"
      ],
      "correctAnswer": 2,
      "additionalContext": "Start with staff/internal exposure, then percentage ramps or cohort/geo targeting to limit blast radius while learning.",
      "keyConcepts": [
        "Progressive delivery",
        "Targeting",
        "Blast radius"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "A &ldquo;kill switch&rdquo; for critical surfaces should:",
      "options": [
        "Depend on long cache TTLs to avoid flapping",
        "Require code redeploys to take effect",
        "Be limited to staging environments",
        "Be instantly actionable via synchronous control or fast&ndash;refresh rules"
      ],
      "correctAnswer": 3,
      "additionalContext": "High&ndash;risk flags need a rapid disable path: synchronous control plane or cached rules with short TTLs.",
      "keyConcepts": [
        "Kill switch",
        "TTL",
        "Critical paths"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is &ldquo;flag debt&rdquo; and how do you avoid it?",
      "options": [
        "Latent complexity from stale flags; schedule removal sprints and automate cleanup",
        "A list of disabled flags to never remove",
        "The number of flags flipped per day; increase to reduce debt",
        "Debt measured only by experiment variants"
      ],
      "correctAnswer": 0,
      "additionalContext": "Stale flags add branching complexity and outage risk. Track intent and expiry; remove promptly after success.",
      "keyConcepts": [
        "Flag debt",
        "Cleanup",
        "Lifecycle"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why log flag evaluations with subject/context keys?",
      "options": [
        "To eliminate the need for testing",
        "To enable audits and investigations of &ldquo;who saw what and why&rdquo;",
        "To speed up database queries",
        "To randomly sample user behavior"
      ],
      "correctAnswer": 1,
      "additionalContext": "Evaluation logs provide auditability and help explain outcomes in incidents or experiments.",
      "keyConcepts": [
        "Auditability",
        "Evaluation logs",
        "Compliance"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Governance guidance for sensitive flags (privacy, billing)?",
      "options": [
        "Single&ndash;operator control",
        "Public voting",
        "Dual control, approvals, and immutable logs",
        "Flip only during off&ndash;hours without records"
      ],
      "correctAnswer": 2,
      "additionalContext": "Sensitive flags should require stronger controls: approvals, dual control, and complete audit trails.",
      "keyConcepts": [
        "Governance",
        "Approvals",
        "Audit trail"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "When should teams coordinate a change window for flips?",
      "options": [
        "For small internal tests only",
        "Never; flips should be silent",
        "Only after an incident has occurred",
        "For large audience changes where support/comms need preparation"
      ],
      "correctAnswer": 3,
      "additionalContext": "Coordinate windows for high&ndash;impact flips so support and stakeholders are prepared.",
      "keyConcepts": [
        "Change windows",
        "Stakeholder comms",
        "Support prep"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Outline a flag lifecycle from creation to cleanup. Include owner, intent, telemetry thresholds for success, rollout plan, and a &ldquo;remove by&rdquo; date.",
      "sampleStrongResponse": "Create the flag with intent (&ldquo;release&rdquo;/&ldquo;ops&rdquo;/&ldquo;experiment&rdquo;), named owner, and remove&ndash;by date. Start with staff exposure, then ramp by percentage/cohort while tracking conversion, error rate, and p95 latency against thresholds. Maintain evaluation logs with subject/context. After success, execute a removal PR and delete targeting rules to avoid flag debt."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Design a safe rollout for a high&ndash;risk payment feature behind a flag. Describe targeting, blast radius containment, kill switch behavior, and cleanup criteria.",
      "sampleStrongResponse": "Start internal&ndash;only, then 1% of a low&ndash;risk cohort by region, ramping while SLOs hold. Enable a global emergency off switch with short TTL rule refresh. Log all evaluations with user and reason. Predefine rollback triggers (error rate, p95 latency) and halt expansion if breached. Declare success criteria (conversion, error budgets) and schedule a removal PR once thresholds are met."
    }
  ]
},
  "git-workflows": {
  "title": "Git Workflows Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which description best matches trunk&ndash;based development for high&ndash;cadence teams?",
      "options": [
        "Small, frequent merges to main behind feature flags with short&ndash;lived branches",
        "Quarterly integration from long&ndash;lived branches with manual hardening",
        "Direct pushes to main without reviews or CI",
        "Rewriting shared history via rebase to keep a perfectly linear log"
      ],
      "correctAnswer": 0,
      "additionalContext": "Trunk&ndash;based development emphasizes short&ndash;lived branches, continuous integration, and flags so incomplete work ships safely behind toggles.",
      "keyConcepts": [
        "Trunk&ndash;based",
        "Short&ndash;lived branches",
        "Feature flags",
        "Continuous integration"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "When is a GitFlow&ndash;style workflow typically the better organizational fit?",
      "options": [
        "Startups shipping many times per day with minimal ceremonies",
        "Programs with fixed release trains and formal stabilization windows",
        "Teams that never tag releases or maintain changelogs",
        "Teams that avoid hotfixes and rely only on flags"
      ],
      "correctAnswer": 1,
      "additionalContext": "GitFlow supports release branches, audits, and planned stabilization windows; it suits regulated programs and scheduled releases.",
      "keyConcepts": [
        "GitFlow",
        "Release branches",
        "Stabilization",
        "Auditability"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Safe guidance for merge vs rebase in shared repositories is:",
      "options": [
        "Always rebase all shared branches to keep history linear",
        "Always squash&ndash;merge into main to hide history",
        "Rebase private branches; merge into shared branches to preserve integration context",
        "Avoid merge commits entirely across the organization"
      ],
      "correctAnswer": 2,
      "additionalContext": "Rebase on private branches is safe. Merging into shared branches preserves integration context and avoids rewriting public history.",
      "keyConcepts": [
        "Rebase",
        "Merge",
        "Shared history",
        "Integration context"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Semantic versioning communicates impact as &ldquo;MAJOR.MINOR.PATCH&rdquo;. Which statement aligns with this?",
      "options": [
        "MAJOR adds features; MINOR breaks APIs; PATCH redesigns history",
        "MAJOR/MINOR/PATCH are interchangeable labels",
        "PATCH is for experimental features behind flags only",
        "MAJOR signals breaking changes; MINOR adds features; PATCH fixes bugs"
      ],
      "correctAnswer": 3,
      "additionalContext": "SemVer sets expectations: breaking changes (MAJOR), backward&ndash;compatible features (MINOR), and bug fixes (PATCH).",
      "keyConcepts": [
        "SemVer",
        "Tags",
        "Change visibility"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "What CI policy best supports trunk&ndash;based development?",
      "options": [
        "Run checks on PRs and on merges to main; require green status checks before merge",
        "Run CI only on nightly schedules to save capacity",
        "Allow direct pushes to main if tests pass locally",
        "Skip tests for small PRs to optimize reviewer time"
      ],
      "correctAnswer": 0,
      "additionalContext": "Status checks on PRs and post&ndash;merge catches regressions early and keeps main always releasable.",
      "keyConcepts": [
        "CI gates",
        "Status checks",
        "Always&ndash;green main"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary purpose of a release branch prior to shipping is to:",
      "options": [
        "Begin large new feature work",
        "Stabilize a cut of main with targeted fixes and sign&ndash;off",
        "Replace tagging and changelogs entirely",
        "Rewrite history to simplify the log"
      ],
      "correctAnswer": 1,
      "additionalContext": "Release branches capture a specific cut for final fixes, docs, and validation before tagging and delivery.",
      "keyConcepts": [
        "Release branches",
        "Stabilization",
        "Hardening"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "A pragmatic mainline history policy for feature branches is to:",
      "options": [
        "Enforce fast&ndash;forward merges only across all repos",
        "Allow rebasing of shared release branches for a linear graph",
        "Squash&ndash;merge feature branches to keep main concise and track detail in PRs",
        "Avoid PRs and push directly to main to reduce overhead"
      ],
      "correctAnswer": 2,
      "additionalContext": "Squash&ndash;merging keeps main readable while preserving full detail in the PR conversation and branch history.",
      "keyConcepts": [
        "Squash merge",
        "Mainline history",
        "PR detail"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "To avoid &ldquo;lost fix&rdquo; incidents when hotfixing a release branch, the team should:",
      "options": [
        "Patch the release branch only and close the PR",
        "Patch main only and hope the next release picks it up",
        "Rebase main onto the release branch after every hotfix",
        "Backport to the release branch and forward&ndash;merge to main, then tag"
      ],
      "correctAnswer": 3,
      "additionalContext": "Always forward&ndash;merge hotfixes applied to a release branch back to main so fixes persist in future releases.",
      "keyConcepts": [
        "Backport",
        "Forward merge",
        "Hotfix policy"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Propose a merge policy for release branches that prevents &ldquo;lost fix&rdquo; incidents. Include backport/forward&ndash;merge rules, tagging, and changelog automation.",
      "sampleStrongResponse": "Use a stabilization branch per release. All critical fixes: (1) merge to the release branch, (2) immediately forward&ndash;merge the same commit to main, (3) tag once sign&ndash;off passes. Automate changelog generation from PR titles that carry SemVer intent (&ldquo;major&rdquo;/&ldquo;minor&rdquo;/&ldquo;patch&rdquo;). Rebase allowed only on private feature branches; shared branches use merges."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Design CI triggers and protections for a trunk&ndash;based repository. Specify PR checks, required statuses, branch protections, and how tags integrate with releases.",
      "sampleStrongResponse": "Require status checks (tests, linters, security scans) on every PR and on merges to main; block merge unless all checks are green. Enable branch protection with required reviews and linear history via squash&ndash;merge. Tag from the release commit and publish artifacts; use automated changelogs derived from PR titles. Keep main always releasable by using feature flags for incomplete work."
    }
  ]
},
  "graph-databases": {
  "title": "Graph Databases Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Design proposes a friend‑of‑friend feature. What baseline ask ensures traversals stay predictable at scale?",
      "options": [
        "Start from a selective label+property index and cap hop depth",
        "Enable cross‑partition scans to discover more connections",
        "Remove uniqueness constraints so merges are easier",
        "Increase instance size and let the planner explore freely"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: selective starts and hop caps keep p95 stable.; Why correct: a tight starting set and capped depth bound the search and cost.; Why others are wrong: cross‑partition scans explode fan‑out; dropping constraints invites duplicates; bigger boxes hide plan issues.; Cursor leverage: produce an EXPLAIN/PROFILE summary; flag start cardinality; suggest a depth cap with weights.; Acceptance checks: selective index defined; hop cap documented; p95 budget stated.",
      "keyConcepts": [
        "Selective start",
        "Hop cap",
        "p95 latency"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "A deep path query (5+ hops) is slow and flaky. What is the best TAM‑lens guidance?",
      "options": [
        "Precompute a projection/materialized subgraph for the hot path and route reads there",
        "Double the cluster size so long traversals complete in time",
        "Remove all filters to avoid index lookups",
        "Switch to SQL joins for anything over two hops"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: precompute busy routes into a projection.; Why correct: projections stabilize latency and cost for repeated paths.; Why others are wrong: scaling hardware does not bound search; removing filters broadens search; blanket switching to SQL misfits relationship queries.; Cursor leverage: generate a projection definition and refresh schedule; add a freshness SLA; produce routing notes.; Acceptance checks: projection built; freshness window documented; hot query routed to projection.",
      "keyConcepts": [
        "Projections",
        "Freshness window",
        "Traversal budget"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Fraud team flags random latency spikes tied to a few high‑degree accounts. What should you require?",
      "options": [
        "A hot‑node analysis and mitigations like uniqueness scopes, caps, or neighborhood summaries",
        "Broader traversals so the spikes average out",
        "Relaxed timeouts to avoid errors during peaks",
        "Global consistency so all traversals see the same data"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: identify hot hubs and mitigate fan‑out.; Why correct: high‑degree nodes cause explosive paths; caps and summaries bound cost.; Why others are wrong: broader traversals increase cost; longer timeouts hide problems; consistency settings don&rsquo;t solve fan‑out.; Cursor leverage: detect high‑degree nodes; propose caps and summaries; add alerts on per‑node QPS.; Acceptance checks: hot nodes listed; mitigations merged; p95 improved under load.",
      "keyConcepts": [
        "High‑degree nodes",
        "Fan‑out",
        "Mitigations"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR adds a MATCH with variable‑length patterns. What review stance keeps risk low?",
      "options": [
        "Require EXPLAIN/PROFILE, uniqueness rules, and a max traversal depth",
        "Prefer unlimited expansion for completeness",
        "Turn off indexes temporarily to test raw traversal speed",
        "Delay code review until after production metrics are available"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: verify plan, uniqueness, and depth bounds before merge.; Why correct: variable lengths can explode; the plan and rules keep search tight.; Why others are wrong: unlimited expansions risk outages; disabling indexes is not realistic; waiting for prod metrics is unsafe.; Cursor leverage: summarize plan; point out missing uniqueness; suggest a safe depth cap.; Acceptance checks: EXPLAIN attached; uniqueness set; depth cap enforced in code.",
      "keyConcepts": [
        "Variable‑length patterns",
        "Uniqueness",
        "EXPLAIN/PROFILE"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Product suggests building recommendations directly with 4‑hop traversals. What expectation should you set?",
      "options": [
        "Define a traversal budget (hops/time) and relevance weights; precompute common results",
        "Allow arbitrary hops so recall is maximized",
        "Use cross‑partition breadth‑first searches for completeness",
        "Guarantee identical results to the data warehouse aggregations"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: align on traversal and time budgets with explainable weighting.; Why correct: budgets and weights keep latency predictable and results relevant.; Why others are wrong: arbitrary hops and cross‑partition BFS blow up cost; exact equality with warehouse is unrealistic and unnecessary.; Cursor leverage: draft a budget doc; generate Cypher/Gremlin with weights; add a projection plan.; Acceptance checks: hop/time budget approved; weights documented; p95 and CTR targets set.",
      "keyConcepts": [
        "Traversal budget",
        "Weights/filters",
        "Projections"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Analytics asks to run wide ad‑hoc joins over the graph for daily reporting. What guidance keeps the stack fit‑for‑purpose?",
      "options": [
        "Route heavy tabular aggregations to the warehouse; keep the graph for relationship queries",
        "Mirror the entire graph into SQL daily and drop the graph",
        "Add more edges so joins are faster",
        "Raise request timeouts so long joins can finish"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: send tabular analytics to the warehouse, keep graph for relationships.; Why correct: warehouses excel at scans/aggregations; graphs at traversals.; Why others are wrong: mirroring then dropping misuses both; more edges worsen write cost; longer timeouts hide misfit.; Cursor leverage: produce guidance on which workloads go where; add a pipeline stub; draft PR language.; Acceptance checks: workload split documented; pipeline defined; graph queries scoped to relationships.",
      "keyConcepts": [
        "Workload split",
        "Warehouse vs graph",
        "Query fit"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Org permissions look wrong after a reorg. What&rsquo;s your first verification step?",
      "options": [
        "Check ingestion lag and failed edge upserts; reconcile affected subgraphs",
        "Disable caching layers so results are truly fresh",
        "Increase hop limits to ensure distant managers are included",
        "Add retries to writes and hope consistency improves"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: verify freshness and data integrity of edges.; Why correct: reorgs require timely edge updates; fixing ingestion restores correctness.; Why others are wrong: disabling caches may not help stale edges; more hops add noise; retries don&rsquo;t fix missing data.; Cursor leverage: generate a reconciliation query; list failed upserts; produce a rebuild script for the subgraph.; Acceptance checks: lag cleared; edges reconciled; sampled audits pass.",
      "keyConcepts": [
        "Ingestion lag",
        "Edge reconciliation",
        "Permissions"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR proposes removing label+property indexes to speed writes. What trade‑off do you insist be documented?",
      "options": [
        "Starting sets will broaden, increasing traversal cost; define the slow‑query budget and risk",
        "Reads will always be wrong until caches warm",
        "Write cost will drop to zero regardless of workload",
        "Consistency levels will automatically improve"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: removing selective indexes broadens start sets and raises traversal cost.; Why correct: bounded starts are key to predictable hops/time; budgets must be re‑aligned.; Why others are wrong: caches don&rsquo;t determine correctness here; write cost never drops to zero; consistency is unrelated.; Cursor leverage: summarize EXPLAIN before/after; estimate p95 impact; draft the risk note in PR.; Acceptance checks: budget updated; impact quantified; escalation/rollback path captured.",
      "keyConcepts": [
        "Selective index",
        "Traversal cost",
        "Budget alignment"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to de‑risk a MATCH with variable‑length patterns. Include: EXPLAIN/PROFILE summary, traversal budget (e.g., max 3 hops or 200 ms), uniqueness rule, selective start, and rollback if p95 regresses.",
      "sampleStrongResponse": "Ask for PROFILE on the exact MATCH and confirm the start set uses a label+property index. Require a uniqueness mode and a max depth (for example, 3 hops or 200 ms). State the slow‑query budget and propose a projection if results are reused. Provide a rollback toggle to cap depth in production if p95 regresses. Ask Cursor to generate the EXPLAIN summary and PR‑ready acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a phased migration talk track to introduce a new relationship type across the org graph. Include add → backfill → flip → enforce → cleanup, safety checks, and stakeholder comms.",
      "sampleStrongResponse": "Plan: add the new relationship type and start dual‑writing; backfill edges from authoritative sources in batches; flip reads to prefer the new type with sampled parity checks; enforce uniqueness/constraints; remove legacy relationships and code paths. Safety: shard‑aware batching, max hop/time budget, idempotent backfill, and a rollback that routes reads to legacy edges. Comms: share expected freshness window, p95 targets, and a blast‑radius note with support/security. Ask Cursor to draft Cypher/Gremlin backfill scripts, constraints, and the stakeholder note."
    }
  ]
},
  "indexing-strategies": {
  "title": "Indexing Strategies Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Endpoint lists paid orders by status and created_at with ORDER BY created_at DESC LIMIT 50. What index do you require?",
      "options": [
        "A composite on (status, created_at DESC) that covers id/amount to avoid lookups",
        "An index only on created_at while scanning status in the table",
        "A functional index on lower(status) to cover all cases generically",
        "Separate indexes on status and created_at and let the optimizer merge"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: match index order to predicates and sort, cover the select list.; Why correct: equality before range enables a seek + ordered scan; covering avoids lookups.; Why others are wrong: single‑column or function‑wrapped choices lead to scans; index merge is unstable.; Cursor leverage: extract query shape; propose composite order and INCLUDE columns; show plan delta.; Acceptance checks: EXPLAIN shows seek; ORDER BY satisfied; rows read within budget.",
      "keyConcepts": [
        "Composite order",
        "Equality before range",
        "Covering index",
        "Rows read"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR adds covering indexes to every list endpoint and writes slowed down. What review stance keeps balance?",
      "options": [
        "Keep all covering indexes; dashboards matter more than writes",
        "Prune overlapping indexes; keep a minimal set tied to real predicates and budgets",
        "Add shards so write slowdowns disappear without trade‑offs",
        "Move all writes to nights so indexes don’t matter during the day"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: curate a minimal set of indexes that pay for themselves.; Why correct: each index adds write work; target hot paths and remove redundancy.; Why others are wrong: reads‑only focus ignores OLTP; more shards don’t fix per‑row index cost; timing shifts pain.; Cursor leverage: inspect predicates; suggest a canonical composite; provide a rollback for dropped indexes.; Acceptance checks: unused indexes pruned; hot paths covered; write metrics stable.",
      "keyConcepts": [
        "Write amplification",
        "Predicate coverage",
        "Pruning",
        "OLTP vs analytics"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Query uses WHERE DATE(created_at)=? AND ORDER BY created_at. What sargability fix do you require?",
      "options": [
        "Keep DATE() on the column; optimizers handle functions well now",
        "Add an index on DATE(created_at) and keep the function in predicates",
        "Rewrite to a range on created_at (>= start AND < end) so the index can seek",
        "Drop ORDER BY and sort in the client to reduce server work"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: keep predicates sargable to enable seeks.; Why correct: removing the function allows index use and ordered scans.; Why others are wrong: function‑wrapped columns defeat indexes; client sorts move cost and risk; functional indexes add complexity.; Cursor leverage: rewrite predicate; show EXPLAIN before/after; propose a composite with ORDER BY alignment.; Acceptance checks: seek confirmed; no sort operator; rows read drop.",
      "keyConcepts": [
        "Sargability",
        "Range predicates",
        "EXPLAIN",
        "ORDER BY alignment"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Multi‑tenant query filters by tenant_id = ? and updated_at BETWEEN ? AND ? with ORDER BY updated_at. What composite order do you require?",
      "options": [
        "(updated_at, tenant_id) so the range comes first for better scans",
        "(updated_at DESC) only since ORDER BY dominates everything",
        "(tenant_id) only and accept a sort later for simplicity",
        "(tenant_id, updated_at) so equality leads and range follows the selective prefix"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: lead with equality, then range to maximize selectivity.; Why correct: equality on tenant_id partitions the space; range on updated_at scans in order.; Why others are wrong: leading with range blocks equality seeks; single‑column indexes leave sorts; ORDER BY alone is insufficient.; Cursor leverage: infer shapes from code; emit canonical index order; verify with plan diff.; Acceptance checks: no sort; seek on tenant_id; predictable p95.",
      "keyConcepts": [
        "Composite index",
        "Selectivity",
        "Tenant partitioning",
        "Plan stability"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "EXPLAIN shows a scan + sort on amount for a top report. What de‑risking ask precedes merge?",
      "options": [
        "Attach EXPLAIN with rows‑read and add a minimal composite/cover to remove sort",
        "Increase hardware for the cluster to hide the latency temporarily",
        "Run the query on the primary at peak to observe worst cases live",
        "Create indexes on every stage of the pipeline to be safe"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: verify plan shape and remove wasted work.; Why correct: plan evidence + minimal index reduces rows read and sorts predictably.; Why others are wrong: hardware hides issues; peak tests risk users; indexing everything inflates writes.; Cursor leverage: summarize plan; generate DDL and rollback; write PR budget text.; Acceptance checks: plan attached; rows‑read reduced; rollback path defined.",
      "keyConcepts": [
        "Rows read",
        "Covering index",
        "Sort elimination",
        "Rollback"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "You plan to partition data by region. What index note do you require in PRs?",
      "options": [
        "Rely on partitioning alone; indexes are unnecessary on partitions",
        "Align queries to partition pruning and include the partition key in composite prefixes",
        "Avoid using the partition key in predicates to keep plans generic",
        "Create identical global indexes regardless of access patterns"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: combine partition pruning with selective prefixes.; Why correct: including the partition key enables pruning and efficient seeks within partitions.; Why others are wrong: partitions don’t replace indexes; ignoring the key defeats pruning; global clones waste cost.; Cursor leverage: detect partition predicates; suggest local index shapes; verify prune in plan.; Acceptance checks: pruning observed; seeks inside partitions; stable p95.",
      "keyConcepts": [
        "Partition pruning",
        "Composite prefixes",
        "Access patterns"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "What evidence should justify adding a new index to a hot endpoint?",
      "options": [
        "Anecdotal reports from one developer’s laptop during a demo",
        "Rows‑read reduction and p95 improvement under representative load",
        "Number of columns included to make it future‑proof",
        "Vendor recommendation without local measurements"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: add indexes only with measurable benefit.; Why correct: rows‑read and p95 deltas prove value under real distributions.; Why others are wrong: anecdotes and generic advice are unreliable; over‑wide indexes inflate writes.; Cursor leverage: run plan comparisons; capture rows‑read; write PR budget/acceptance text.; Acceptance checks: measured deltas; index size tracked; write amp within budget.",
      "keyConcepts": [
        "Evidence‑based indexing",
        "Rows read",
        "p95 latency",
        "Write amplification"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Writes regressed after adding two similar composites: (tenant_id, created_at) and (tenant_id, created_at, status). What do you require?",
      "options": [
        "Keep both because future queries might need either form",
        "Add shards so write cost disappears across nodes",
        "Consolidate to one canonical composite that matches WHERE and ORDER; drop the overlap with a rollback plan",
        "Move all writes to a nightly window and hope the pain shifts away"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: drop overlapping shapes and keep one canonical index.; Why correct: a single well‑chosen composite reduces write amp while serving predicates.; Why others are wrong: speculative indexes cost; sharding doesn’t remove per‑row index work; batching shifts pain.; Cursor leverage: suggest canonical shape; generate drop/rollback scripts; monitor write metrics.; Acceptance checks: overlap removed; hot path covered; write p95 stable.",
      "keyConcepts": [
        "Index pruning",
        "Canonical composite",
        "Write cost",
        "Rollback"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment for a new hot‑path list query: attach EXPLAIN summary, set a slow‑query budget (e.g., p95 &le; 120 ms), propose the minimal composite/cover, and include a rollback if regressions appear.",
      "sampleStrongResponse": "Ask for an EXPLAIN with rows read, operators, and sort usage. State a slow‑query budget (p95 &le; 120 ms at current QPS). Propose a composite (equality first, then range, INCLUDE select list) to eliminate scan/sort. Note write‑amp cost and add a rollback toggle and drop script if p95 regresses. Ask Cursor to generate the DDL and PR‑ready acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a phased index cleanup plan that removes redundant indexes safely. Include discovery → evidence → drop behind a flag → monitor → rollback, with comms to stakeholders.",
      "sampleStrongResponse": "Discovery: collect usage stats and overlap. Evidence: plan diffs and rows‑read vs write‑amp deltas. Drop: disable via flag or mark unused and remove with a rollback script ready. Monitor: p95, error rates, and plan hashes. Rollback on thresholds. Communicate expected impact, success criteria, and an office‑hours window for consumers."
    }
  ]
},
  "integrated-development-environments": {
  "title": "Integrated Development Environments Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What does an IDE&rsquo;s code intelligence typically provide beyond basic syntax highlighting?",
      "options": [
        "Only color themes and font rendering",
        "Type‑aware completions, symbol navigation, and inline documentation",
        "A built‑in production deployment pipeline",
        "Automatic database schema migrations"
      ],
      "correctAnswer": 1,
      "additionalContext": "Modern IDE code intelligence uses parse trees, symbol indexes, and language servers to surface context‑aware suggestions, jump‑to‑definition, and inline docs, reducing cognitive load and navigation time.",
      "keyConcepts": [
        "Code intelligence",
        "Language Server Protocol",
        "Productivity"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is a conditional breakpoint used for when debugging in an IDE?",
      "options": [
        "To always pause on every iteration",
        "To print logs without pausing execution",
        "To pause only when a specified expression evaluates to true",
        "To speed up execution by skipping lines"
      ],
      "correctAnswer": 2,
      "additionalContext": "Conditional breakpoints help isolate issues that occur only under certain states (for example, when a counter exceeds a threshold), avoiding noisy pauses and enabling focused inspection.",
      "keyConcepts": [
        "Debugger",
        "Breakpoints",
        "State inspection"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "How do IDE profilers help address performance problems?",
      "options": [
        "They enforce code style rules",
        "They provision staging environments",
        "They manage Git branches automatically",
        "They measure CPU time, memory usage, and hot paths to find bottlenecks"
      ],
      "correctAnswer": 3,
      "additionalContext": "Profilers reveal where time and memory are actually spent (hot functions, allocations, blocking calls), allowing targeted optimizations instead of guesswork.",
      "keyConcepts": [
        "Profiling",
        "CPU hotspots",
        "Memory diagnostics"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "What benefit does IDE test runner integration primarily provide?",
      "options": [
        "Run tests with focused filters, watch mode, and inline failure details",
        "Start and stop the production database",
        "Manage Kubernetes cluster scaling",
        "Generate UI wireframes automatically"
      ],
      "correctAnswer": 0,
      "additionalContext": "Tight test runner integration shortens feedback loops with quick filtering (by file, tag, or failed tests), watch re‑runs, and clickable stack traces.",
      "keyConcepts": [
        "Test runners",
        "Feedback loop",
        "Developer velocity"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is the purpose of IDE refactor tools like Rename Symbol or Extract Function?",
      "options": [
        "To obfuscate variable names for security",
        "To randomly reorder code blocks to test resilience",
        "To safely update usages across the project while preserving behavior",
        "To minify code for production"
      ],
      "correctAnswer": 2,
      "additionalContext": "Refactor tools operate on the symbol graph, updating all references consistently (for example, renaming across files) and reducing manual, error‑prone edits.",
      "keyConcepts": [
        "Refactoring",
        "Symbol graph",
        "Safety"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "In an IDE, what does the project model (workspace indexing) enable?",
      "options": [
        "Auto‑scaling of cloud infrastructure",
        "Live production feature flags",
        "Automated legal compliance reports",
        "Cross‑file navigation, find‑usages, and refactor accuracy"
      ],
      "correctAnswer": 3,
      "additionalContext": "Indexing builds a searchable map of symbols and relationships, powering accurate navigation (find usages) and safe refactors across large codebases.",
      "keyConcepts": [
        "Project model",
        "Indexing",
        "Find usages"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "How does the Language Server Protocol (LSP) relate to IDE code intelligence?",
      "options": [
        "LSP is a UI theme engine",
        "LSP standardizes how editors/IDEs request symbols, diagnostics, and completions from language servers",
        "LSP is a Git hosting protocol",
        "LSP is only for building container images"
      ],
      "correctAnswer": 1,
      "additionalContext": "LSP decouples language smarts from the editor UI. A language server provides completions, diagnostics, and definitions to any LSP‑compatible client.",
      "keyConcepts": [
        "LSP",
        "Diagnostics",
        "Completions"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "When is attaching an IDE debugger preferable to adding temporary print statements?",
      "options": [
        "When you need to inspect complex, stateful interactions and step through code paths",
        "When you only need final program output",
        "When the code runs once and cannot be paused",
        "When you are formatting code for readability only"
      ],
      "correctAnswer": 0,
      "additionalContext": "Debuggers provide granular control (step‑in, step‑over, watch expressions) to analyze state transitions that are hard to capture with ad‑hoc logs.",
      "keyConcepts": [
        "Debugger vs logs",
        "State analysis",
        "Step control"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Describe a practical workflow to diagnose a slow test suite using IDE tools.",
      "sampleStrongResponse": "Start by scoping with the IDE&rsquo;s test explorer (filter to the slowest suites by duration), then run with watch to reproduce locally. Use the built‑in profiler to capture a CPU timeline and identify hot paths (for example, expensive setup/teardown or I/O). Inspect flame graphs for repeated allocations. Add conditional breakpoints around suspected hotspots to examine state without spamming logs. Finally, verify improvements by rerunning the filtered tests and reviewing before/after timings inside the IDE.",
      "keyConcepts": [
        "Test explorer",
        "Profiling",
        "Hot path isolation"
      ]
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a safe refactor using IDE tools to extract a large code block into a function and verify correctness.",
      "sampleStrongResponse": "Use the IDE&rsquo;s Extract Function to move the block behind a clear signature with typed parameters and return value. Run &ldquo;find usages&rdquo; to confirm call sites and use Rename Symbol to align names. Execute unit tests via the IDE&rsquo;s runner and add a focused test if coverage is thin. If behavior is complex, attach the debugger and step through both the original and refactored paths with breakpoints to confirm identical state transitions.",
      "keyConcepts": [
        "Extract Function",
        "Rename Symbol",
        "Verification"
      ]
    }
  ]
},
  "key-value-stores": {
  "title": "Key-Value Stores Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team proposes using a key‑value store to speed dashboards. What alignment prevents surprise &ldquo;stale&rdquo; complaints?",
      "options": [
        "Guarantee keys always return the primary&rsquo;s latest data",
        "Define a freshness window and route must‑be‑fresh reads to the source of truth",
        "Disable TTLs so cached values persist longer",
        "Increase instance size so latency hides staleness"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: set a freshness SLA and route critical reads to the source of truth.; Why correct: caches and eventually consistent modes can serve stale values; expectations and routing prevent overpromising.; Why others are wrong: guarantees are unrealistic; disabling TTLs grows staleness; bigger boxes don&rsquo;t change correctness.; Cursor leverage: draft PR‑ready freshness language; list primary‑only paths; add a simple staleness/lag monitor.; Acceptance checks: SLA documented; routes updated; monitoring in place.",
      "keyConcepts": [
        "Freshness window",
        "Must‑be‑fresh routing",
        "Cache semantics"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Hot key drives p95 spikes. What&rsquo;s the most effective first mitigation to require?",
      "options": [
        "Key salting or sharding to spread load; add per‑key rate limits",
        "Turn off persistence so writes are faster",
        "Increase client timeouts to reduce error rates",
        "Force strong consistency globally to slow readers"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: distribute traffic and protect shards.; Why correct: salting/sharding and rate limits reduce per‑shard pressure.; Why others are wrong: disabling persistence risks data loss; longer timeouts hide issues; strong consistency globally raises latency without fixing hotspots.; Cursor leverage: detect hot keys; propose salting scheme; generate per‑key QPS dashboards.; Acceptance checks: skew reduced; rate limits applied; p95 stabilized.",
      "keyConcepts": [
        "Hot keys",
        "Salting/sharding",
        "Rate limiting"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Cache is flapping after deploys (miss → thundering herd). What playbook do you require?",
      "options": [
        "Short timeouts, request coalescing, backoff, and prewarm on release",
        "Raise TTLs across the board so keys rarely expire",
        "Remove circuit breakers so traffic flows freely",
        "Retry aggressively from clients until success"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: coalesce, back off, and prewarm to avoid stampedes.; Why correct: coordinated retries and prewarm prevent load spikes and cascading failures.; Why others are wrong: blanket TTL increases hide stale data; removing breakers risks outages; aggressive retries amplify the herd.; Cursor leverage: generate middleware snippets for coalescing; add prewarm steps; produce a release checklist.; Acceptance checks: herd rate drops; error budget protected; prewarm documented.",
      "keyConcepts": [
        "Thundering herd",
        "Request coalescing",
        "Prewarm"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team adds three GSIs for convenience. Writes slowed. What is the TAM ask that balances UX and cost?",
      "options": [
        "Keep all GSIs because reads are more important than writes",
        "Prune to a minimal index set that matches real predicates; quantify write amp",
        "Switch to eventual consistency for writes",
        "Increase shard count so write cost disappears"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: curate minimal GSIs and account for write amplification.; Why correct: each GSI adds write work; keeping only predicate‑matching ones preserves throughput.; Why others are wrong: prioritizing reads only harms OLTP; consistency modes don&rsquo;t change write amp; more shards don&rsquo;t remove per‑item index cost.; Cursor leverage: list predicate usage; propose minimal GSI set; estimate write amp and rollback.; Acceptance checks: unused GSIs dropped; hot paths covered; write metrics stable.",
      "keyConcepts": [
        "GSI/secondary index",
        "Write amplification",
        "Predicate coverage"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "&ldquo;Stale data&rdquo; reports appear after rollout. What verification and fix path do you require?",
      "options": [
        "Verify invalidation events and TTL policy; route must‑be‑fresh reads to the primary",
        "Reboot the cluster to refresh all keys in memory",
        "Disable caching across the app to guarantee correctness",
        "Force synchronous writes on every request"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: check invalidation and TTL, and route critical reads.; Why correct: most stale‑read issues stem from missing invalidations or TTLs too long; routing preserves UX where it matters.; Why others are wrong: reboots are noise; disabling cache kills performance; synchronous writes on every path overconstrains.; Cursor leverage: scan code for emit points; propose TTLs by access pattern; draft route rules.; Acceptance checks: invalidations fixed; TTLs tuned; primary routes set for critical flows.",
      "keyConcepts": [
        "Invalidation",
        "TTL policy",
        "Primary routing"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Capacity planning shows memory pressure and eviction storms. What&rsquo;s the right next step?",
      "options": [
        "Tune eviction policy and compress values; move large blobs to object storage",
        "Disable eviction so errors are obvious",
        "Turn off TTLs to reduce churn",
        "Increase client retries during storms"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: reduce memory footprint and make eviction behavior predictable.; Why correct: compression and moving blobs out reduce pressure; policy tuning stabilizes p95.; Why others are wrong: disabling eviction isn&rsquo;t supported and would fail hard; turning off TTLs increases staleness; retries amplify storms.; Cursor leverage: estimate value size savings; propose policy settings; add dashboards for eviction and memory.; Acceptance checks: eviction rate drops; p95 stabilizes; blob offload completed.",
      "keyConcepts": [
        "Eviction policy",
        "Compression",
        "Object storage"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Feature flags and counters will live in the KVS. What alignment ensures correctness and speed?",
      "options": [
        "Atomic increments and namespaced, versioned keys with clear TTLs",
        "Batch counters nightly to reduce write load",
        "Use wide keys to pack many values into one item for fewer calls",
        "Disable TTLs so flags never expire unexpectedly"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: use atomic ops and disciplined key schema.; Why correct: atomic increments keep counters correct; namespacing/versioning and TTLs enable safe rollouts.; Why others are wrong: nightly batches break real‑time; wide keys cause contention; disabling TTLs risks stale flags.; Cursor leverage: generate key naming policy; add atomic op examples; create a TTL matrix by feature.; Acceptance checks: key schema merged; atomic ops used; TTLs documented.",
      "keyConcepts": [
        "Atomic increments",
        "Key schema",
        "TTL discipline"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "New design reads via cache but writes only to the primary DB. What is your must‑have to avoid &ldquo;write then stale read&rdquo; bugs?",
      "options": [
        "Write‑through or change‑event invalidation so cache reflects updates",
        "Increase cache size so misses are rare",
        "Add retries to GET calls until the cache warms",
        "Disable the cache for all endpoints"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: keep cache coherent via write‑through or invalidation.; Why correct: without update paths, readers can serve stale data after writes.; Why others are wrong: larger caches don&rsquo;t ensure freshness; retries don&rsquo;t fix staleness; killing cache removes the benefit.; Cursor leverage: generate invalidation hooks; propose write‑through for hot keys; add tests that assert freshness after writes.; Acceptance checks: invalidation implemented; freshness tests pass; stale‑read tickets drop.",
      "keyConcepts": [
        "Write‑through",
        "Invalidation",
        "Cache coherence"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to de‑risk a cache hot path. Include: EXPLAIN‑style access summary, slow‑query budget (e.g., p95 ≤ 50 ms), minimal key schema, TTL policy, and a rollback path if hit rate or p95 regress.",
      "sampleStrongResponse": "Ask for a brief access pattern summary: key shape, value size, expected QPS, and read/write mix. State the slow‑query budget (for example, p95 ≤ 50 ms, hit rate ≥ 90%). Propose a minimal namespaced, versioned key schema and TTL policy per access pattern. Require a rollback toggle to bypass the cache if p95 or hit rate regress. Ask Cursor to draft the PR comment, key naming policy, and a small dashboard query for hit rate and p95."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a phased migration talk track to introduce a new cache namespace without downtime. Include add → backfill → flip → enforce → cleanup, safety checks, and comms.",
      "sampleStrongResponse": "Plan: add the new namespaced keys alongside legacy and start dual‑writes; backfill hot keys with a script and prewarm; flip reads via a flag and validate hit rate/p95 on a sampled cohort; enforce writes only to the new namespace; clean up legacy keys with a TTL sweep. Safety: idempotent backfill, circuit breakers, surge controls, and a rollback that routes reads/writes to legacy keys. Comms: share freshness window, p95 and hit‑rate targets, and a blast‑radius note. Ask Cursor to draft the scripts, flags, and stakeholder note."
    }
  ]
},
  "lean-startup": {
  "title": "Lean Startup Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 24,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Core loop in Lean Startup:",
      "options": [
        "Build-Measure-Learn",
        "Plan-Execute-Control",
        "Design-Implement-Test",
        "Ideate-Scale-Exit"
      ],
      "correctAnswer": 0,
      "additionalContext": "Build experiments, measure results, and learn to refine the next iteration.",
      "keyConcepts": [
        "Experimentation",
        "Feedback Loop"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "MVP stands for:",
      "options": [
        "Most Valuable Plan",
        "Minimum Viable Product",
        "Managed Vendor Product",
        "Market Validation Process"
      ],
      "correctAnswer": 1,
      "additionalContext": "MVP validates riskiest assumptions quickly with minimal investment.",
      "keyConcepts": [
        "MVP",
        "Validation"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary goal of MVP:",
      "options": [
        "Perfect UI",
        "Max features",
        "Validate assumptions quickly",
        "Full automation"
      ],
      "correctAnswer": 2,
      "additionalContext": "Focus on learning, not completeness; ship the smallest experiment that yields signal.",
      "keyConcepts": [
        "Assumptions",
        "Learning"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Actionable metrics are:",
      "options": [
        "Vanity",
        "Non‑repeatable",
        "Guide decisions",
        "Purely aesthetic"
      ],
      "correctAnswer": 2,
      "additionalContext": "They map directly to decisions (e.g., pricing change) and can be repeated.",
      "keyConcepts": [
        "Actionable Metrics",
        "Decision Making"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Pivot means:",
      "options": [
        "Stop all work",
        "Minor tweak",
        "Strategic shift based on learning",
        "Ignore data"
      ],
      "correctAnswer": 2,
      "additionalContext": "A pivot changes strategy while preserving the vision, based on validated learning.",
      "keyConcepts": [
        "Pivot",
        "Validated Learning"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Cohort analysis helps with:",
      "options": [
        "UI theming",
        "Deployment scheduling",
        "Understanding user behavior over time",
        "Randomization"
      ],
      "correctAnswer": 2,
      "additionalContext": "Tracks behavior by user cohorts to see retention and engagement patterns.",
      "keyConcepts": [
        "Cohorts",
        "Retention"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Riskiest assumption first principle:",
      "options": [
        "Build big first",
        "Test least risky",
        "Test most uncertain first",
        "Skip validation"
      ],
      "correctAnswer": 2,
      "additionalContext": "Test the assumption that would most undermine the idea if false.",
      "keyConcepts": [
        "Risk",
        "Prioritization"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Good MVP characteristic:",
      "options": [
        "Pixel‑perfect",
        "Quick to build and measure",
        "Large scope",
        "No instrumentation"
      ],
      "correctAnswer": 1,
      "additionalContext": "An MVP is quick to build and instrumented to measure outcomes.",
      "keyConcepts": [
        "Speed",
        "Instrumentation"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Describe one experiment you would run to validate a pricing hypothesis and your success metric.",
      "sampleStrongResponse": "A/B test two price points on a landing page; measure conversion to signup and downstream retention at 2 weeks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 4,
      "question": "Explain how you would decide to pivot vs persevere after two MVP iterations.",
      "sampleStrongResponse": "Compare actionable metrics to thresholds; if north‑star metric is below target with negative trend and qualitative feedback indicates mismatch, pivot with a new hypothesis."
    }
  ]
},
  "local-development-setup": {
  "title": "Local Development Setup Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Role of version managers (e.g., asdf, nvm, pyenv):",
      "options": [
        "Install multiple runtime versions and switch per project",
        "Replace package managers entirely",
        "Manage OS kernel updates",
        "Run databases in production"
      ],
      "correctAnswer": 0,
      "additionalContext": "Version managers pin language runtimes per project, improving reproducibility and avoiding global conflicts.",
      "keyConcepts": [
        "asdf",
        "nvm",
        "pyenv",
        "Reproducibility"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Reproducible setup scripts should:",
      "options": [
        "Be manual, documented in a wiki",
        "Be automated via Makefile/NPM scripts with idempotent steps",
        "Use one‑off shell commands copied from chat",
        "Be different on each laptop"
      ],
      "correctAnswer": 1,
      "additionalContext": "Automate with scripts that can be re‑run safely. Capture prerequisites, lint/format commands, and common workflows consistently.",
      "keyConcepts": [
        "Automation",
        "Idempotence",
        "Makefile/NPM scripts"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Environment variable tooling best practice:",
      "options": [
        "Commit .env files to git",
        "Hardcode secrets in source code",
        "Use templates (.env.example) and load via tooling like direnv",
        "Rely on global machine variables only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Provide an .env.example without secrets, and use tools like direnv to load env variables automatically per project. Keep secrets out of source control.",
      "keyConcepts": [
        ".env",
        "direnv",
        "Templates"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Cross‑OS caveat to watch for:",
      "options": [
        "Uniform path separators across platforms",
        "Identical native tooling across OSes",
        "Same filesystem behavior everywhere",
        "Differences in line endings and file permissions"
      ],
      "correctAnswer": 3,
      "additionalContext": "Windows vs Unix line endings, permissions, and path separators can break builds. Normalize via editorconfig, git settings, and cross‑platform scripts.",
      "keyConcepts": [
        "Line endings",
        "Permissions",
        "Paths"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Local secrets handling:",
      "options": [
        "Use a secrets manager or encrypted files (e.g., sops)",
        "Store secrets in plaintext .env committed to git",
        "Email API keys to teammates",
        "Bake secrets into binaries"
      ],
      "correctAnswer": 0,
      "additionalContext": "Prefer managers like 1Password/Keychain or encrypted files with sops/age. Provide tooling to decrypt on demand and avoid committing secrets.",
      "keyConcepts": [
        "Secrets",
        "sops",
        "Keychain"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Managing databases locally:",
      "options": [
        "Install directly on the host only",
        "Use containers or managed services for easy start/stop and isolation",
        "Share a single database across all projects",
        "Never reset state"
      ],
      "correctAnswer": 1,
      "additionalContext": "Use containers (docker compose) or lightweight managed options for local testing. Reset state with migrations/fixtures to ensure reproducibility.",
      "keyConcepts": [
        "Databases",
        "Compose",
        "Fixtures"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Consistent toolchains across OSes:",
      "options": [
        "Rely on OS‑specific docs",
        "Ask teammates for ad‑hoc help",
        "Containerize dev environments or use devcontainers",
        "Skip consistency concerns"
      ],
      "correctAnswer": 2,
      "additionalContext": "Devcontainers or Docker‑based workflows provide consistent toolchains across macOS, Linux, and Windows (via WSL).",
      "keyConcepts": [
        "Devcontainers",
        "Consistency",
        "WSL"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Speeding feedback loops locally:",
      "options": [
        "Disable caches and hot‑reload",
        "Reinstall dependencies every run",
        "Avoid using watchers",
        "Enable hot‑reload and cache deps; run focused tests"
      ],
      "correctAnswer": 3,
      "additionalContext": "Use hot‑reload, watch mode, and cached dependencies. Scope tests to changed areas and keep fixtures small for quick cycles.",
      "keyConcepts": [
        "Hot‑reload",
        "Caching",
        "Focused tests"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a local setup guide for a TypeScript monorepo: runtime/version managers, package manager, scripts, env loading, and database strategy.",
      "sampleStrongResponse": "Use asdf to pin Node and any other runtimes; commit .tool-versions. Use a single workspace package manager (e.g., pnpm) with a lockfile. Provide Make/NPM scripts for common workflows. Supply .env.example and direnv for loading vars. Run Postgres via docker compose with a named volume and seed scripts. Add lint/format/pre-commit hooks and a CI check that reproduces locally."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "How would you make a cross‑platform dev workflow reliable across macOS, Linux, and Windows (including WSL)?",
      "sampleStrongResponse": "Containerize the toolchain via devcontainers or Docker to avoid OS differences. If host tools are needed, use asdf/nvm/pyenv to pin versions. Normalize line endings via .editorconfig and git config; avoid OS‑specific paths in scripts. Use cross‑platform CLIs (e.g., shelljs, zx) and verify in CI on all OSes. Document fallbacks and add health checks for services."
    }
  ]
},
  "mob-programming": {
  "title": "Mob Programming Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Mob programming involves:",
      "options": [
        "The whole team collaborating at one keyboard with explicit roles and timeboxes",
        "Two developers working asynchronously",
        "Managers writing code with the team",
        "Solo development with periodic check‑ins"
      ],
      "correctAnswer": 0,
      "additionalContext": "Mob sessions synchronize attention and decision‑making via facilitation, roles, and timers.",
      "keyConcepts": [
        "Whole‑team",
        "Facilitation",
        "Timeboxes"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Key roles often used in mobs:",
      "options": [
        "Driver, Facilitator, Navigator(s)",
        "Scrum Master, Product Owner, Executive",
        "Only Driver and no other roles",
        "Auditor and Scribe only"
      ],
      "correctAnswer": 0,
      "additionalContext": "Driver operates the keyboard, Facilitator manages flow, Navigator(s) guide approach and architecture.",
      "keyConcepts": [
        "Driver",
        "Facilitator",
        "Navigator"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "When mobs are most beneficial:",
      "options": [
        "Architecture definition and cross‑cutting decisions",
        "Routine formatting changes",
        "Late‑night hotfixing without context",
        "Simple CSS tweaks"
      ],
      "correctAnswer": 0,
      "additionalContext": "Mobs accelerate convergence on complex, high‑impact decisions and gnarly bugs.",
      "keyConcepts": [
        "Architecture",
        "Cross‑cutting decisions",
        "Gnarly bugs"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "An expected outcome of effective mobbing:",
      "options": [
        "Reduced knowledge spread",
        "Wider knowledge spread and shared mental models",
        "Slower decisions on complex topics",
        "More rework later"
      ],
      "correctAnswer": 1,
      "additionalContext": "Collective validation reduces rework, and shared mental models increase throughput later.",
      "keyConcepts": [
        "Knowledge spread",
        "Shared models",
        "Reduced rework"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Risk to watch for in mobs and mitigation:",
      "options": [
        "Social loafing; rotate roles and keep contributions visible",
        "Excessive documentation; delete all notes",
        "Too many keyboards; add more keyboards",
        "No agenda; add more participants"
      ],
      "correctAnswer": 0,
      "additionalContext": "Timeboxed rotations and explicit contributions help maintain engagement.",
      "keyConcepts": [
        "Social loafing",
        "Rotation",
        "Engagement"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Anti‑pattern indicating a meeting smell:",
      "options": [
        "Defined agenda, outcomes, and breakout plan",
        "Undefined scope and no timeboxes",
        "Clear decision record (ADR) at the end",
        "Explicit handoffs to pairs for implementation"
      ],
      "correctAnswer": 1,
      "additionalContext": "Without agenda and timeboxes, mobs devolve into meetings. Create outcomes and breakouts.",
      "keyConcepts": [
        "Agenda",
        "Timeboxes",
        "Breakouts"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Artifact that helps post‑mob alignment:",
      "options": [
        "Unwritten verbal agreements",
        "Random chat logs",
        "Architecture Decision Records (ADRs) summarizing key decisions",
        "Private notes only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Summarize key decisions and rationale into ADRs and issue descriptions for clear handoffs.",
      "keyConcepts": [
        "ADRs",
        "Handoffs",
        "Summaries"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Good follow‑up after a mob session:",
      "options": [
        "Rotate prompts across team members to sustain engagement",
        "Forget to record decisions",
        "Delay all actions until next quarter",
        "Discard the timer and cadence"
      ],
      "correctAnswer": 0,
      "additionalContext": "Rotate prompts and actions to keep engagement high and spread ownership.",
      "keyConcepts": [
        "Rotation",
        "Engagement",
        "Ownership"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design a 60‑minute mob for diagnosing a gnarly production bug. Include roles, agenda, timeboxes, and breakout triggers. How will you capture decisions?",
      "sampleStrongResponse": "Agenda: 5m context, 20m hypothesis generation, 20m focused investigation, 10m decision, 5m next steps. Roles: Facilitator, Driver, 1–2 Navigators. Breakout when two viable paths emerge. Capture decisions and rationale in an ADR and issue with owners and due dates."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "You have to define cross‑cutting architecture for a new platform. Propose a mob plan and success metrics to justify the time investment.",
      "sampleStrongResponse": "Plan: 90‑minute mob with rotating Driver/Navigators, explicit agenda, and timeboxed spikes; follow with ADRs and pair breakouts to implement. Success: fewer rework cycles, faster convergence on decisions, improved alignment scores, and reduced incident rate due to early validation."
    }
  ]
},
  "normalization": {
  "title": "Normalization Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR duplicates customer_email in orders to avoid a join. What will you require before merge?",
      "options": [
        "Document a single source of truth; add unique on natural keys; define a freshness window; ship CDC/view with a repair job",
        "Switch to a document store and drop relational constraints for speed",
        "Disable foreign keys globally so writers are never blocked by checks",
        "Promise to remove the duplicate later without a plan or owner"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: denormalization needs trust guardrails tied to a normalized source.; Why correct: a clear source of truth with uniqueness prevents drift; CDC/materialized views serve reads without corrupting writes.; Why others are wrong: changing stores does not solve duplication risk; removing FKs hides bugs; vague promises lack safety.; Cursor leverage: draft a denorm trust note; add uniqueness/FK DDL; scaffold a CDC/view and reconciliation job.; Acceptance checks: SoT documented; uniqueness/foreign keys enforced; refresh/repair SLOs defined.",
      "keyConcepts": [
        "Denormalization",
        "Source of truth",
        "Unique constraints",
        "CDC",
        "Materialized view"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Design shows only natural keys and no surrogate primary keys. What alignment prevents duplicate entities during merges?",
      "options": [
        "Rely on natural keys only; they never change across systems",
        "Add surrogate PKs and keep unique on natural identifiers; document merge rules and dedupe paths",
        "Delay key decisions until analytics needs are clearer",
        "Drop uniqueness to keep writes fast under load"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: combine surrogate identity with business uniqueness checks.; Why correct: surrogate PKs stabilize joins while unique on natural keys prevents duplicates.; Why others are wrong: natural keys can change; delaying creates data debt; removing uniqueness invites drift.; Cursor leverage: generate PK/unique DDL; add merge/dedupe checklist; produce PR text explaining identity strategy.; Acceptance checks: surrogate PK present; unique on natural keys; merge rules documented.",
      "keyConcepts": [
        "Surrogate key",
        "Natural key",
        "Uniqueness",
        "Dedupe"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Orders table includes customer_city and customer_state copied from profile. What safeguard do you require?",
      "options": [
        "Keep derived fields permanently to simplify analytics everywhere",
        "Use triggers so many tables update the same attributes in place",
        "Eliminate the transitive dependency; reference customer; if denormed, define staleness and refresh budget",
        "Make city optional so anomalies are less likely to block writes"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: remove 3NF violations; if you denormalize, bound staleness.; Why correct: 3NF eliminates update anomalies; explicit staleness/refresh keeps copies trustworthy.; Why others are wrong: permanent duplication drifts; triggers multiply failure modes; optional fields hide bugs.; Cursor leverage: flag functional dependencies; suggest 3NF refactor; draft a projection with refresh cadence.; Acceptance checks: 3NF documented; FKs in place; projection refresh and staleness window agreed.",
      "keyConcepts": [
        "3NF",
        "Transitive dependency",
        "Foreign keys",
        "Staleness window"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Reports over OLTP are slow; proposal is to denormalize OLTP tables wholesale. What requirement keeps trust and performance?",
      "options": [
        "Replace OLTP with one wide table so joins disappear entirely",
        "Add many new OLTP indexes for BI and accept write costs",
        "Run heavy reports on the primary at peak to find worst case",
        "Serve BI from denormalized views/warehouse fed from normalized sources with refresh SLOs and keys"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: separate OLTP correctness from BI speed via projections.; Why correct: normalized OLTP protects writes; views/warehouse give fast reads with defined refresh.; Why others are wrong: a single wide table corrodes correctness; piling OLTP indexes inflates writes; running at peak risks customers.; Cursor leverage: generate a star/view DDL; add refresh schedule; outline ownership and lineage.; Acceptance checks: BI served from projections; refresh SLO stated; OLTP write SLOs stable.",
      "keyConcepts": [
        "OLTP vs OLAP",
        "Materialized views",
        "Refresh SLO",
        "Lineage"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "New normalized_address replaces legacy address_text. What migration plan do you require before rollout?",
      "options": [
        "Add → backfill → flip reads → enforce validators → cleanup with rollback toggles",
        "Flip immediately in prod and fix any fallout as tickets",
        "Delete the legacy column first to force consumers to adapt",
        "Hide the new field in UI only and hope downstream copes"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: expand→backfill→flip→enforce→cleanup for safe schema change.; Why correct: phased steps minimize outages and give rollback lines.; Why others are wrong: instant flips cause incidents; deleting first breaks contracts; UI‑only hides coupling.; Cursor leverage: scaffold migration scripts; add backfill batcher; generate PR comment with SLOs and toggles.; Acceptance checks: idempotent backfill; parity checks pass; toggle/rollback path verified.",
      "keyConcepts": [
        "Phased migration",
        "Validators",
        "Rollback",
        "Parity checks"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Multiple services write to order_totals causing drift. What guardrail do you require?",
      "options": [
        "Let each service keep its own totals and reconcile in dashboards",
        "Establish a single write path; enforce constraints; expose read‑only copies elsewhere",
        "Run a nightly cron to overwrite totals from a random source",
        "Use long cross‑service transactions to guarantee global consistency"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: one writer per fact with constraints and clear consumers.; Why correct: single write path + constraints prevent drift; consumers read without mutating.; Why others are wrong: many writers drift; crons hide bugs; global transactions add fragility.; Cursor leverage: draft ownership matrix; add CHECK/unique DDL; propose consumer projections.; Acceptance checks: write owner declared; constraints active; consumers read‑only.",
      "keyConcepts": [
        "Single source of truth",
        "Constraints",
        "Ownership",
        "Consumers"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR stores phone numbers as a comma‑separated string to avoid a join. What is your ask?",
      "options": [
        "Approve; parsing strings is simpler than modeling relations",
        "Switch to one JSON string so the shape is flexible enough",
        "Model a child table (one row per phone); enforce FK/uniqueness; document access patterns",
        "Keep a TEXT column and validate in app code only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: 1NF requires one value per field.; Why correct: a child table with FKs preserves integrity and keeps queries indexable.; Why others are wrong: strings/JSON hide structure and block indexes; app‑only checks miss drift.; Cursor leverage: suggest table DDL; add FK/unique; create query examples for common filters.; Acceptance checks: 1NF respected; FK/unique enforced; queries sargable.",
      "keyConcepts": [
        "1NF",
        "Foreign keys",
        "Uniqueness",
        "Sargability"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team proposes dropping foreign keys during peak to speed writes. What stance keeps trust?",
      "options": [
        "Drop constraints; they are optional in mature systems",
        "Rely on app‑level checks only and hope tests catch issues",
        "Drop FKs nightly and recreate them after traffic slows",
        "Keep FKs for invariants; quantify write cost; move heavy reads to projections instead of removing integrity"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: protect invariants; optimize reads without sacrificing integrity.; Why correct: FKs enforce correctness; shifting reads to projections avoids write inflation without data risk.; Why others are wrong: removing checks loses trust; app‑only checks fail silently; nightly toggles are brittle.; Cursor leverage: compute write amp of indexes; propose projections; add FK coverage tests.; Acceptance checks: integrity guaranteed; write SLOs measured; projections documented.",
      "keyConcepts": [
        "Foreign keys",
        "Integrity",
        "Projections",
        "Write amplification"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to de‑risk a hot‑path join for order summaries. Include: EXPLAIN summary, slow‑query budget (e.g., p95 &le; 150 ms), minimal index or projection rationale, and a rollback plan if p95 regresses.",
      "sampleStrongResponse": "Request an EXPLAIN plan snippet and confirm selective starts on customer/order keys with no scans or large memory grants. State a slow‑query budget (for example, p95 &le; 150 ms at current QPS) and propose the smallest composite index or a materialized view if joins are unavoidable. Call out write‑amplification and include a rollback toggle to drop the index or route reads back to the view if p95 regresses. Ask Cursor to summarize the plan, generate the DDL/view and rollback script, and produce PR‑ready acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a phased migration to move a duplicated customer_email into a normalized shape. Include add → backfill → flip → enforce → cleanup with safety checks and stakeholder comms.",
      "sampleStrongResponse": "Add the normalized column and start dual‑writes behind a flag. Backfill existing rows in shard‑aware batches with idempotent upserts and an error budget. Flip reads via a feature flag and verify parity on a sampled slice. Enforce validators and remove writes to the legacy field. Clean up the old column and monitoring. Safety: p95 &le; target, FK/unique enforced, and a rollback toggle to route reads back. Comms: share staleness window, expected p95, and a blast‑radius note with support/product."
    }
  ]
},
  "package-managers": {
  "title": "Package Managers Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Lockfiles primarily ensure:",
      "options": [
        "Faster network speed regardless of versions",
        "Automatic upgrades to latest versions on install",
        "Deterministic, reproducible installs with exact transitive versions",
        "That developers never need to commit dependency files"
      ],
      "correctAnswer": 2,
      "additionalContext": "Lockfiles capture resolved versions and integrity so installs match across machines and CI.",
      "keyConcepts": [
        "Lockfiles",
        "Determinism",
        "Integrity"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Integrity/signature checks are used to:",
      "options": [
        "Speed up compilation only",
        "Replace testing",
        "Decorate release notes",
        "Detect tampering and verify publisher authenticity"
      ],
      "correctAnswer": 3,
      "additionalContext": "Integrity fields and signatures defend against tampering and support supply chain assurance.",
      "keyConcepts": [
        "Integrity",
        "Signatures",
        "Supply chain security"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "SemVer communicates impact as MAJOR.MINOR.PATCH. Which statement aligns?",
      "options": [
        "MAJOR signals breaking changes; MINOR adds features; PATCH fixes bugs",
        "MAJOR/ MINOR/ PATCH are interchangeable",
        "PATCH introduces experiments by default",
        "MINOR always breaks APIs"
      ],
      "correctAnswer": 0,
      "additionalContext": "Use SemVer to set expectations: breaking vs additive vs fixes.",
      "keyConcepts": [
        "SemVer",
        "Compatibility",
        "Impact"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Recommended enterprise stance on install commands in CI:",
      "options": [
        "Use floating installs to catch new fixes",
        "Use frozen, lockfile-respecting installs (e.g., npm ci, pip-sync)",
        "Allow developers to skip installs",
        "Always regenerate the lockfile on every CI run"
      ],
      "correctAnswer": 1,
      "additionalContext": "Frozen installs enforce the lockfile and prevent accidental drift.",
      "keyConcepts": [
        "Frozen installs",
        "CI",
        "Drift prevention"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Workspaces in monorepos primarily help by:",
      "options": [
        "Removing the need for version control",
        "Publishing everything globally by default",
        "Preventing local development across packages",
        "Linking internal packages and sharing a single lockfile for consistency"
      ],
      "correctAnswer": 3,
      "additionalContext": "Workspaces speed local iteration and keep resolution consistent across packages.",
      "keyConcepts": [
        "Workspaces",
        "Monorepos",
        "Shared lockfile"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "A safe update policy for dependencies is:",
      "options": [
        "Automate patch/minor updates with tests; plan majors with migration guides",
        "Auto-merge all majors daily",
        "Never update unless broken",
        "Pin forever to first working version"
      ],
      "correctAnswer": 0,
      "additionalContext": "Routine small updates reduce risk; majors deserve scheduled migrations.",
      "keyConcepts": [
        "Update cadence",
        "Automation",
        "Migrations"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "A practical registry governance control is:",
      "options": [
        "Public write for everyone",
        "No audit logs",
        "Namespace ownership and signature verification",
        "Always use mutable tags in production"
      ],
      "correctAnswer": 2,
      "additionalContext": "Private proxies with ownership, signatures, and audit trails reduce supply chain risk.",
      "keyConcepts": [
        "Registry governance",
        "Ownership",
        "Signatures"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which practice prevents &ldquo;random Monday versions&rdquo; in CI?",
      "options": [
        "Frozen installs that honor the lockfile",
        "Running installs with network disabled",
        "Allowing caret ranges without locks",
        "Deleting node_modules on every run"
      ],
      "correctAnswer": 0,
      "additionalContext": "Use lockfile-enforcing commands (e.g., npm ci) to avoid drift from floating ranges.",
      "keyConcepts": [
        "Deterministic installs",
        "Lockfile enforcement",
        "CI"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Propose an enterprise policy that enforces lockfile usage, frozen installs, and integrity/signature checks across repos. How will exceptions be handled?",
      "sampleStrongResponse": "Require committed lockfiles and frozen installs in CI (npm ci/pip-sync). Enforce integrity and signature verification at install/publish via private proxies. Maintain an exception registry with time-bound waivers and owner approval. Monitor drift and block merges on violations."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Design a monorepo workspace strategy: shared lockfile, boundaries, and publish flows that mimic production. How will you debug resolution issues?",
      "sampleStrongResponse": "Use a single top-level lockfile with workspaces linking internal packages. Enforce boundaries via lint rules and build graphs. Publish through a private registry proxy; use digest/signature verification. When debugging, switch to isolated installs per package and trace resolution; then revert to hoisted for speed."
    }
  ]
},
  "pair-programming": {
  "title": "Pair Programming Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary roles in pairing:",
      "options": [
        "Driver writes code; Navigator reviews in real time and thinks ahead",
        "Driver reviews while Navigator types",
        "Both type simultaneously on separate branches",
        "No defined roles; ad‑hoc collaboration only"
      ],
      "correctAnswer": 0,
      "additionalContext": "Clear roles improve focus: Driver handles the keyboard; Navigator scans for edge cases, design, and risks.",
      "keyConcepts": [
        "Driver",
        "Navigator",
        "Role clarity"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Recommended rotation cadence:",
      "options": [
        "Once per day",
        "Every 15–30 minutes",
        "Once per sprint",
        "No rotation necessary"
      ],
      "correctAnswer": 1,
      "additionalContext": "Regular rotation balances attention, maintains energy, and spreads knowledge evenly.",
      "keyConcepts": [
        "Rotation",
        "Cadence",
        "Attention management"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "When pairing delivers the most value:",
      "options": [
        "Routine, low‑risk refactors",
        "Formatting‑only changes",
        "High‑risk or complex changes (security, performance, data)",
        "Late after release"
      ],
      "correctAnswer": 2,
      "additionalContext": "Use pairing for high‑risk or unknown problem spaces; solo is fine for small, low‑risk tasks.",
      "keyConcepts": [
        "Risk‑based pairing",
        "Complexity",
        "Exploration"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team‑level outcome from consistent pairing:",
      "options": [
        "More single points of failure",
        "Longer onboarding time",
        "Fewer defects on trivial tasks",
        "Higher bus factor and fewer single points of failure"
      ],
      "correctAnswer": 3,
      "additionalContext": "Pairing spreads context, increasing the team&rsquo;s resilience to individual unavailability.",
      "keyConcepts": [
        "Bus factor",
        "Onboarding",
        "Quality"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "A common trade‑off of pairing is:",
      "options": [
        "Better UI polish by default",
        "Guaranteed schedule acceleration",
        "Diminishing returns on well‑understood, low‑risk changes",
        "Elimination of all defects"
      ],
      "correctAnswer": 2,
      "additionalContext": "Schedule pairing during high‑value windows; avoid over‑pairing on simple, low‑risk work.",
      "keyConcepts": [
        "Trade‑offs",
        "Scheduling",
        "Value focus"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Remote ergonomics that matter most:",
      "options": [
        "Video always on with no exceptions",
        "Low‑latency tools with shared cursors, clear audio, and agreed handoffs",
        "Emailing code snippets between developers",
        "Screen sharing with 10‑second lag"
      ],
      "correctAnswer": 1,
      "additionalContext": "Optimize for low latency and clarity; video can be optional when prompts, checklists, and small commits are used.",
      "keyConcepts": [
        "Latency",
        "Shared cursors",
        "Handoffs"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Practice that improves remote pairing clarity:",
      "options": [
        "Use prompts, checklists, and small commits",
        "Disable commit messages to move faster",
        "Avoid writing tests until the end",
        "Hide the cursor to reduce distractions"
      ],
      "correctAnswer": 0,
      "additionalContext": "Shared context prompts and small, well‑described commits reduce confusion and rework.",
      "keyConcepts": [
        "Prompts",
        "Checklists",
        "Small commits"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Test‑first flow enabled by pairing:",
      "options": [
        "Skip tests to type faster",
        "Write tests only after deployment",
        "Defer acceptance criteria to a later sprint",
        "Scaffold unit tests and acceptance criteria while designing"
      ],
      "correctAnswer": 3,
      "additionalContext": "Pairing supports test‑first flows: clarify acceptance criteria and scaffold tests early.",
      "keyConcepts": [
        "Test‑first",
        "Acceptance criteria",
        "Scaffolding"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Outline a pairing rotation policy for a new service (roles, 15–30 minute cadence, break conditions). Which metrics would you track to evaluate effectiveness?",
      "sampleStrongResponse": "Define Driver/Navigator rotation every 20 minutes with a timer and explicit handoff prompts. Break when latency, fatigue, or scope shifts require it. Track defect rates in complex paths, lead time for risky changes, onboarding time, and developer sentiment."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "You must land a risky concurrency change under time pressure. Propose a pairing plan (who, when, where) and justify the ROI. How will you measure success?",
      "sampleStrongResponse": "Pair a domain expert with an implementer in the highest‑risk code area during peak collaboration hours. Use shared cursors, prompts, and test‑first scaffolding. Success metrics: reduction in escaped defects, faster code review cycle time, stable performance metrics, and positive developer sentiment."
    }
  ]
},
  "pull-request-process": {
  "title": "Pull Request Process Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary purpose of a PR template is to:",
      "options": [
        "Capture intent, scope, risk, and test plan for reviewers",
        "Enforce personal style preferences",
        "Replace CI and automated checks",
        "Discourage early feedback via drafts"
      ],
      "correctAnswer": 0,
      "additionalContext": "Templates standardize context so reviewers quickly understand change intent, risk areas, and validation steps.",
      "keyConcepts": [
        "PR templates",
        "Reviewer context",
        "Risk and test plan"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Risk labels on PRs should influence:",
      "options": [
        "Keyboard layout choices",
        "Depth of review, required approvals, and CI rigor",
        "Random assignment of reviewers",
        "Skipping reviews to accelerate merges"
      ],
      "correctAnswer": 1,
      "additionalContext": "Higher&ndash;risk changes warrant deeper reviews, more approvals, and stricter pre&ndash;merge checks.",
      "keyConcepts": [
        "Risk labels",
        "Approvals",
        "CI gates"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Non&ndash;blocking vs blocking feedback should be handled by:",
      "options": [
        "Treating all comments as blocking",
        "Hiding all nit comments",
        "Separating must&ndash;fix from suggestions with rationale",
        "Moving all feedback to post&ndash;merge"
      ],
      "correctAnswer": 2,
      "additionalContext": "Clear separation keeps velocity while ensuring critical issues block merges; suggestions can be queued.",
      "keyConcepts": [
        "Blocking vs non&ndash;blocking",
        "Review norms"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "A practical SLA for reviews prioritizes:",
      "options": [
        "Time to first response and time to decision",
        "Number of emoji reactions",
        "Longest possible review duration to catch everything",
        "Reviewing only on Fridays"
      ],
      "correctAnswer": 0,
      "additionalContext": "Fast first response unblocks authors; time to decision keeps delivery predictable.",
      "keyConcepts": [
        "SLA",
        "Time to first response",
        "Time to decision"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Effective reviewer checklists emphasize:",
      "options": [
        "Personal naming preferences",
        "Security, accessibility, performance budgets, and error handling",
        "Keyboard shortcuts",
        "Code style nits only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Checklists target risk hot spots and keep reviews consistent across changes and teams.",
      "keyConcepts": [
        "Checklists",
        "Risk areas",
        "Consistency"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Pre&ndash;merge CI policies that improve quality include:",
      "options": [
        "Optional tests to speed up merges",
        "Required status checks (tests, lint, security) before merge",
        "CI only after merge to main",
        "Local testing only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Required checks prevent regressions and enforce policy&ndash;as&ndash;code before changes land in main.",
      "keyConcepts": [
        "Status checks",
        "Policy&ndash;as&ndash;code",
        "Pre&ndash;merge gates"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Using draft PRs early primarily helps by:",
      "options": [
        "Delaying reviews until the end",
        "Triggering early CI and gathering feedback on approach",
        "Avoiding writing any description",
        "Skipping tests while coding"
      ],
      "correctAnswer": 1,
      "additionalContext": "Drafts invite design feedback and CI validation earlier, reducing rework later.",
      "keyConcepts": [
        "Draft PRs",
        "Early feedback",
        "CI signal"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "A healthy review culture encourages reviewers to:",
      "options": [
        "Gatekeep with blanket rejections",
        "Block on preference&ndash;only comments",
        "Ask questions with rationale and offer alternatives",
        "Nitpick unrelated formatting"
      ],
      "correctAnswer": 2,
      "additionalContext": "Questions with rationale support psychological safety and better decisions.",
      "keyConcepts": [
        "Psychological safety",
        "Rationale",
        "Alternatives"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Design a PR template that encodes risk and validation info. Include sections, example labels, and how it maps to required checks.",
      "sampleStrongResponse": "Include sections: Context, Scope, Risk level, Test plan, Rollback plan. Risk labels drive required checks (e.g., high&ndash;risk requires security scan and two approvals). Provide examples and link to standards. Keep a checklist for security, accessibility, performance budgets, and error handling."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Propose review SLAs and norms for a team handling mixed&ndash;risk changes. Show how to measure and improve them over time.",
      "sampleStrongResponse": "Set SLAs: time to first response &le; 4 hours in working time; time to decision &le; 2 days for typical changes. Label risk to scale approvals and checks. Track metrics (first response, decision time, change failure rate, developer sentiment). Run monthly retros, adjust templates and checklists, and coach on separating must&ndash;fix vs suggestions."
    }
  ]
},
  "query-optimization": {
  "title": "Query Optimization Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "EXPLAIN for a hot query shows a full scan and large memory grant. What is your first de‑risking ask before merge?",
      "options": [
        "Attach plan summary; propose a selective start with a minimal index and project only needed fields",
        "Increase instance size to hide latency and revisit later",
        "Add hints immediately to force a specific join algorithm",
        "Test only on developer laptops because data scale is smaller there"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: start from selective sets and remove wasted work.; Why correct: selective seeks and lean projections cut rows read and stabilize memory.; Why others are wrong: hardware hides design issues; hints lock in brittle plans; small data lies.; Cursor leverage: summarize plan operators/hashes; generate minimal DDL; write PR budget text.; Acceptance checks: rows‑read reduced; memory grant lowered; plan hash stable.",
      "keyConcepts": [
        "EXPLAIN",
        "Selective start",
        "Rows read",
        "Memory grant"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Random p95 spikes for the same query after deploy. What alignment do you require to stabilize plans?",
      "options": [
        "Disable statistics collection to avoid plan changes",
        "Keep stats fresh; parameterize queries; detect parameter sniffing risk and guard",
        "Pin the plan forever with a hard hint regardless of data",
        "Retry queries twice and accept spikes as normal"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: stabilize estimates and parameter sensitivity.; Why correct: fresh stats and parameterization prevent plan flips driven by skew.; Why others are wrong: disabling stats hurts estimates; hard hints age poorly; retries mask root cause.; Cursor leverage: add plan‑hash regression alerts; propose guard patterns; generate stats jobs.; Acceptance checks: stable plan hashes; p95 within budget; stats freshness SLO.",
      "keyConcepts": [
        "Parameter sniffing",
        "Statistics",
        "Plan stability",
        "p95 latency"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Feed endpoint uses offset paging and shows duplicates under heavy writes. What is your requirement?",
      "options": [
        "Keep offset and raise page size to reduce calls",
        "Return everything in one response to avoid pagination complexity",
        "Move to cursor pagination with a stable ORDER BY and opaque cursor",
        "Sort in the client to dedupe records post‑hoc"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: use cursor paging to avoid gaps and repeats.; Why correct: stable ordering + cursor prevent drift under writes.; Why others are wrong: larger pages still drift; huge payloads break clients; client sorts cannot fix missing/duplicate items.; Cursor leverage: generate cursor design; add contract tests; produce SDK examples.; Acceptance checks: ORDER BY defined; cursor contract in OpenAPI; gap/repeat tests pass.",
      "keyConcepts": [
        "Cursor pagination",
        "Stable ordering",
        "OpenAPI contract"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "A join applies filters after expanding rows, causing large intermediates. What do you ask before approving?",
      "options": [
        "Leave as is; optimizers always push down filters correctly",
        "Push predicates to selective sides and adjust join order to reduce intermediates",
        "Add a full table scan hint to simplify the plan shape",
        "Increase connection pool size to hide slow queries"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: push down predicates and right‑size join ordering.; Why correct: reducing intermediates cuts rows read and memory; plans become predictable.; Why others are wrong: optimizers miss pushdowns; hints and pools dodge the issue.; Cursor leverage: produce before/after plans; suggest indexes to support pushdowns; write PR acceptance text.; Acceptance checks: smaller intermediates; rows‑read drop; p95 meets budget.",
      "keyConcepts": [
        "Predicate pushdown",
        "Join order",
        "Rows read",
        "p95"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "The API shows an N+1 pattern for user orders. What is your proposed change?",
      "options": [
        "Keep N+1; it allows simpler code paths for now",
        "Rewrite as a single query (JOIN/IN with selective start) and measure rows‑read delta",
        "Add sleeps between queries so the database cools down",
        "Move the problem to a background job without changing queries"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: collapse N+1 into a single selective query.; Why correct: one well‑shaped query reduces round trips and rows read.; Why others are wrong: sleeps and backgrounding hide issues; code simplicity doesn’t beat latency.; Cursor leverage: generate a rewrite; attach plan diffs; set a slow‑query budget.; Acceptance checks: N reduced to 1; rows‑read down; p95 improved.",
      "keyConcepts": [
        "N+1",
        "Query rewrite",
        "Rows read"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Export endpoint times out and sorts a large dataset client‑side. What is your requirement?",
      "options": [
        "Keep client‑side sort; servers are already busy",
        "Add ORDER BY index, cover select list, and paginate with a streaming cursor",
        "Return unsorted results and let users adjust",
        "Increase memory limits until the sort passes"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: eliminate server sorts and stream results.; Why correct: ORDER BY index + covering remove sorts and reduce I/O; streaming keeps memory stable.; Why others are wrong: client sort moves cost to users; unsorted breaks contracts; more memory is brittle.; Cursor leverage: propose composite index; add cursor examples; define p95/throughput targets.; Acceptance checks: no sort operator; p95 within budget; memory steady.",
      "keyConcepts": [
        "Sort elimination",
        "Covering",
        "Cursor streaming",
        "p95"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Dashboard query competes with OLTP reads and spikes CPU. What guardrail do you require?",
      "options": [
        "Run heavy reads on the primary only to ensure freshness",
        "Cache or route through a read model/projection sized for analytics",
        "Throttle user traffic globally when dashboards run",
        "Disable indexes to equalize performance across users"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: decouple analytics from OLTP with caches/read models.; Why correct: dedicated projections keep OLTP predictable; caches reduce load.; Why others are wrong: primary‑only hurts capacity; global throttles punish users; removing indexes slows everything.; Cursor leverage: propose a projection; define refresh budget; add router rules.; Acceptance checks: OLTP p95 stable; projection freshness window agreed; cache hit rate tracked.",
      "keyConcepts": [
        "Read models",
        "Caching",
        "OLTP vs analytics",
        "Freshness window"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "A PR shows an accidental cross join (missing join predicate). What is your review requirement?",
      "options": [
        "Approve; cross joins sometimes discover useful combinations",
        "Add an optimizer hint so the engine chooses a better algorithm",
        "Require explicit join predicates and verify row estimates and rows‑read in plan",
        "Move the query to a nightly batch to reduce user impact"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: prevent accidental cross joins with explicit keys.; Why correct: predicates bound the join and stabilize estimates; plans become predictable.; Why others are wrong: hints and timing dodge correctness; batches hide defects.; Cursor leverage: add lints/tests for missing predicates; attach plan diffs; set acceptance checks.; Acceptance checks: join keys present; rows‑read bounded; plan estimates reasonable.",
      "keyConcepts": [
        "Cross join",
        "Join predicates",
        "Estimates",
        "Rows read"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to de‑risk a hot aggregation. Include: EXPLAIN summary, slow‑query budget (e.g., p95 &le; 150 ms), minimal index/rewrite rationale, and a rollback path if p95 regresses.",
      "sampleStrongResponse": "Request plan operators and rows‑read; confirm selective starts and no cross‑shard or full scans. State p95 &le; 150 ms at current QPS and propose the smallest composite or a rewrite that removes a sort. Call out write‑amp and attach rollback toggles/scripts. Ask Cursor to summarize the plan, generate the DDL/rewrite, and produce PR‑ready acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a staged optimization plan for a slow export: rewrite → index → cache/projection → rollout with flags. Include safety checks and stakeholder comms.",
      "sampleStrongResponse": "Rewrite predicates for sargability and pushdowns; add ORDER BY index and cover fields; introduce a projection for large scans; cache where safe. Roll out behind flags with plan‑hash and p95 monitors. Success: rows‑read down &ge; 80%, p95 &le; target, and zero contract changes. Communicate expected freshness window and a blast‑radius note to support/product."
    }
  ]
},
  "rate-limiting": {
  "title": "Rate Limiting Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR adds a global limit without headers. What is your requirement?",
      "options": [
        "Return 429 only; clients can guess backoff",
        "Return 429 with Retry‑After and X‑RateLimit‑* headers and provide client guidance",
        "Throttle silently by dropping connections",
        "Use 500 so clients retry more aggressively"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: clear server hints prevent retry storms.; Why correct: Retry‑After and X‑RateLimit‑* guide clients to adapt safely.; Why others are wrong: silent drops and 500s cause thundering herds; no headers create confusion.; Cursor leverage: scaffold middleware; add headers; update docs/SDK.; Acceptance checks: headers present; client examples updated; 429 rate stable.",
      "keyConcepts": [
        "429",
        "Retry‑After",
        "X‑RateLimit‑*"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Limits are enforced by IP only and multi‑tenant customers are throttled unfairly. What do you require?",
      "options": [
        "Stay with IP; it’s simplest",
        "Limit by trusted identity (API key/OAuth client) and segment by plan tier",
        "Allowlist all known IPs to avoid throttling",
        "Disable limits for paying customers"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: choose the right identity key for fairness.; Why correct: API key/client identity maps to tenants; plan tiers align SLOs with revenue.; Why others are wrong: IP misattributes; allowlists don’t scale; removing limits breaks isolation.; Cursor leverage: propose identity mapping; config by plan; dashboards.; Acceptance checks: identity confirmed; plan tiers applied; fairness issues resolved.",
      "keyConcepts": [
        "Identity",
        "Plan tiers",
        "Fairness"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Short bursts cause user‑visible throttling. What pattern do you require?",
      "options": [
        "Leaky bucket only with strict steady state",
        "Token bucket with burst capacity and clear reset semantics",
        "Global lock around hot endpoints",
        "No throttling for GET endpoints"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: allow short bursts within budget.; Why correct: token buckets smooth UX while respecting limits.; Why others are wrong: strict leaky buckets hurt UX; global locks harm throughput; GET can still DDoS.; Cursor leverage: configure bucket sizes; add tests; document headers.; Acceptance checks: burst tolerated; p95 unchanged; error rates stable.",
      "keyConcepts": [
        "Token bucket",
        "Burst",
        "Reset"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Batch jobs starve interactive UI. What requirement balances traffic?",
      "options": [
        "Single shared bucket for all endpoints",
        "Separate pools for writes/reads and job/UI with different budgets",
        "Disable batch jobs during business hours only",
        "Request clients to slow down manually"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: segment buckets by route and intent.; Why correct: separate pools protect UX and core writes.; Why others are wrong: single buckets cause starvation; time windows are brittle; manual requests don’t scale.; Cursor leverage: per‑route config; docs for SDK backoff; monitoring.; Acceptance checks: UI p95 stable; 429s reduced on UI; batch throughput predictable.",
      "keyConcepts": [
        "Segmentation",
        "GET/POST pools",
        "SLOs"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Abuse spike from a single ASN/IP range floods login. What immediate control do you require?",
      "options": [
        "Disable limits globally so legit users pass",
        "Add temporary per‑IP/ASN dampening and CAPTCHA where appropriate",
        "Throttle by region only",
        "Return 500 to discourage attackers"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: targeted dampening limits blast radius.; Why correct: per‑IP/ASN throttles abuse while preserving legit traffic; CAPTCHAs help selectively.; Why others are wrong: disabling limits breaks reliability; region throttling is too coarse; 500s encourage retries.; Cursor leverage: add edge rules; feature toggle; alerting.; Acceptance checks: abuse traffic reduced; legit success rate maintained; toggle removed after window.",
      "keyConcepts": [
        "Abuse control",
        "Per‑IP/ASN",
        "Feature toggle"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR suggests silent drops on limit to hide behavior. What is your position?",
      "options": [
        "Approve; security by obscurity is safer",
        "Reject; respond with 429 and guidance so clients back off",
        "Return 408 to imply a timeout instead",
        "Randomize between 429 and 500 to confuse bots"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: explicit feedback prevents storms.; Why correct: 429 + headers enables adaptive clients and stability.; Why others are wrong: obscurity worsens retries; 408 misleads; randomization breaks clients.; Cursor leverage: middleware changes; client examples; monitors.; Acceptance checks: proper status/headers; client SDKs updated; retry storms down.",
      "keyConcepts": [
        "429",
        "Client guidance",
        "Stability"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Global limiter sits in the application layer only. What improvement do you require?",
      "options": [
        "Keep it app‑only; edge work is unnecessary",
        "Add an edge/gateway limiter backed by Redis and jittered TTLs; keep app‑side as defense in depth",
        "Move limiter to a cron job that runs hourly",
        "Disable limiter in staging to keep config simple"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: enforce limits as close to the edge as possible.; Why correct: edge limits reduce load earlier and improve consistency; app‑side remains as backup.; Why others are wrong: cron is irrelevant; staging config drift is risky; app‑only increases cost.; Cursor leverage: scaffold edge middleware; config validation; dashboards.; Acceptance checks: edge enabled; app fallback present; consistency improved.",
      "keyConcepts": [
        "Edge limiting",
        "Redis",
        "Defense in depth"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Clients hammer 429 without backoff. What do you require in SDK guidance?",
      "options": [
        "Retry immediately to overcome transient throttles",
        "Use exponential backoff with jitter and honor Retry‑After/X‑RateLimit‑Reset",
        "Stop retrying permanently after the first 429",
        "Retry faster when Retry‑After is missing"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: disciplined retries protect systems and UX.; Why correct: jittered backoff and server hints prevent synchronized storms.; Why others are wrong: immediate/faster retries amplify load; stopping permanently breaks resilience.; Cursor leverage: ship SDK helpers; docs; examples.; Acceptance checks: SDKs updated; backoff adopted; 429 spikes dampened.",
      "keyConcepts": [
        "Exponential backoff",
        "Jitter",
        "Retry‑After"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a policy PR for rate limiting: identities, windows, algorithms, headers, and SDK guidance. Include measurable acceptance checks.",
      "sampleStrongResponse": "Policy: limit by API key/client with token bucket (rate + burst). Windows: 60s and daily quotas per plan. Headers: X‑RateLimit‑Limit/Remaining/Reset and Retry‑After. SDK: exponential backoff with jitter. Acceptance: headers present on 100% of 429; backoff in SDKs; fairness tickets drop; UI p95 unchanged."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a rollout plan to segment GET/POST pools and per‑tenant limits with monitoring and rollback toggles. Include comms to key customers.",
      "sampleStrongResponse": "Create config for separate GET/POST buckets and per‑tenant caps by plan. Roll out behind flags with dashboards for top 429 producers. Success: UI p95 stable, error budgets respected, and batch throughput within targets. Provide rollback toggles and notify key customers with guidance and SDK updates."
    }
  ]
},
  "relational-databases": {
  "title": "Relational Databases Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR writes touch orders, payments, and inventory together. Which review ask best validates all-or-nothing behavior?",
      "options": [
        "Show the transaction boundary and failure path; confirm partial writes cannot persist",
        "Increase isolation globally to the strongest level for safety",
        "Add retries so failures eventually succeed without further checks",
        "Move the logic into a stored procedure to make it atomic by default"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: confirm atomic all-or-nothing across order, payment, inventory. Why correct: asking to show the transaction boundary and failure path validates atomicity and prevents partial writes that confuse customers and finance. Why others are wrong: raising isolation globally is overreach and may reduce throughput without proving atomicity; retry-only does not stop duplicate effects on failure; a stored procedure is not automatically atomic without an explicit transaction. Cursor leverage: ask Cursor to draft a PR-ready comment that highlights begin and commit points, error handling, and an idempotency guard; have it scan the diff for any write before commit. Acceptance checks: transaction scope documented, negative path tested, idempotency keys in place.",
      "keyConcepts": [
        "ACID",
        "Atomicity",
        "PR review asks"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Product wants dashboards to read from replicas. Which expectation should you set up front?",
      "options": [
        "Replicas reflect the primary instantly for all dashboards",
        "Agree on a freshness window and route must-be-fresh reads to the primary",
        "Dashboards should never use replicas to avoid any lag",
        "Dashboards must exactly match the primary at all times"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: set a freshness window and route must-be-fresh reads to primary. Why correct: replicas improve read capacity but may lag; users may see old data after save unless paths are routed. Why others are wrong: instant match and exact equality at all times are overpromises; avoiding replicas entirely wastes safe capacity. Cursor leverage: ask Cursor to produce a 2–3 sentence PR comment that defines the freshness SLA and identifies which read paths stay on primary; request a small monitoring snippet for replica lag. Acceptance checks: freshness window documented, primary paths identified, lag monitoring defined.",
      "keyConcepts": [
        "Read replicas",
        "Freshness window",
        "Expectation setting"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Engineer adds an index on created_at to speed a hot query. What PR comment de-risks this best?",
      "options": [
        "Merge now; indexes are always helpful on hot tables",
        "Also add indexes on every filter column to be safe",
        "Bump the connection pool so the query gets more concurrent slots",
        "Share an EXPLAIN for the hot path and justify a minimal composite index that matches predicates; note write cost"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: show plan and choose the smallest index that matches predicates; acknowledge write cost. Why correct: an EXPLAIN confirms plan shape; a minimal composite index that matches equality then range avoids full scans while limiting write amplification. Why others are wrong: merge now or indexing every column is cargo-cult and increases write cost; more pool slots do not fix poor plans. Cursor leverage: ask Cursor to summarize EXPLAIN, propose a minimal composite index DDL, estimate write amplification, and generate a rollback script. Acceptance checks: EXPLAIN attached, slow-query budget stated, index matches predicates, rollback path included.",
      "keyConcepts": [
        "EXPLAIN",
        "Indexing trade-offs",
        "PR review asks"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team proposes raising isolation to Serializable to prevent anomalies. What trade-off must you align on first?",
      "options": [
        "Serializable guarantees infinite throughput at any scale",
        "Higher contention and rollbacks under load; ask for expected concurrency and impact",
        "Read caches will stop working once isolation increases",
        "Storage costs will grow even if workload stays the same"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: Serializable reduces anomalies but increases contention and rollbacks. Why correct: you must align on expected concurrency and error budgets before increasing isolation. Why others are wrong: infinite throughput is false; read caches continue to work; storage growth is unrelated. Cursor leverage: ask Cursor to draft questions for expected throughput, conflict rate, and rollback handling; request a short note on fallback isolation per endpoint if regressions appear. Acceptance checks: concurrency profile documented, rollback policy defined, budgeted error rate accepted, fallback path clear.",
      "keyConcepts": [
        "Isolation",
        "Throughput trade-offs",
        "Risk surfacing"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Reporting is slow but checkouts are sensitive. What approach keeps product traffic safe while speeding reports?",
      "options": [
        "Move heavy reporting to replicas or materialized views with a freshness SLA",
        "Run reports on the primary and increase CPU until it is fine",
        "Denormalize everything immediately to make all reads fast",
        "Increase isolation so reads are always the latest"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: protect product traffic by offloading reporting to replicas or materialized views with a freshness window. Why correct: dashboards can tolerate staleness; OLTP cannot tolerate contention. Why others are wrong: running reports on primary risks slow checkouts; denormalize everything is overreach; raising isolation does not address reporting load. Cursor leverage: ask Cursor to produce an SLA phrasing and a small playbook for routing reads and monitoring lag. Acceptance checks: SLA documented, report paths moved, p95 targets set, alerts created.",
      "keyConcepts": [
        "Replica routing",
        "Materialized views",
        "Freshness SLA"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Team wants to denormalize a feed for speed. What must be documented to keep trust?",
      "options": [
        "That the entire app is now eventually consistent everywhere",
        "That no further indexes will ever be needed",
        "That refunds and reversals are no longer supported",
        "Freshness window, source of truth, conflict resolution, and write-amplification budget"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: denormalization is safe only with trust guardrails. Why correct: documenting freshness window, source of truth, conflict resolution, and a write-amplification budget prevents confusion and data drift. Why others are wrong: calling the whole app eventually consistent is unnecessary; claiming no future indexes is unrealistic; dropping support for reversals breaks product needs. Cursor leverage: ask Cursor to generate a short design note template that captures these guardrails and a checklist for PR review. Acceptance checks: guardrails filled, reconciliation flow owned, staleness window communicated.",
      "keyConcepts": [
        "Denormalization",
        "Trust guardrails",
        "Documentation"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Schema change adds a non-nullable column to a large table. Which plan do you require before approving?",
      "options": [
        "Apply a blocking ALTER during a short maintenance window",
        "Ship the app change first; fix the schema after release",
        "Phase it: add nullable, backfill in batches, flip flag, enforce, then drop old paths",
        "Rename the table to avoid risks and migrate later"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: ship schema changes in phases so rush hour never locks the app. Why correct: add then backfill in batches, flip via flag, enforce, and clean up reduces blocking risk and enables rollback. Why others are wrong: blocking ALTER risks downtime; shipping app first can break writes; renaming the table is high-risk and rarely needed. Cursor leverage: ask Cursor to produce a phased plan with batch SQL, metrics to watch, and a rollback toggle. Acceptance checks: batch size and pacing defined, feature flag identified, monitoring and rollback documented.",
      "keyConcepts": [
        "Phased migrations",
        "Operational risk",
        "Rollback plan"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Customers report seeing old data right after saving. What is the likely cause and best guidance?",
      "options": [
        "Indexes are corrupt; rebuild all indexes",
        "The database is down; restart the cluster to refresh",
        "Reads hit a replica before catch-up; route freshness-critical reads to the primary and set a freshness window",
        "Disable replicas; transactions are being lost"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: this is replica lag; route must-be-fresh paths to primary. Why correct: replicas can serve stale reads immediately after a write; routing and SLA language avoid user confusion. Why others are wrong: index rebuilds or restarts do not address lag; disabling replicas loses safe capacity. Cursor leverage: ask Cursor to draft the PR comment that sets the freshness window and identifies primary-only paths plus a simple lag monitor. Acceptance checks: routes updated, SLA documented, monitoring in place.",
      "keyConcepts": [
        "Replica lag",
        "Freshness SLA",
        "Routing"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to de-risk a new hot-path query. Include: EXPLAIN plan, slow-query budget target, minimal non-overlapping index rationale, and rollback plan if p95 regresses.",
      "sampleStrongResponse": "Ask for EXPLAIN on the exact WHERE and ORDER BY; confirm the plan avoids full scans and uses a composite index that matches predicates. State the slow-query budget (for example, p95 at or below 120 ms) and propose the smallest non-overlapping index that meets it. Call out write-amplification impact on inserts and updates, and require a rollback toggle or script if p95 regresses after deploy. Use Cursor to summarize EXPLAIN, generate the DDL and rollback, and produce a PR-ready comment."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a phased migration talk track for a non-nullable column on a large table. Include steps, safety checks, and how you will communicate risk to product and support.",
      "sampleStrongResponse": "Plan: add a nullable column; backfill in batches with monitoring; dual-write and validate; flip a feature flag to switch reads and writes; enforce non-null; remove legacy code. Safety: idempotent writes, timeouts and retry budget, metrics for backfill pace, and a rollback path. Communication: share expected blast radius, any maintenance window, and success metrics such as zero lock timeouts and stable p95. Ask Cursor to draft the step plan, batch SQL, and a stakeholder note for support and product."
    }
  ]
},
  "repository-organization": {
  "title": "Repository Organization Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Mono&ndash;repo advantages commonly include:",
      "options": [
        "Unified dependency and tooling management across services",
        "Guaranteed faster builds in all cases",
        "Complete isolation by default",
        "No need for code ownership boundaries"
      ],
      "correctAnswer": 0,
      "additionalContext": "Mono&ndash;repos centralize tooling and dependencies, easing refactors and cross&ndash;cutting changes when guardrails exist.",
      "keyConcepts": [
        "Mono&ndash;repo",
        "Tooling",
        "Dependencies"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Multi&ndash;repo trade&ndash;offs often include:",
      "options": [
        "Clearer service boundaries and independent releases",
        "No duplication risk",
        "Single pipeline for everything",
        "Automatic cross&ndash;repo refactors"
      ],
      "correctAnswer": 0,
      "additionalContext": "Multi&ndash;repos emphasize isolation and independent versioning, though shared libraries need release discipline.",
      "keyConcepts": [
        "Multi&ndash;repo",
        "Isolation",
        "Independent releases"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Submodules or subtree strategies are useful when:",
      "options": [
        "Sharing a library across repos while keeping its history and release cycle",
        "Avoiding versioning entirely",
        "You want to merge all repos into one without history",
        "You need zero configuration for consumers"
      ],
      "correctAnswer": 0,
      "additionalContext": "Submodules/subtrees allow reuse while preserving independent history and version control of the shared component.",
      "keyConcepts": [
        "Submodules",
        "Subtree",
        "Shared libraries"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "CODEOWNERS files primarily help by:",
      "options": [
        "Enforcing keyboard layouts",
        "Automatically assigning knowledgeable reviewers to owned areas",
        "Replacing CI",
        "Blocking all changes by default"
      ],
      "correctAnswer": 1,
      "additionalContext": "Ownership rules route PRs to the right people, improving review quality and governance.",
      "keyConcepts": [
        "CODEOWNERS",
        "Ownership",
        "Governance"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "In a mono&ndash;repo, boundaries are maintained by:",
      "options": [
        "Skipping tests for speed",
        "Enforcing module boundaries with tooling, ownership, and CI rules",
        "Copying code freely between packages",
        "Letting any code import anything"
      ],
      "correctAnswer": 1,
      "additionalContext": "Tools like path rules, lint boundaries, and package ownership keep coupling under control.",
      "keyConcepts": [
        "Module boundaries",
        "Lint rules",
        "Ownership"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Release versioning in a multi&ndash;repo setup typically means:",
      "options": [
        "Each service or library can version and release independently",
        "All components must share one version at all times",
        "No tags are used",
        "Only nightly bulk releases"
      ],
      "correctAnswer": 0,
      "additionalContext": "Independent versioning allows targeted releases; shared libraries must communicate changes via SemVer.",
      "keyConcepts": [
        "Independent versioning",
        "SemVer"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Build and test isolation in mono&ndash;repos is commonly achieved by:",
      "options": [
        "Running the full repo on every PR without caching",
        "Using workspaces, affected&ndash;graph detection, and caching",
        "Disabling CI to speed up",
        "Manual selection of tests by each developer"
      ],
      "correctAnswer": 1,
      "additionalContext": "Affected&ndash;graph and caching target only impacted packages, keeping feedback loops fast.",
      "keyConcepts": [
        "Affected graph",
        "Caching",
        "Workspaces"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Choose mono&ndash;repo when you need:",
      "options": [
        "Maximum independent governance between teams",
        "Unified tooling, shared libraries, and coordinated cross&ndash;cutting changes",
        "No cross&ndash;team work ever",
        "Total isolation of build infrastructure"
      ],
      "correctAnswer": 1,
      "additionalContext": "Mono&ndash;repos shine for coordinated refactors, shared tooling, and unified standards across many packages.",
      "keyConcepts": [
        "Mono&ndash;repo",
        "Cross&ndash;cutting changes",
        "Unified tooling"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Recommend mono&ndash;repo vs multi&ndash;repo for a platform with many shared libraries and frequent cross&ndash;cutting refactors. Include governance and tooling.",
      "sampleStrongResponse": "Prefer a mono&ndash;repo with workspaces. Enforce module boundaries and CODEOWNERS; use affected&ndash;graph CI and caching. Centralize tooling (lint, test, build) and adopt SemVer for shared libraries. Define ownership and review policies to avoid uncontrolled coupling."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Define a submodule/subtree strategy for a shared cryptography library used by multiple services. Cover versioning, release process, and consumer updates.",
      "sampleStrongResponse": "Maintain the library in its own repo with SemVer and signed tags. Consumers integrate via submodule/subtree. Publish releases with changelogs; CI verifies API compatibility. Consumers pin versions and update via scheduled PRs that run full security and performance suites."
    }
  ]
},
  "rest-best-practices": {
  "title": "REST Best Practices Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "A new POST /orders endpoint may double‑charge on retry. What will you require in the PR?",
      "options": [
        "Return 200 OK on duplicates without any indication",
        "Support an Idempotency‑Key header and return 201 with Location on first success and the original result on replay",
        "Use a custom verb in the path like /orders/create to signal special logic",
        "Advise clients to avoid retries altogether"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: idempotent POSTs prevent duplicates and clarify outcomes.; Why correct: Idempotency‑Key enables safe retries; 201 + Location is predictable.; Why others are wrong: silent 200 hides state; RPC verbs in paths break conventions; banning retries is unrealistic.; Cursor leverage: add OpenAPI examples; scaffold middleware; write PR‑ready contract text.; Acceptance checks: key handled; 201 + Location on create; replay returns prior result.",
      "keyConcepts": [
        "Idempotency",
        "201 Created",
        "Location header"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Error responses vary per endpoint. What alignment do you require?",
      "options": [
        "Return plain strings to keep payloads small",
        "Adopt RFC 7807 Problem Details with stable code, message, and traceId",
        "Use HTML error pages so browsers can render nicely",
        "Document errors in a wiki page instead of the spec"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: standardize errors for machine handling and DX.; Why correct: Problem Details with code/traceId enables automation and support.; Why others are wrong: strings/HTML are brittle; wikis drift from reality.; Cursor leverage: update OpenAPI; add error middleware; generate SDK samples.; Acceptance checks: schema validated in CI; error examples present; traceId logged.",
      "keyConcepts": [
        "RFC 7807",
        "Error contracts",
        "traceId"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Offset pagination shows duplicates/gaps under writes. What do you require?",
      "options": [
        "Keep offset; raise page size and hope for fewer issues",
        "Use cursor pagination with stable ordering and Link headers",
        "Return everything in one page to avoid pagination",
        "Sort in the client and dedupe duplicates"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: cursor paging prevents drift.; Why correct: stable ORDER + opaque cursor avoids gaps/repeats.; Why others are wrong: larger pages still drift; one page is impractical; client sorts can’t fill gaps.; Cursor leverage: generate cursor design; add OpenAPI/SDK examples; create contract tests.; Acceptance checks: ORDER defined; cursor params in spec; no gaps/repeats in tests.",
      "keyConcepts": [
        "Cursor pagination",
        "Stable ordering",
        "Link headers"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "PUT /orders/{id} is not idempotent and can create duplicates. What change do you require?",
      "options": [
        "Keep behavior; clients should call carefully",
        "Make PUT idempotent (replace semantics) and use POST for creation with idempotency",
        "Rename it to /orders/update and keep semantics the same",
        "Return 500 on duplicates so clients learn fast"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: align methods to semantics for safety.; Why correct: PUT must be idempotent; POST creation with idempotency prevents duplicates.; Why others are wrong: naming doesn’t fix behavior; 500s are not contracts.; Cursor leverage: update OpenAPI; add method tests; scaffold idempotency middleware.; Acceptance checks: PUT idempotent; POST has Idempotency‑Key; tests pass.",
      "keyConcepts": [
        "Method semantics",
        "PUT vs POST",
        "Idempotency"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Endpoints mix RPC verbs in paths (e.g., /orders/cancelOrder). What is your review stance?",
      "options": [
        "Allow RPC verbs; teams can guess semantics",
        "Model nouns and use standard HTTP methods; represent actions as resources if needed",
        "Embed verbs deeply to make routes descriptive",
        "Use POST for every operation to simplify clients"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: REST uses nouns + standard methods.; Why correct: consistent modeling improves predictability and tooling.; Why others are wrong: RPC verbs reduce reuse; over‑descriptive paths harm contracts; one‑verb POST harms caching/idempotency.; Cursor leverage: lint OpenAPI; propose resource names; update examples.; Acceptance checks: nouns in paths; verbs only as methods; docs/SDK regenerated.",
      "keyConcepts": [
        "Resource modeling",
        "HTTP methods",
        "Consistency"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Large collections time out with offset. What do you ask before merge?",
      "options": [
        "Keep offset but increase timeouts",
        "Adopt cursor paging with stable sort and document back/next links",
        "Return unsorted results to improve speed",
        "Paginate in the client only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: stable cursor paging scales.; Why correct: stable sort + links give predictable navigation at scale.; Why others are wrong: timeouts dodge design; unsorted breaks contracts; client‑only paging is brittle.; Cursor leverage: spec examples; header/link helpers; SDK updates.; Acceptance checks: spec validates; e2e tests show no skips/repeats; performance meets SLO.",
      "keyConcepts": [
        "Pagination",
        "Stable sort",
        "HATEOAS/Links"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Some endpoints return HTML errors while others return JSON. What do you require?",
      "options": [
        "Keep HTML for readability",
        "Standardize on JSON Problem Details with content‑type and codes",
        "Use text/plain for errors to reduce payload size",
        "Respond 204 No Content on errors to avoid payloads"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: consistent machine‑readable errors.; Why correct: JSON Problem Details enables client automation and logging.; Why others are wrong: HTML/text are brittle; 204 hides failure.; Cursor leverage: add middleware; update OpenAPI; regenerate SDK.; Acceptance checks: correct content‑type; schema validated; examples in docs.",
      "keyConcepts": [
        "Problem Details",
        "Content negotiation",
        "Error handling"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Async processing is added but API blocks until done. What pattern do you ask for?",
      "options": [
        "Return 202 Accepted with Location to a status resource and poll",
        "Keep blocking and raise server timeouts",
        "Return 201 with body only and no status link",
        "Use WebSockets for every async job regardless of clients"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: use 202 + status resource for async.; Why correct: decouples long work with a standard pattern and discoverable status.; Why others are wrong: blocking harms reliability; 201 is for creation; WebSockets everywhere is overkill.; Cursor leverage: scaffold job resource; add status schema; update docs.; Acceptance checks: 202 + Location implemented; status schema documented; retry/backoff examples provided.",
      "keyConcepts": [
        "202 Accepted",
        "Status resource",
        "Asynchrony"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment to make /orders robust: include idempotent POST, cursor paging, RFC 7807 errors, and measurable success (e.g., duplicate rate &lt; 0.1%, p95 list &le; 120 ms).",
      "sampleStrongResponse": "Specify POST with Idempotency‑Key; return 201 + Location and stable IDs. Use cursor paging with stable ORDER and Link headers. Adopt RFC 7807 with codes and traceId. Success: duplicate charge rate &lt; 0.1%, list p95 &le; 120 ms, and contract tests green. Ask Cursor to update OpenAPI/SDK, scaffold middleware, and add acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a deprecation policy rollout for a breaking response change: warnings → dual responses → versioned endpoint. Include headers, comms, and success metrics.",
      "sampleStrongResponse": "Phase 1: add deprecation docs and warnings. Phase 2: return both fields with a flag; publish SDK guidance. Phase 3: introduce /v2 with frozen contract. Send Deprecation/Sunset headers with dates; docs/SDK per version. Success: &ge; 90% traffic on new contract, zero Sev‑1s, and customer comms acknowledged."
    }
  ]
},
  "risk-assessment": {
  "title": "Risk Assessment Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is the primary purpose of a likelihood/impact matrix?",
      "options": [
        "To assign blame after incidents",
        "To create audit paperwork only",
        "To replace monitoring entirely",
        "To visualize risk exposure and prioritize mitigations"
      ],
      "correctAnswer": 3,
      "additionalContext": "The matrix highlights high likelihood/high impact risks for prioritization and mitigation planning.",
      "keyConcepts": [
        "Risk matrix",
        "Prioritization",
        "Exposure"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "A mitigation differs from a contingency because:",
      "options": [
        "Mitigation is applied after the risk occurs; contingency is before",
        "They are identical",
        "Mitigation reduces likelihood/impact beforehand; contingency is the plan if the risk happens",
        "Contingency reduces probability only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Mitigations act proactively to reduce probability or impact; contingencies are &ldquo;what we do if it happens&rdquo;.",
      "keyConcepts": [
        "Mitigation",
        "Contingency",
        "Proactive vs reactive"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "A good trigger for a risk is:",
      "options": [
        "A specific observable event like error rate exceeding a threshold",
        "Vague concern with no observable signal",
        "A quarterly meeting invite",
        "A teammate&rsquo;s feeling"
      ],
      "correctAnswer": 0,
      "additionalContext": "Triggers should be measurable signals (metrics, logs, events) that indicate increased risk likelihood.",
      "keyConcepts": [
        "Triggers",
        "Signals",
        "Monitoring"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which practice supports ongoing risk visibility during a project?",
      "options": [
        "Static risk list created once",
        "Risk burndown chart updated with discovery and mitigations",
        "Only postmortems",
        "Ignoring low probability risks"
      ],
      "correctAnswer": 1,
      "additionalContext": "A risk burndown tracks exposure over time and shows effect of mitigations and new discoveries.",
      "keyConcepts": [
        "Risk burndown",
        "Discovery",
        "Exposure over time"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "When interpreting a risk burndown that is flat or rising:",
      "options": [
        "Everything is fine by default",
        "It proves schedule padding is too large",
        "It means we overestimated impact",
        "It indicates mitigations are insufficient or new risks emerged"
      ],
      "correctAnswer": 3,
      "additionalContext": "Flat or rising exposure suggests mitigations are ineffective or risks are being discovered faster than addressed.",
      "keyConcepts": [
        "Interpretation",
        "Exposure",
        "Mitigation effectiveness"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Scenario planning helps by:",
      "options": [
        "Eliminating all uncertainty",
        "Replacing incident response",
        "Defining responses for plausible futures and decision points",
        "Guaranteeing dates regardless of risk"
      ],
      "correctAnswer": 2,
      "additionalContext": "Scenarios outline plausible futures with triggers/decision points so teams can act quickly when signals occur.",
      "keyConcepts": [
        "Scenario planning",
        "Decision points",
        "Futures"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "A common bias to avoid in risk assessment:",
      "options": [
        "Anchoring to first estimates without new data",
        "Using data from monitoring",
        "Considering multiple mitigation options",
        "Revisiting assumptions when signals change"
      ],
      "correctAnswer": 0,
      "additionalContext": "Anchoring and confirmation bias can distort likelihood/impact estimates; regularly revisit with fresh data.",
      "keyConcepts": [
        "Bias",
        "Anchoring",
        "Confirmation bias"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which combination best reduces risk exposure before launch?",
      "options": [
        "Disable monitoring and ship",
        "Pilot with canary/feature flags plus rollback strategy",
        "Skip load testing to save time",
        "Ship on Friday evening"
      ],
      "correctAnswer": 1,
      "additionalContext": "Pilots with flags and clear rollback reduce blast radius and time to recover.",
      "keyConcepts": [
        "Pilot",
        "Feature flags",
        "Rollback"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "You inherit a project with high unknowns. Describe how you would establish a risk register with triggers, mitigations, and contingencies. How will you track exposure over time?",
      "sampleStrongResponse": "Create a lightweight register listing risk, likelihood, impact, owner, trigger, mitigation, contingency. Tie triggers to metrics/logs and review weekly. Track exposure via a risk burndown chart updated as mitigations land and new risks are discovered."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "An upcoming launch depends on an external API with uncertain limits. Propose mitigations and contingencies, including signals to switch strategies.",
      "sampleStrongResponse": "Mitigations: cache, rate limiting, backoff, prefetching, contract tests. Contingencies: failover path, toggle to reduced capability, staged rollout. Signals: elevated 429/5xx rate or latency p95 crossing threshold triggers fallback and rollback."
    }
  ]
},
  "rollback-procedures": {
  "title": "Rollback Procedures Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Core principle of reversible deployments?",
      "options": [
        "Design forward&ndash;only DB changes and idempotent operations with versioned artifacts",
        "Allow destructive DB changes under peak load",
        "Rely on manual recovery steps only",
        "Avoid testing rollbacks in staging"
      ],
      "correctAnswer": 0,
      "additionalContext": "Reversible deployments favor forward&ndash;only migrations, idempotent ops, immutable artifacts, and rehearsal of rollbacks.",
      "keyConcepts": [
        "Reversible deployments",
        "Idempotency",
        "Versioned artifacts"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Blue/Green vs canary &mdash; which mapping is correct?",
      "options": [
        "Blue/Green shifts a small percent first; canary flips all traffic instantly",
        "Blue/Green maintains two environments for atomic traffic switch; canary starts with a small percentage",
        "Both are identical strategies",
        "Canary requires DNS only; Blue/Green requires no routing changes"
      ],
      "correctAnswer": 1,
      "additionalContext": "Blue/Green runs two environments and flips traffic atomically for instant rollback; canary ramps a small percentage to detect regressions early.",
      "keyConcepts": [
        "Blue/Green",
        "Canary",
        "Rollback speed"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Observability requirement for safe rollback strategies?",
      "options": [
        "Informal logging only",
        "Manual dashboards after incidents",
        "SLO&ndash;linked signals (errors, p95 latency) with alerting",
        "Noisy alerts without thresholds"
      ],
      "correctAnswer": 2,
      "additionalContext": "Rollback triggers depend on timely signals tied to SLOs with alerting to detect regressions quickly.",
      "keyConcepts": [
        "Observability",
        "SLOs",
        "Alerts"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Database&ndash;safe change pattern during migrations?",
      "options": [
        "Destructive schema changes during peak",
        "Permanent dual&ndash;write architecture",
        "Skip backfill and reconcile later only if issues occur",
        "Forward&ndash;only additive changes; temporary dual&ndash;write/dual&ndash;read"
      ],
      "correctAnswer": 3,
      "additionalContext": "Prefer additive changes and short&ndash;lived dual&ndash;write/dual&ndash;read to migrate safely with clear backfill and reconciliation steps.",
      "keyConcepts": [
        "Forward&ndash;only",
        "Dual write/read",
        "Backfill"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Benefit of practicing rollbacks in staging?",
      "options": [
        "Reveals missing scripts and coupling before customers are impacted",
        "Increases surprise during production",
        "Eliminates the need for runbooks",
        "Guarantees zero incidents"
      ],
      "correctAnswer": 0,
      "additionalContext": "Rehearsals expose gaps in scripts and hidden coupling early, improving confidence and speed during incidents.",
      "keyConcepts": [
        "Rehearsal",
        "Staging",
        "Runbooks"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Automated rollback triggers should:",
      "options": [
        "Flip on any single noisy metric",
        "Use multi&ndash;signal confirmation tied to SLOs to avoid flapping",
        "Depend on manual approval only",
        "Ignore error budgets"
      ],
      "correctAnswer": 1,
      "additionalContext": "Combine metrics, logs, and synthetic checks with thresholds to trigger rollback reliably without flapping.",
      "keyConcepts": [
        "Triggers",
        "Multi&ndash;signal",
        "Error budgets"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Blast radius containment means:",
      "options": [
        "Roll out everywhere at once",
        "Disable monitoring to reduce noise",
        "Stagger rollouts by region/cohort and isolate experiments from core flows",
        "Dark launch UI to all users first"
      ],
      "correctAnswer": 2,
      "additionalContext": "Limit simultaneous risk by regional or cohort ramps, dark launches, and isolation of experimental changes.",
      "keyConcepts": [
        "Blast radius",
        "Staggered rollout",
        "Dark launch"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Why pin artifacts, infra, and migrations?",
      "options": [
        "To allow silent drift between environments",
        "To avoid tagging releases",
        "To remove the need for version control",
        "To reproduce prior states faithfully for deterministic rollback"
      ],
      "correctAnswer": 3,
      "additionalContext": "Pinning versions makes rollback deterministic by reproducing the previous known&ndash;good state.",
      "keyConcepts": [
        "Version pinning",
        "Determinism",
        "Immutability"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a per&ndash;service rollback checklist for a DB migration. Include health checks, version pinning, backfill steps, and owner acknowledgements.",
      "sampleStrongResponse": "Checklist: (1) Verify prior artifact and schema versions are available and pinned, (2) Pre&ndash;flight health checks green, (3) Backfill plan and verification queries prepared, (4) Dual&ndash;write toggle path and teardown plan documented, (5) Rollback triggers linked to SLO thresholds, (6) On&ndash;call and service owner acks recorded, (7) Post&ndash;rollback validation and changelog entry."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Compare canary vs Blue/Green for a high&ndash;traffic service. When would you choose each, and what rollback signals/triggers would you configure?",
      "sampleStrongResponse": "Use canary for incremental risk: start at 1&ndash;5% to validate error rate and p95 latency with multi&ndash;signal confirmation; expand as signals stay green. Choose Blue/Green when you need instant rollback and minimal downtime: maintain two environments and flip traffic atomically. In both cases, define SLO thresholds, synthetic probes, and alerting; auto&ndash;revert on threshold breach and notify stakeholders with version and reason."
    }
  ]
},
  "schema-design": {
  "title": "Schema Design Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Proposal models users, orders, and products in one wide table. What alignment do you require before approving?",
      "options": [
        "Keep a single table to avoid all joins across the system",
        "Model clear entities with primary/foreign keys; encode invariants with constraints and ownership",
        "Store everything as JSON blobs so the schema can change later",
        "Rely on application code only for data integrity checks"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: design entities with keys and constraints for trust.; Why correct: clear PK/FK and constraints make rules explicit and evolvable.; Why others are wrong: one table harms integrity/scale; JSON blobs block indexes; app‑only checks drift.; Cursor leverage: draft ER diagram; generate PK/FK/unique/check DDL; produce ownership notes.; Acceptance checks: PK/FK present; key constraints enforced; ownership documented.",
      "keyConcepts": [
        "Entity boundaries",
        "Primary/Foreign keys",
        "Constraints",
        "Ownership"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Design uses only natural keys and no surrogate id. What change do you require to reduce merge risks?",
      "options": [
        "Natural keys are enough because business identifiers never change",
        "Add surrogate PKs and keep unique constraints on natural keys; document merge rules",
        "Use GUIDs everywhere without any uniqueness on business fields",
        "Drop uniqueness entirely to reduce write contention"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: stable identity plus business uniqueness.; Why correct: surrogate PKs stabilize joins; unique on natural IDs prevents duplicates.; Why others are wrong: business IDs change; GUIDs without unique checks drift; dropping uniqueness corrodes trust.; Cursor leverage: emit DDL; add merge policy; write PR rationale.; Acceptance checks: surrogate PKs; unique natural keys; merge policy recorded.",
      "keyConcepts": [
        "Surrogate key",
        "Natural key",
        "Uniqueness",
        "Merges"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "A future shard/partition is planned. What early alignment do you require on keys?",
      "options": [
        "Choose any key; we can rebalance later with no cost",
        "Pick shard/partition keys that match dominant filters and access paths; document rebalancing",
        "Avoid shard keys so cross‑partition joins are easier",
        "Use random hashing only to avoid hot tenants by default"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: align keys with access to avoid cross‑partition pain.; Why correct: matching keys to filters prevents scatter/gather and hotspots; a rebalancing plan reduces risk.; Why others are wrong: key changes are costly; avoiding keys or random hashes ignores access.; Cursor leverage: analyze filters; simulate scatter/gather; propose key options.; Acceptance checks: key rationale documented; fan‑out eliminated in EXPLAIN; p95 within budget.",
      "keyConcepts": [
        "Shard/partition key",
        "Access patterns",
        "Scatter/gather",
        "p95 latency"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "PR changes a critical column type and adds NOT NULL. How should the rollout proceed?",
      "options": [
        "Apply change in one step in production to save time",
        "Gate on application restarts only; schema can lag behind",
        "Use expand → backfill → flip → enforce → cleanup with idempotent batches",
        "Rely on implicit conversions at runtime across services"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: stage incompatible changes to avoid lock and outage.; Why correct: phased steps minimize locks and allow safe rollback.; Why others are wrong: single‑step changes risk downtime; implicit conversions are brittle.; Cursor leverage: scaffold migration plan; generate backfill scripts; add toggles and monitors.; Acceptance checks: backfill parity; lock times acceptable; rollback path tested.",
      "keyConcepts": [
        "Phased migration",
        "Idempotent backfill",
        "Rollback",
        "Locks"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Analytics uses the same OLTP store and long joins time out. What do you require?",
      "options": [
        "Keep analytics in OLTP and raise timeouts until it passes",
        "Export normalized data to a star schema or views with refresh SLOs and lineage",
        "Replace OLTP with a wide denormalized table for everything",
        "Turn off constraints to speed up analytics joins"
      ],
      "correctAnswer": 0,
      "additionalContext": "Headline: serve analytics from dedicated shapes, not OLTP.; Why correct: stars/views give fast BI without harming OLTP writes; refresh SLOs keep trust.; Why others are wrong: raising timeouts dodges design; one wide table breaks invariants; removing constraints corrodes data.; Cursor leverage: generate stars/views; schedule refresh; document lineage.; Acceptance checks: BI moved; refresh SLO documented; OLTP p95 steady.",
      "keyConcepts": [
        "OLTP vs OLAP",
        "Star schema",
        "Views",
        "Refresh SLO"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Security/audit requires who/when on changes. What schema design guardrail do you ask for?",
      "options": [
        "Store audit data only in logs and parse later when needed",
        "Add created_at/updated_at and created_by/updated_by with constraints and triggers where appropriate",
        "Keep only created_at; updated fields are noisy in analytics",
        "Track audit fields in a separate spreadsheet maintained by hand"
      ],
      "correctAnswer": 1,
      "additionalContext": "Headline: capture audit fields at the source with structure.; Why correct: structured audit fields enable traceability and governance.; Why others are wrong: logs/spreadsheets drift; partial fields miss changes.; Cursor leverage: scaffold audit columns/triggers; add validation; propose dashboards.; Acceptance checks: audit fields present; populated correctly; reports wired.",
      "keyConcepts": [
        "Audit fields",
        "Traceability",
        "Governance"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "A boolean flag is modeled as a string with free‑form values. What do you require?",
      "options": [
        "Allow any string; validation can happen later in the app",
        "Keep string and add a partial index to filter valid values",
        "Use a proper boolean or constrained enum and add a CHECK to enforce domain",
        "Delete the field and infer behavior from logs only"
      ],
      "correctAnswer": 2,
      "additionalContext": "Headline: encode domain rules in the schema.; Why correct: types and CHECK constraints prevent invalid states at the edge.; Why others are wrong: app‑only checks drift; partial indexes don’t fix bad values; logs are not a source of truth.; Cursor leverage: propose type/enum change; generate CHECK DDL; write PR rationale.; Acceptance checks: constraints enforced; invalid writes blocked; incidents reduced.",
      "keyConcepts": [
        "Data types",
        "CHECK constraint",
        "Domain rules"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "Cross‑tenant reports require joins across many partitions. What stance keeps performance predictable?",
      "options": [
        "Avoid partitioning; single table scales indefinitely",
        "Use cross‑partition broadcasts as the default join strategy",
        "Provide shard‑aware entry points and precomputed extracts; avoid scatter/gather on OLTP",
        "Run every cross‑tenant report on the primary during peak hours"
      ],
      "correctAnswer": 3,
      "additionalContext": "Headline: avoid scatter/gather on OLTP; feed cross‑tenant reports from extracts.; Why correct: shard‑aware entry points and extracts keep p95 stable.; Why others are wrong: no partitioning ignores scale; broadcasts explode work; peak primaries risk customers.; Cursor leverage: simulate fan‑out; propose entry points/extracts; add acceptance checks.; Acceptance checks: no scatter/gather in plans; extracts documented; p95 within budget.",
      "keyConcepts": [
        "Shard awareness",
        "Scatter/gather",
        "Extracts",
        "p95"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Draft a PR comment for a risky schema change. Include: phased plan (add → backfill → flip → enforce → cleanup), constraints to encode rules, and a rollback path with measurable success criteria.",
      "sampleStrongResponse": "Describe the phased plan with idempotent backfills and toggles. Add keys/uniques/checks to encode invariants. Success: parity on a sampled slice, lock times within budget, and p95 unchanged. Include rollback to previous reads/writes and scripts to revert DDL. Ask Cursor to scaffold migrations, backfill batches, and the PR acceptance checks."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Outline a tenant sharding plan that avoids hotspots. Include key selection, rebalancing, cutover steps, and communication to stakeholders.",
      "sampleStrongResponse": "Choose a shard key aligned to dominant filters (e.g., tenant_id with optional hash). Plan rebalancing with chunk moves and idempotent backfills. Cutover behind flags per route; verify parity and p95. Communicate blast radius, success metrics, and sunset any legacy paths. Add dashboards for key skew and scatter/gather detection."
    }
  ]
},
  "sprint-planning": {
  "title": "Sprint Planning Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What best characterizes a strong sprint goal?",
      "options": [
        "A collection of unrelated tasks",
        "A committed list of every backlog item regardless of capacity",
        "A cohesive outcome that guides trade offs and sequencing",
        "An exact task list with hour estimates for each person"
      ],
      "correctAnswer": 2,
      "additionalContext": "A sprint goal describes a coherent outcome that focuses the team and enables trade offs in scope while preserving intent.",
      "keyConcepts": [
        "Sprint goal",
        "Focus",
        "Trade offs"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Preferred slicing approach for stories selected in planning:",
      "options": [
        "Horizontal slices by layer only",
        "Thin vertical slice that delivers end to end user value",
        "One large spike followed by a big bang delivery",
        "Only technical subtasks with no user impact"
      ],
      "correctAnswer": 1,
      "additionalContext": "Thin vertical slices validate value and integration early, reducing risk and carryover.",
      "keyConcepts": [
        "Slicing",
        "Vertical slice",
        "Risk reduction"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Capacity versus commitment guidance:",
      "options": [
        "Plan at 110 percent of capacity to push throughput",
        "Commit exactly to average velocity without buffer",
        "Ignore capacity if stakeholders need a date",
        "Plan below capacity and include buffer for unplanned and support"
      ],
      "correctAnswer": 3,
      "additionalContext": "Plan conservatively against capacity and historical velocity, reserving buffer for support and discovery.",
      "keyConcepts": [
        "Capacity",
        "Velocity",
        "Buffer"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "How should carryover be handled at the end of a sprint?",
      "options": [
        "Split the work and keep only completed scope as done; roll the remainder",
        "Mark everything done if it is close",
        "Extend the sprint length to finish",
        "Count points for partially completed work"
      ],
      "correctAnswer": 0,
      "additionalContext": "Only work that meets the definition of done is counted; remaining scope is split or re planned.",
      "keyConcepts": [
        "Carryover",
        "Definition of done",
        "Splitting"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Definition of ready primarily ensures:",
      "options": [
        "Tasks are fully coded before planning",
        "Stories are clear, sized, and testable enough to plan",
        "Stakeholders have approved every detail",
        "Velocity will increase automatically"
      ],
      "correctAnswer": 1,
      "additionalContext": "Definition of ready sets entry quality so teams can plan and forecast with fewer surprises.",
      "keyConcepts": [
        "Definition of ready",
        "Planning quality"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Tasking during sprint planning is most useful when:",
      "options": [
        "It clarifies approach for complex stories without over specifying",
        "It specifies minute by minute actions for the sprint",
        "It replaces acceptance criteria",
        "It is skipped for all work to save time"
      ],
      "correctAnswer": 0,
      "additionalContext": "Lightweight tasking can expose risk and dependencies for complex items while avoiding premature detail.",
      "keyConcepts": [
        "Tasking",
        "Complexity",
        "Dependencies"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "How should velocity be used in sprint planning?",
      "options": [
        "Set as a target to hit each sprint",
        "Compare teams and rank performance",
        "Ignore it and rely only on optimism",
        "Use historical team trend as an input to forecast"
      ],
      "correctAnswer": 3,
      "additionalContext": "Velocity is a team internal forecasting signal, not a target or comparison metric.",
      "keyConcepts": [
        "Velocity",
        "Forecasting",
        "Anti patterns"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "A dependent item is not ready due to an external team. Best action during planning:",
      "options": [
        "Commit anyway and hope it resolves",
        "Overcommit to compensate",
        "Surface the risk, add mitigation or spike, and re sequence if possible",
        "Remove the story and cancel the sprint"
      ],
      "correctAnswer": 2,
      "additionalContext": "Identify dependencies early, plan spikes or mitigations, and choose items that keep the sprint goal achievable.",
      "keyConcepts": [
        "Dependencies",
        "Risk",
        "Spikes"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Given three backlog items that touch the same user outcome, write a sprint goal and describe one vertical slice that proves value early.",
      "sampleStrongResponse": "Sprint goal focuses on a single outcome such as enabling self service password reset. Choose a thin slice that hits UI, API, and data path to complete one reset path, then iterate on edge cases."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Your team averages a velocity range of 20 to 26 over the last six sprints. Support typically consumes two points. Describe your commitment and buffer for the next sprint and why.",
      "sampleStrongResponse": "Commit near the low end of historical range minus expected support, for example 18 to 20 points of planned work. Reserve explicit buffer for support and discovery. This preserves sprint goal focus and reduces rollover."
    }
  ]
},
  "technical-debt-management": {
  "title": "Technical Debt Management Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "What is the “interest” on technical debt?",
      "options": [
        "Ongoing extra effort, defects, and slower delivery caused by the debt",
        "The one time refactor cost",
        "Financial expense from cloud invoices",
        "Depreciation of hardware"
      ],
      "correctAnswer": 0,
      "additionalContext": "Interest manifests as recurring costs: slower changes, more bugs, and reduced throughput until the debt is addressed.",
      "keyConcepts": [
        "Technical debt",
        "Interest",
        "Throughput"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Best first step to prioritize a portfolio of debt items:",
      "options": [
        "Sort alphabetically",
        "Estimate once and forget",
        "Only fix what engineers find annoying",
        "Create a simple impact versus effort matrix with triggers"
      ],
      "correctAnswer": 3,
      "additionalContext": "Use impact/effort and clear triggers (e.g., incident count, lead time) to decide when to pay down debt.",
      "keyConcepts": [
        "Prioritization",
        "Impact/Effort",
        "Triggers"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "A safe refactor strategy for high risk areas includes:",
      "options": [
        "Large bang rewrite without tests",
        "Editing production directly",
        "Refactor behind feature flags with incremental steps and tests",
        "Skipping code review to move faster"
      ],
      "correctAnswer": 2,
      "additionalContext": "Incremental refactors with tests and flags reduce blast radius and allow progressive hardening.",
      "keyConcepts": [
        "Refactor",
        "Feature flags",
        "Incremental"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "Which safety net most directly reduces refactor risk?",
      "options": [
        "Weekly email updates",
        "Automated tests in CI with fast feedback",
        "Extensive manual QA only",
        "Bigger PRs to keep context together"
      ],
      "correctAnswer": 1,
      "additionalContext": "Automated unit, integration, and contract tests in CI catch regressions quickly.",
      "keyConcepts": [
        "CI",
        "Automated tests",
        "Regression"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "A clear guardrail for tech debt management is:",
      "options": [
        "No tests needed if code is simple",
        "Avoid writing ADRs for debt-related decisions",
        "Merge on red builds if change is urgent",
        "Block refactors that reduce coverage below threshold"
      ],
      "correctAnswer": 3,
      "additionalContext": "Policy-as-code guardrails keep quality bars intact during refactors.",
      "keyConcepts": [
        "Guardrails",
        "Policy as code",
        "Coverage"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Identifying technical debt effectively involves:",
      "options": [
        "Using signals like flaky tests, long lead time, hotspots, and incident history",
        "Only engineers logging annoyances",
        "Relying solely on intuition",
        "Ignoring production metrics"
      ],
      "correctAnswer": 0,
      "additionalContext": "Objective signals surface cost centers: hotspots in version control, MTTR, change failure rate, flaky tests.",
      "keyConcepts": [
        "Signals",
        "Hotspots",
        "Incidents"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "When should you schedule debt work within sprints?",
      "options": [
        "Only when there is no feature work",
        "As dedicated slices within feature work or a small standing allocation",
        "Never; it fixes itself",
        "At the very end of a release only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Blend debt work into the flow or reserve a small, explicit allocation to avoid perpetual deferral.",
      "keyConcepts": [
        "Scheduling",
        "Allocation",
        "Flow"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "A telltale sign that a rewrite is riskier than an incremental refactor:",
      "options": [
        "Interfaces are stable and well tested",
        "There is robust observability and contract tests",
        "Large unknowns and undocumented behaviors exist",
        "The area has low coupling and clear boundaries"
      ],
      "correctAnswer": 2,
      "additionalContext": "Undocumented edge cases make big bang rewrites risky; prefer incremental changes with characterization tests.",
      "keyConcepts": [
        "Rewrite risk",
        "Characterization tests",
        "Unknowns"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "You have a payment service with frequent hotfixes due to brittle code. Outline a plan to stabilize it while paying down debt with safety nets.",
      "sampleStrongResponse": "Introduce contract and integration tests around critical paths, add logging and tracing, and refactor behind feature flags in small steps. Track change failure rate and MTTR; require green CI and coverage thresholds for merges."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Propose a quarterly technical debt roadmap that balances feature delivery and debt. Include triggers to escalate specific items.",
      "sampleStrongResponse": "Reserve a 10–15% allocation for prioritized debt tied to measurable outcomes (lead time, CFR). Use an impact/effort matrix, set triggers like incident count or blocked PRs, and review monthly. Escalate items when triggers fire or variance grows."
    }
  ]
},
  "version-control-strategies": {
  "title": "Version Control Strategies Knowledge Quiz",
  "totalQuestions": 10,
  "totalPoints": 25,
  "questions": [
    {
      "id": "1",
      "type": "multiple-choice",
      "points": 2,
      "question": "Default strategy that keeps integration pain low for teams beyond 8&ndash;10 engineers?",
      "options": [
        "Trunk&ndash;based development with small, frequent merges and flags",
        "Long&ndash;lived GitFlow branches with quarterly integration",
        "Only release branches with extended code freezes",
        "Hotfixes directly on main without review"
      ],
      "correctAnswer": 0,
      "additionalContext": "Trunk&ndash;based development emphasizes short&ndash;lived branches and frequent merges to main, often behind flags, which reduces integration risk as teams scale.",
      "keyConcepts": [
        "Trunk&ndash;based",
        "Short&ndash;lived branches",
        "Feature flags"
      ]
    },
    {
      "id": "2",
      "type": "multiple-choice",
      "points": 2,
      "question": "Primary purpose of a release branch before shipping?",
      "options": [
        "Begin new feature work",
        "Rewrite history for readability",
        "Replace tagging and changelogs",
        "Stabilize a cut of main for hardening and targeted fixes"
      ],
      "correctAnswer": 3,
      "additionalContext": "Release branches capture a specific cut for final fixes, docs, and sign&ndash;off before shipping.",
      "keyConcepts": [
        "Release branches",
        "Stabilization",
        "Hardening"
      ]
    },
    {
      "id": "3",
      "type": "multiple-choice",
      "points": 2,
      "question": "Code freeze best practice during a stabilization window?",
      "options": [
        "Pause all changes indefinitely",
        "Continue all merges to main at full speed",
        "Pause risky changes; allow targeted fixes; keep freeze short",
        "Ban hotfixes across environments"
      ],
      "correctAnswer": 2,
      "additionalContext": "Code freezes should be short, minimize risk, and still allow targeted fixes that are backported to the release branch and forward&ndash;merged to main.",
      "keyConcepts": [
        "Code freeze",
        "Backporting",
        "Forward merge"
      ]
    },
    {
      "id": "4",
      "type": "multiple-choice",
      "points": 2,
      "question": "SemVer communicates impact as &ldquo;MAJOR.MINOR.PATCH&rdquo;. Which statement aligns with this?",
      "options": [
        "MAJOR adds features; MINOR breaks APIs; PATCH redesigns history",
        "MAJOR signals breaking changes; MINOR adds features; PATCH fixes bugs",
        "MAJOR/ MINOR/ PATCH are interchangeable labels",
        "PATCH is for experimental features behind flags only"
      ],
      "correctAnswer": 1,
      "additionalContext": "Semantic versioning communicates expected impact: MAJOR for breaking changes, MINOR for backward&ndash;compatible features, PATCH for fixes.",
      "keyConcepts": [
        "SemVer",
        "Tags",
        "Change visibility"
      ]
    },
    {
      "id": "5",
      "type": "multiple-choice",
      "points": 2,
      "question": "Safe standard for rebase vs merge?",
      "options": [
        "Rebase private branches; merge into shared branches to preserve integration context",
        "Rebase shared branches to keep history linear",
        "Always squash&ndash;merge into main to hide history",
        "Avoid merge commits entirely"
      ],
      "correctAnswer": 0,
      "additionalContext": "Rebase on private branches is safe; merging into shared branches preserves integration context and avoids rewriting public history.",
      "keyConcepts": [
        "Rebase",
        "Merge",
        "Shared history"
      ]
    },
    {
      "id": "6",
      "type": "multiple-choice",
      "points": 2,
      "question": "Risk of long&ndash;lived branches in GitFlow&ndash;style workflows?",
      "options": [
        "Reduced merge conflicts over time",
        "Simpler audits due to fewer commits",
        "Guaranteed faster lead time",
        "Drift and higher integration risk as divergence grows"
      ],
      "correctAnswer": 3,
      "additionalContext": "Long&ndash;lived branches drift from main, increasing merge conflicts and integration risk, especially with tightly coupled code.",
      "keyConcepts": [
        "Long&ndash;lived branches",
        "Merge conflicts",
        "Coupling"
      ]
    },
    {
      "id": "7",
      "type": "multiple-choice",
      "points": 2,
      "question": "Benefit of automating changelogs from commits or PR titles?",
      "options": [
        "Removes the need for tags",
        "Eliminates all release notes",
        "Improves change visibility and reduces manual error",
        "Allows arbitrary rewrite of history"
      ],
      "correctAnswer": 2,
      "additionalContext": "Automated changelogs increase transparency and reduce manual error, helping customers and internal teams understand &ldquo;what changed&rdquo;.",
      "keyConcepts": [
        "Changelogs",
        "Automation",
        "Visibility"
      ]
    },
    {
      "id": "8",
      "type": "multiple-choice",
      "points": 2,
      "question": "To avoid &ldquo;lost fix&rdquo; incidents when patching a release branch, the team should:",
      "options": [
        "Only patch the release branch",
        "Backport to the release branch and forward&ndash;merge to main",
        "Patch main only and hope the release picks it up",
        "Rebase main onto the release branch"
      ],
      "correctAnswer": 1,
      "additionalContext": "Patches applied to a release branch should also be forward&ndash;merged to main so fixes are preserved in future releases.",
      "keyConcepts": [
        "Backport",
        "Forward merge",
        "Release policy"
      ]
    },
    {
      "id": "9",
      "type": "freeform",
      "points": 4,
      "question": "Propose a release branch merge policy that prevents &ldquo;lost fix&rdquo; incidents. Include backport/forward&ndash;merge rules, tagging, and how changelogs are generated.",
      "sampleStrongResponse": "Use a stabilization branch per release. All critical fixes: (1) merge to release branch, (2) immediately forward&ndash;merge the same commit to main, (3) tag once sign&ndash;off passes. Automate changelog generation from PR titles that include SemVer intent (&ldquo;major&rdquo;/&ldquo;minor&rdquo;/&ldquo;patch&rdquo;). Protect shared branches; allow rebase only on private feature branches."
    },
    {
      "id": "10",
      "type": "freeform",
      "points": 5,
      "question": "Given a regulated program needing quarterly releases and audit trails, justify GitFlow vs trunk&ndash;based. Specify rebase/merge rules, code freeze handling, and tag/changelog automation.",
      "sampleStrongResponse": "Choose GitFlow for quarterly, audited releases: long&ndash;lived release branches for stabilization and formal sign&ndash;off; short code freezes limited to riskier changes. Rebase allowed only on private branches; merge to shared branches. Tag every release with SemVer and auto&ndash;generate changelogs from PR titles. Backport fixes to the release branch and forward&ndash;merge to main to avoid &ldquo;lost fix&rdquo; issues."
    }
  ]
}
};
